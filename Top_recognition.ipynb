{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxAaEhT0JqM3",
        "outputId": "a4e72f73-13c3-4098-9ef5-faa7bf591246"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: uproot in /usr/local/lib/python3.7/dist-packages (4.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from uproot) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from uproot) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: uproot_methods in /usr/local/lib/python3.7/dist-packages (0.9.2)\n",
            "Requirement already satisfied: numpy>=1.13.1 in /usr/local/lib/python3.7/dist-packages (from uproot_methods) (1.21.6)\n",
            "Requirement already satisfied: awkward<1.0.0 in /usr/local/lib/python3.7/dist-packages (from uproot_methods) (0.14.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220719082949)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.47.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install uproot\n",
        "!pip install uproot_methods\n",
        "import uproot\n",
        "from uproot_methods.classes import TLorentzVector\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "!pip install tensorflow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DhLuB22cm59"
      },
      "source": [
        "# Caricamento dei file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEkF7CrsJ7xo",
        "outputId": "e15dffed-484e-413b-9899-a5a78f060008"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['muons_size', 'muons_pt', 'muons_eta', 'muons_phi', 'muons_e', 'muons_charge', 'muons_chi2', 'muons_mctruthmatch', 'muons_minDR', 'muons_dB', 'muons_dz', 'muons_reliso', 'muons_isLooseMuon', 'muons_isTightMuon', 'muons_nmatchstat', 'muons_nmuonhits', 'muons_npixhits', 'muons_nlaywithmeas', 'electrons_size', 'electrons_pt', 'electrons_eta', 'electrons_phi', 'electrons_e', 'electrons_mctruthmatch', 'electrons_minDR', 'electrons_isTightElectron', 'electrons_reliso', 'electrons_hOverE', 'electrons_dB', 'electrons_dz', 'electrons_dEtaIn', 'electrons_dPhiIn', 'electrons_ninner', 'electrons_sigmaieie', 'electrons_ooemoop', 'met_pt', 'met_phi', 'jets_size', 'jets_pt', 'jets_eta', 'jets_phi', 'jets_e', 'muons_c', 'genlep_size', 'genlep_pt', 'genlep_eta', 'genlep_phi', 'genlep_e', 'genlep_id', 'electrons_charge']\n"
          ]
        }
      ],
      "source": [
        "# carico i file\n",
        "filename=\"segnale1.root\" # segnale dileptonico\n",
        "segnale = uproot.open(filename)\n",
        "\n",
        "filename2=\"fondo_1.root\" # fondo\n",
        "fondo = uproot.open(filename2)\n",
        "\n",
        "# accedo alle colonne\n",
        "print(segnale[\"trees/events\"].keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYR3fG0v_Kud"
      },
      "outputs": [],
      "source": [
        "# fondo contro segnale\n",
        "# contro segnale Z\n",
        "# massa della Z\n",
        "# feature met energia mancante -> es. neutrini\n",
        "# nella zeta avrò met minore perché i neutrini trasportano meno energia\n",
        "# allenare contro il fondo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oI4Mm5RRKSkO"
      },
      "outputs": [],
      "source": [
        "# trasformo in pandas dataframe i dati\n",
        "\n",
        "# segnale\n",
        "np_segnale = (segnale[\"trees/events\"].arrays(segnale[\"trees/events\"].keys(),library=\"np\"))\n",
        "df_segnale = pd.DataFrame(np_segnale)\n",
        "\n",
        "# fondo\n",
        "np_fondo = (fondo[\"trees/events\"].arrays(fondo[\"trees/events\"].keys(),library=\"np\"))\n",
        "df_fondo = pd.DataFrame(np_fondo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dB4JxIAsNE8c",
        "outputId": "a23e3421-08a0-4169-d72d-986d4944a6fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 50)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "print(df_segnale.shape)\n",
        "df_fondo.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1nSaYdqhd-r"
      },
      "outputs": [],
      "source": [
        "def drop_size(df):\n",
        "  for i in range(df.shape[0]):\n",
        "    if df['jets_size'][i] < df['electrons_size'][i] or df['jets_size'][i] < df['electrons_size'][i]:\n",
        "      # print(i)\n",
        "      df = df.drop(i, axis=0)\n",
        "  df.index=list(range(df.shape[0]))\n",
        "  return df\n",
        "\n",
        "df_fondo = drop_size(df_fondo)\n",
        "df_segnale = drop_size(df_segnale)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e68gvLa7Lwhv"
      },
      "outputs": [],
      "source": [
        "def drop_rows(df):\n",
        "  drop_rows = []\n",
        "  for i in range(df.shape[0]):\n",
        "    if df['jets_pt'][i].size==0 and df['muons_pt'][i].size==0 and df['electrons_pt'][i].size==0:\n",
        "      drop_rows.append(i)\n",
        "  return drop_rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4-69nDYLBLj",
        "outputId": "058a0ece-47a1-4381-f326-c70dd5e76786"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(49976, 50)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42306, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "drop_list_segnale = drop_rows(df_segnale)\n",
        "drop_list_fondo = drop_rows(df_fondo)\n",
        "\n",
        "df_segnale = df_segnale.drop(drop_list_segnale, axis=0)\n",
        "df_fondo = df_fondo.drop(drop_list_fondo, axis=0)\n",
        "\n",
        "print(df_segnale.shape)\n",
        "df_fondo.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKMQMFH4Y_D_"
      },
      "outputs": [],
      "source": [
        "df_fondo = df_fondo[:5000]\n",
        "df_segnale = df_segnale[:5000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKCy235oOZem"
      },
      "outputs": [],
      "source": [
        "df_fondo.index=list(range(5000))\n",
        "df_segnale.index=list(range(5000))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLLTHUeldHUR"
      },
      "source": [
        "# Preprocessing dei dati\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDaQsmu-Si-r"
      },
      "outputs": [],
      "source": [
        "def filter_df_by_name(dataframe,particle):\n",
        "  '''restituisce dataframe con le colonne relative alla particella selezionata,\n",
        "  il parametro particle da inserire deve essere una stringa'''\n",
        "  '''per esempio \"electrons\" oppure \"muons\"'''\n",
        "  list_feat_elect=[]\n",
        "  for i in list(dataframe.columns):\n",
        "    if particle in i:\n",
        "        list_feat_elect.append(i)\n",
        "  df_filtered=dataframe[list_feat_elect]\n",
        "  return df_filtered"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYFzBciJkSUu",
        "outputId": "3d07da8d-1e1f-499e-d427-cfff912ebd10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fondo:  {'muons_size': 'int', 'muons_pt': 3376, 'muons_eta': 3376, 'muons_phi': 3376, 'muons_e': 3376, 'muons_charge': 3376, 'muons_chi2': 3376, 'muons_mctruthmatch': 3376, 'muons_minDR': 3376, 'muons_dB': 3376, 'muons_dz': 3376, 'muons_reliso': 3376, 'muons_isLooseMuon': 3376, 'muons_isTightMuon': 3376, 'muons_nmatchstat': 5000, 'muons_nmuonhits': 3376, 'muons_npixhits': 3376, 'muons_nlaywithmeas': 3376, 'electrons_size': 'int', 'electrons_pt': 3212, 'electrons_eta': 3212, 'electrons_phi': 3212, 'electrons_e': 3212, 'electrons_mctruthmatch': 3212, 'electrons_minDR': 3212, 'electrons_isTightElectron': 3212, 'electrons_reliso': 3212, 'electrons_hOverE': 3212, 'electrons_dB': 3212, 'electrons_dz': 3212, 'electrons_dEtaIn': 3212, 'electrons_dPhiIn': 3212, 'electrons_ninner': 3212, 'electrons_sigmaieie': 3212, 'electrons_ooemoop': 3212, 'met_pt': 0, 'met_phi': 0, 'jets_size': 'int', 'jets_pt': 0, 'jets_eta': 0, 'jets_phi': 0, 'jets_e': 0, 'muons_c': 5000, 'genlep_size': 'int', 'genlep_pt': 5000, 'genlep_eta': 5000, 'genlep_phi': 5000, 'genlep_e': 5000, 'genlep_id': 5000, 'electrons_charge': 3212}\n",
            "segnale:  {'muons_size': 'int', 'muons_pt': 2360, 'muons_eta': 2360, 'muons_phi': 2360, 'muons_e': 2360, 'muons_charge': 2360, 'muons_chi2': 2360, 'muons_mctruthmatch': 2360, 'muons_minDR': 2360, 'muons_dB': 2360, 'muons_dz': 2360, 'muons_reliso': 2360, 'muons_isLooseMuon': 2360, 'muons_isTightMuon': 2360, 'muons_nmatchstat': 5000, 'muons_nmuonhits': 2360, 'muons_npixhits': 2360, 'muons_nlaywithmeas': 2360, 'electrons_size': 'int', 'electrons_pt': 2201, 'electrons_eta': 2201, 'electrons_phi': 2201, 'electrons_e': 2201, 'electrons_mctruthmatch': 2201, 'electrons_minDR': 2201, 'electrons_isTightElectron': 2201, 'electrons_reliso': 2201, 'electrons_hOverE': 2201, 'electrons_dB': 2201, 'electrons_dz': 2201, 'electrons_dEtaIn': 2201, 'electrons_dPhiIn': 2201, 'electrons_ninner': 2201, 'electrons_sigmaieie': 2201, 'electrons_ooemoop': 2201, 'met_pt': 0, 'met_phi': 0, 'jets_size': 'int', 'jets_pt': 0, 'jets_eta': 0, 'jets_phi': 0, 'jets_e': 0, 'muons_c': 5000, 'genlep_size': 'int', 'genlep_pt': 5000, 'genlep_eta': 5000, 'genlep_phi': 5000, 'genlep_e': 5000, 'genlep_id': 5000, 'electrons_charge': 2201}\n"
          ]
        }
      ],
      "source": [
        "def is_null(df):\n",
        "    '''\n",
        "    Check and count if there are null value in a whole dataframe, column by column\n",
        "    '''\n",
        "    col=list(df.columns)\n",
        "    counting = []\n",
        "    for i in col:\n",
        "        count = 0\n",
        "        for j in df[i]:\n",
        "            if type(j)==int:\n",
        "              count = 'int'\n",
        "              break\n",
        "            if len(j)==0:\n",
        "                count += 1\n",
        "        counting.append(count)\n",
        "    return dict(zip(col, counting))\n",
        "\n",
        "print('fondo: ', is_null(df_fondo))\n",
        "print('segnale: ', is_null(df_segnale))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FFJef3UvLy7",
        "outputId": "189a6b23-eae8-4b77-d9fe-a272862ef7ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5000, 50)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 44)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# droppiamo le colonne che hanno nel nome 'genlep' perché vuote\n",
        "def drop_genlep(dataframe):\n",
        "    list_feat_del=[]\n",
        "    for column in list(dataframe.columns):\n",
        "        if \"genlep\" in column:\n",
        "            list_feat_del.append(column)\n",
        "\n",
        "    dataframe=dataframe.drop(columns=list_feat_del)\n",
        "    return dataframe\n",
        "\n",
        "print(df_segnale.shape)\n",
        "df_segnale = drop_genlep(df_segnale)\n",
        "df_fondo = drop_genlep(df_fondo)\n",
        "df_segnale.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpVvFW10TzVX"
      },
      "outputs": [],
      "source": [
        "def n_particles(df):\n",
        "# Vogliamo sapere per ogni evento quante particelle ci sono\n",
        "# in modo da creare una lista con un secondo indice\n",
        "  col = df.columns\n",
        "  index_2 = []\n",
        "  col_index = []\n",
        "  list_dict = []\n",
        "  for i in col:\n",
        "    index_2 = []\n",
        "    for j in range(df.shape[0]):\n",
        "      if type(df[i][j])==int:\n",
        "          break\n",
        "      count = 1\n",
        "      if (df[i][j].size==1 or df[i][j].size==0):\n",
        "        count = 1\n",
        "        index_2.append(count)\n",
        "      else:\n",
        "        for k in range(1,df[i][j].size+1):\n",
        "          count = k\n",
        "          index_2.append(count)\n",
        "    #col_index è una lista (ciclata su tutte le colonne) del tipo:\n",
        "    #col_index[41]=[1,2,3,1,2,1,...]\n",
        "    #cioè la colonna 41 ha come prima riga un array di dimensione 3,\n",
        "    #come seconda uno di dimensione 2,ecc..\n",
        "\n",
        "    col_index.append(index_2)\n",
        "\n",
        "    #dic è un dizionario che associa ad ogni colonna il numero totale di\n",
        "    #particelle coinvolte\n",
        "    dic = dict(zip(df.columns, [len(col_index[i]) for i in range(len(col_index))] ))\n",
        "    # dizionario che restituisce come chiave il nome della feature\n",
        "    # e come valore la size della colonna corrispondente\n",
        "  return dic,col_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAKAxyfWzI8g"
      },
      "outputs": [],
      "source": [
        "def indexing_columns(df, feature_name, size, col_index):\n",
        "  '''\n",
        "  Restituisce una lista di indici che segnalano l'evento di riferimento\n",
        "  contando tutte le particelle (o suoi attributi) presenti in una determinata colonna\n",
        "  '''\n",
        "  # prendo l'indice corrispondente a quella colonna per lavorare su col_index\n",
        "  index_col = df.columns.get_loc(feature_name)\n",
        "  ind = []\n",
        "  evento = 0\n",
        "  for i in range(size):\n",
        "    # condizione sull'ultimo valore: se è 1 bisogna incrementare la variabile evento\n",
        "    if i==(size-1):\n",
        "      ind.append(evento)\n",
        "      break\n",
        "    ind.append(evento)\n",
        "    # condizione che si verifica quando si cambia evento\n",
        "    # esempio: [1,2,3,1,2,1] -> questa lista contiene 3 eventi:\n",
        "    # il primo è composto da tre slot particelle, il secondo da due e l'ultimo da uno\n",
        "    if col_index[index_col][i] >= col_index[index_col][i+1]:\n",
        "      evento = evento + 1\n",
        "  return ind"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lck-XGsOyh_2"
      },
      "outputs": [],
      "source": [
        "# non ci interessano tutte le colonne\n",
        "features = ['muons_pt', 'muons_e', 'electrons_pt', 'electrons_e', 'electrons_isTightElectron', 'muons_isTightMuon', 'jets_pt', 'jets_e', 'met_pt', 'met_phi', 'muons_eta', 'muons_phi', 'electrons_eta', 'electrons_phi', 'jets_eta', 'jets_phi']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2RIUPGP3GNK"
      },
      "outputs": [],
      "source": [
        "# vogliamo creare l'indice 1, quello che ci dà informazione su che evento stiamo guardando,\n",
        "# dunque prendo nome e size della colonna con size massima (solitamente è quella che fa riferimento\n",
        "# agli attributi dei jet -MA NON LA SIZE-)\n",
        "import operator\n",
        "\n",
        "# prendiamo solo le colonne selezionate\n",
        "df = df_segnale[features] # per il segnale\n",
        "df_f = df_fondo[features] # per il fondo\n",
        "\n",
        "# genero il dizionario delle size e l'indice che conta le particelle per evento\n",
        "dic, col_index = n_particles(df) # per il segnale\n",
        "dic_fondo, col_index_fondo = n_particles(df_f) # per il fondo\n",
        "\n",
        "# size colonna di dimensione massima (solitamente è quella dei jet)\n",
        "max_value = max(dic.values()) # per il segnale\n",
        "max_value_fondo = max(dic_fondo.values()) # per il fondo\n",
        "\n",
        "# nome corrispondente alla colonna di size massima\n",
        "max_key = max(dic.items(), key=operator.itemgetter(1))[0] # per il segnale\n",
        "max_key_fondo = max(dic_fondo.items(), key=operator.itemgetter(1))[0] # per il fondo\n",
        "\n",
        "# genero l'indice degli eventi\n",
        "ind_max_list = indexing_columns(df, max_key, max_value, col_index)\n",
        "ind_max_list_fondo = indexing_columns(df_f, max_key_fondo, max_value_fondo, col_index_fondo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgTT42xXFX-4"
      },
      "outputs": [],
      "source": [
        "\n",
        "# generiamo il nuovo array di dati in cui tutte le colonne avranno size pari\n",
        "# alla dimensione della colonna di size massima, riempiendo gli 'spazi vuoti' con 'null_var',\n",
        "# altrimenti -10 (per le grandezze eta e phi)\n",
        "\n",
        "def new_array_stepone(df, ind_max_list, dic, col_index):\n",
        "  new_df_array = []\n",
        "  new_df_col = []\n",
        "  col = df.columns\n",
        "\n",
        "  for i in col:\n",
        "    new_df_col = []\n",
        "    # if 'eta' in i or 'phi' in i:\n",
        "    if 'isTight' in i:\n",
        "      null_var = 0\n",
        "    else:\n",
        "      null_var = -10\n",
        "\n",
        "    for j in range(df.shape[0]):\n",
        "\n",
        "      # questa condizione serve nel caso ci sia una colonna di int\n",
        "      if type(df[i][j])==int or type(df[i][j])==np.int32:\n",
        "          break\n",
        "\n",
        "      # calcolo la differenza di particelle tra quelle presenti\n",
        "      # nella colonna i-esima e la colonna con la size massima\n",
        "      diff = ind_max_list.count(j) - indexing_columns(df, i, dic[i], col_index).count(j)\n",
        "\n",
        "      if df[i][j].size==0:\n",
        "        # nel caso in cui ci sia un vettore vuoto aggiungiamo null_var\n",
        "        new_df_col.append(null_var)\n",
        "        for w in range(diff): # riempio gli slot vuoti\n",
        "          new_df_col.append(null_var)\n",
        "\n",
        "      else:\n",
        "\n",
        "        for k in range(df[i][j].size):\n",
        "          # nel caso in cui il vettore abbia dei valori, li aggiungo\n",
        "          new_df_col.append(df[i][j].tolist()[k])\n",
        "        for w in range(diff): # riempio gli slot vuoti\n",
        "          new_df_col.append(null_var)\n",
        "\n",
        "    new_df_array.append(new_df_col)\n",
        "\n",
        "  return new_df_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bLtIBVjgOHp"
      },
      "outputs": [],
      "source": [
        "new_df_array = new_array_stepone(df, ind_max_list, dic, col_index)\n",
        "new_df_array_fondo = new_array_stepone(df_f, ind_max_list_fondo, dic_fondo, col_index_fondo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4B_8pAszCtz"
      },
      "outputs": [],
      "source": [
        "# 'muons_pt', 'muons_e', 'electrons_pt', 'electrons_e', 'electrons_isTightElectron', 'muons_isTightMuon', 'jets_pt', 'jets_e', 'met_pt', 'met_phi', 'muons_eta', 'muons_phi', 'electrons_eta', 'electrons_phi', 'jets_eta', 'jets_phi'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zs31QWDkxMlK"
      },
      "outputs": [],
      "source": [
        "# for i in range(len(new_df_array_fondo)):\n",
        "#   print(len(new_df_array_fondo[i]))\n",
        "\n",
        "# print(new_df_array_fondo[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHiP7YEQJLcP"
      },
      "outputs": [],
      "source": [
        "dic_df = dict(zip(features, new_df_array))\n",
        "dic_df_f = dict(zip(features, new_df_array_fondo))\n",
        "\n",
        "# trasformo il vettore creato in pandas dataframe, con indice relativo all'evento\n",
        "new_df_segnale = pd.DataFrame(data=dic_df, index=ind_max_list)\n",
        "new_df_fondo = pd.DataFrame(data=dic_df_f, index=ind_max_list_fondo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyXirPPuy_Bj"
      },
      "source": [
        "# Padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_dHma28dsgY"
      },
      "outputs": [],
      "source": [
        "# controllo il numero di eventi massimo\n",
        "def check_max_event(new_df, max_key):\n",
        "  n_partic_per_event = []\n",
        "  for i in range(max(list(new_df.index))+1):\n",
        "    if type(new_df[max_key].loc[i])==np.float64: # caso in cui abbiamo un unico jet (non posso ciclare su un unico valore)\n",
        "      n_partic_per_event.append(1)\n",
        "    else:\n",
        "      n_partic_per_event.append(new_df[max_key].loc[i].count())\n",
        "\n",
        "  return max(n_partic_per_event)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2I2-fyDla8t"
      },
      "outputs": [],
      "source": [
        "# computo il numero di slot massimo per evento presente nel dataframe segnale e fondo\n",
        "max_event_segnale = check_max_event(new_df_segnale, max_key)\n",
        "max_event_fondo = check_max_event(new_df_fondo, max_key_fondo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7XsNaNnr3Sn",
        "outputId": "663cda10-66ea-474f-cbc4-1503cc610732"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19\n"
          ]
        }
      ],
      "source": [
        "# dovranno essere concatenati, quindi scegliamo il maggiore tra i due\n",
        "max_n_slot = max([max_event_segnale, max_event_fondo])\n",
        "print(max_n_slot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdvyzUP4_ZUf"
      },
      "outputs": [],
      "source": [
        "def index_padding(ind_max_list, max_event):\n",
        "  '''\n",
        "  creo la nuova lista di indici per rendere ogni evento di size\n",
        "  pari alla dimensione massima di un evento\n",
        "  '''\n",
        "  ind_list = []\n",
        "  for i in range(len(ind_max_list)):\n",
        "    if i==(len(ind_max_list)-1): # condizione sull'ultimo valore\n",
        "      ind_list.append(ind_max_list[i])\n",
        "      diff = max_event - ind_list.count(ind_max_list[i])\n",
        "      for j in range(diff):\n",
        "        ind_list.append(ind_max_list[i])\n",
        "      break\n",
        "    ind_list.append(ind_max_list[i])\n",
        "    diff = max_event - ind_list.count(ind_max_list[i])\n",
        "    if diff<0: # volevo essere simpatica\n",
        "      print(ind_max_list[i])\n",
        "      print('Houston, we have a problem!')\n",
        "    if ind_max_list[i+1] > ind_max_list[i]:\n",
        "      for j in range(diff):\n",
        "        ind_list.append(ind_max_list[i])\n",
        "  return ind_list\n",
        "\n",
        "# ind_list è quindi l'indice del dataframe definitivo dopo aver fatto il padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjBavRdqnoK_"
      },
      "outputs": [],
      "source": [
        "# unrolling\n",
        "ind_list = index_padding(ind_max_list, max_n_slot)\n",
        "ind_list_fondo = index_padding(ind_max_list_fondo, max_n_slot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnUFwqZvidAr"
      },
      "outputs": [],
      "source": [
        "def array_colonne_def(col, new_df, max_event):\n",
        "  colonne_definitive = [] # finalmente\n",
        "\n",
        "  for i in col:\n",
        "    # if 'eta' in i or 'phi' in i:\n",
        "    if 'isTight' in i:\n",
        "      null_var = 0\n",
        "    else:\n",
        "      null_var = -10\n",
        "\n",
        "    col_def = []\n",
        "\n",
        "    for j in range(max(list(new_df.index))+1):\n",
        "\n",
        "      if type(new_df[i].loc[j])==np.float64: # nel caso ci sia un unico jet\n",
        "        diff = max_event - 1\n",
        "        col_def.append(new_df[i].loc[j])\n",
        "        for w in range(diff):\n",
        "            col_def.append(null_var)\n",
        "\n",
        "      else:\n",
        "\n",
        "        diff = max_event - len(list(new_df[i].loc[j]))\n",
        "        for k in list(new_df[i].loc[j]):\n",
        "          col_def.append(k)\n",
        "        for w in range(diff):\n",
        "          col_def.append(null_var)\n",
        "\n",
        "    colonne_definitive.append(col_def)\n",
        "  return colonne_definitive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DaubBgMKocui"
      },
      "outputs": [],
      "source": [
        "# colonne_definitive è il dataframe che conta per ogni evento\n",
        "# numero di event_max_size slot particelle\n",
        "\n",
        "colonne_definitive = array_colonne_def(features, new_df_segnale, max_n_slot)\n",
        "colonne_definitive_fondo = array_colonne_def(features, new_df_fondo, max_n_slot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luIURqfCnGCP"
      },
      "outputs": [],
      "source": [
        "dic_def_df = dict(zip(features, colonne_definitive))\n",
        "dic_def_df_f = dict(zip(features, colonne_definitive_fondo))\n",
        "\n",
        "# l'indice per il fondo deve essere diverso, perché\n",
        "# il df fondo deve essere concatenato con df segnale\n",
        "index_fondo = np.array(ind_list_fondo) + 5000    # ci sono 10000 eventi per df\n",
        "\n",
        "# lo trasformo in pandas dataframe\n",
        "def_df_segnale = pd.DataFrame(data=dic_def_df, index=ind_list)\n",
        "def_df_fondo = pd.DataFrame(data=dic_def_df_f, index=index_fondo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LY5akT1BfAN9"
      },
      "outputs": [],
      "source": [
        "# magari servirà più in là, boh\n",
        "v1 = TLorentzVector.TLorentzVector.from_ptetaphie(pt=40.124088,\teta= -0.154926,\tphi=-2.44714, energy=40.606724)\n",
        "v2 = TLorentzVector.TLorentzVector.from_ptetaphie(pt=118.894325,\teta=-1.415037, \tphi=1.565296, energy=259.1633)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0vqTn_FDDHi",
        "outputId": "f2687a9d-3b64-4037-cdaa-970adf819913"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       0.0\n",
              "0       0.0\n",
              "0       0.0\n",
              "0       0.0\n",
              "0       0.0\n",
              "       ... \n",
              "4999    0.0\n",
              "4999    0.0\n",
              "4999    0.0\n",
              "4999    0.0\n",
              "4999    0.0\n",
              "Name: muons_isTightMuon, Length: 95000, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "def_df_segnale['muons_isTightMuon']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFeuYcEBok34"
      },
      "outputs": [],
      "source": [
        "def select_events(df):\n",
        "  '''\n",
        "  questa funzione aggiunge al dataframe la label binaria 'top_label',\n",
        "  essa vale 1 quando:\n",
        "  - ci sono due elettroni 'isTight';\n",
        "  - ci sono due muoni 'isTight';\n",
        "  - c'è un elettrone e un muone, entrambi 'isTight'.\n",
        "  altrimenti vale 0.\n",
        "  'num_events' = 2 perché prendiamo almeno 2 leptoni per evento\n",
        "  '''\n",
        "  label=[]\n",
        "  for i in range(df.index[0], max(df.index)+1):\n",
        "    # se i leptoni sono isolati\n",
        "    if df.loc[i]['electrons_isTightElectron'].sum()+df.loc[i]['muons_isTightMuon'].sum()>=2:\n",
        "      for i in range(max_n_slot):\n",
        "        # label segnale\n",
        "        label.append(1)\n",
        "    else:\n",
        "      for i in range(max_n_slot):\n",
        "        # label fondo\n",
        "        label.append(0)\n",
        "\n",
        "  df['top_label'] = label\n",
        "  # df = df.query('top_label==1')\n",
        "  return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LG7D-6TMngK2"
      },
      "outputs": [],
      "source": [
        "# creo il dataframe con la label\n",
        "df_stepone = select_events(def_df_segnale)\n",
        "df_stepone_fondo = select_events(def_df_fondo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "9NwMRjd_zkCt",
        "outputId": "6adfec96-4c60-44f7-ab77-2711e7cbb6ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           muons_pt  muons_e  electrons_pt  electrons_e  \\\n",
              "top_label                                                 \n",
              "0             77083    77083         77083        77083   \n",
              "1             17917    17917         17917        17917   \n",
              "\n",
              "           electrons_isTightElectron  muons_isTightMuon  jets_pt  jets_e  \\\n",
              "top_label                                                                  \n",
              "0                              77083              77083    77083   77083   \n",
              "1                              17917              17917    17917   17917   \n",
              "\n",
              "           met_pt  met_phi  muons_eta  muons_phi  electrons_eta  \\\n",
              "top_label                                                         \n",
              "0           77083    77083      77083      77083          77083   \n",
              "1           17917    17917      17917      17917          17917   \n",
              "\n",
              "           electrons_phi  jets_eta  jets_phi  \n",
              "top_label                                     \n",
              "0                  77083     77083     77083  \n",
              "1                  17917     17917     17917  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c915470c-dbf7-40e9-bc81-0f88fa584c33\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>muons_pt</th>\n",
              "      <th>muons_e</th>\n",
              "      <th>electrons_pt</th>\n",
              "      <th>electrons_e</th>\n",
              "      <th>electrons_isTightElectron</th>\n",
              "      <th>muons_isTightMuon</th>\n",
              "      <th>jets_pt</th>\n",
              "      <th>jets_e</th>\n",
              "      <th>met_pt</th>\n",
              "      <th>met_phi</th>\n",
              "      <th>muons_eta</th>\n",
              "      <th>muons_phi</th>\n",
              "      <th>electrons_eta</th>\n",
              "      <th>electrons_phi</th>\n",
              "      <th>jets_eta</th>\n",
              "      <th>jets_phi</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top_label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>77083</td>\n",
              "      <td>77083</td>\n",
              "      <td>77083</td>\n",
              "      <td>77083</td>\n",
              "      <td>77083</td>\n",
              "      <td>77083</td>\n",
              "      <td>77083</td>\n",
              "      <td>77083</td>\n",
              "      <td>77083</td>\n",
              "      <td>77083</td>\n",
              "      <td>77083</td>\n",
              "      <td>77083</td>\n",
              "      <td>77083</td>\n",
              "      <td>77083</td>\n",
              "      <td>77083</td>\n",
              "      <td>77083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>17917</td>\n",
              "      <td>17917</td>\n",
              "      <td>17917</td>\n",
              "      <td>17917</td>\n",
              "      <td>17917</td>\n",
              "      <td>17917</td>\n",
              "      <td>17917</td>\n",
              "      <td>17917</td>\n",
              "      <td>17917</td>\n",
              "      <td>17917</td>\n",
              "      <td>17917</td>\n",
              "      <td>17917</td>\n",
              "      <td>17917</td>\n",
              "      <td>17917</td>\n",
              "      <td>17917</td>\n",
              "      <td>17917</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c915470c-dbf7-40e9-bc81-0f88fa584c33')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c915470c-dbf7-40e9-bc81-0f88fa584c33 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c915470c-dbf7-40e9-bc81-0f88fa584c33');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "df_stepone.groupby('top_label').count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "Qhn47gON03nF",
        "outputId": "4ea6ccb0-9cae-4393-bac2-ba8536a4936b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           muons_pt  muons_e  electrons_pt  electrons_e  \\\n",
              "top_label                                                 \n",
              "0             74461    74461         74461        74461   \n",
              "1             20539    20539         20539        20539   \n",
              "\n",
              "           electrons_isTightElectron  muons_isTightMuon  jets_pt  jets_e  \\\n",
              "top_label                                                                  \n",
              "0                              74461              74461    74461   74461   \n",
              "1                              20539              20539    20539   20539   \n",
              "\n",
              "           met_pt  met_phi  muons_eta  muons_phi  electrons_eta  \\\n",
              "top_label                                                         \n",
              "0           74461    74461      74461      74461          74461   \n",
              "1           20539    20539      20539      20539          20539   \n",
              "\n",
              "           electrons_phi  jets_eta  jets_phi  \n",
              "top_label                                     \n",
              "0                  74461     74461     74461  \n",
              "1                  20539     20539     20539  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b6de067e-7f09-4844-8d70-1fcadc12fc36\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>muons_pt</th>\n",
              "      <th>muons_e</th>\n",
              "      <th>electrons_pt</th>\n",
              "      <th>electrons_e</th>\n",
              "      <th>electrons_isTightElectron</th>\n",
              "      <th>muons_isTightMuon</th>\n",
              "      <th>jets_pt</th>\n",
              "      <th>jets_e</th>\n",
              "      <th>met_pt</th>\n",
              "      <th>met_phi</th>\n",
              "      <th>muons_eta</th>\n",
              "      <th>muons_phi</th>\n",
              "      <th>electrons_eta</th>\n",
              "      <th>electrons_phi</th>\n",
              "      <th>jets_eta</th>\n",
              "      <th>jets_phi</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top_label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>74461</td>\n",
              "      <td>74461</td>\n",
              "      <td>74461</td>\n",
              "      <td>74461</td>\n",
              "      <td>74461</td>\n",
              "      <td>74461</td>\n",
              "      <td>74461</td>\n",
              "      <td>74461</td>\n",
              "      <td>74461</td>\n",
              "      <td>74461</td>\n",
              "      <td>74461</td>\n",
              "      <td>74461</td>\n",
              "      <td>74461</td>\n",
              "      <td>74461</td>\n",
              "      <td>74461</td>\n",
              "      <td>74461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20539</td>\n",
              "      <td>20539</td>\n",
              "      <td>20539</td>\n",
              "      <td>20539</td>\n",
              "      <td>20539</td>\n",
              "      <td>20539</td>\n",
              "      <td>20539</td>\n",
              "      <td>20539</td>\n",
              "      <td>20539</td>\n",
              "      <td>20539</td>\n",
              "      <td>20539</td>\n",
              "      <td>20539</td>\n",
              "      <td>20539</td>\n",
              "      <td>20539</td>\n",
              "      <td>20539</td>\n",
              "      <td>20539</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b6de067e-7f09-4844-8d70-1fcadc12fc36')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b6de067e-7f09-4844-8d70-1fcadc12fc36 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b6de067e-7f09-4844-8d70-1fcadc12fc36');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "df_stepone_fondo.groupby('top_label').count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpeTq94-20lQ"
      },
      "outputs": [],
      "source": [
        "df_stepone = df_stepone.query('top_label==1')\n",
        "df_stepone_fondo = df_stepone_fondo.query('top_label==1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZqX8zm3CBtm"
      },
      "outputs": [],
      "source": [
        "def target(df_segnale, df_fondo):\n",
        "  '''\n",
        "  Questa funzione prende in input i dataframe di segnale e fondo, crea la label\n",
        "  per distinguerli e poi fa il merge dei due.\n",
        "  '''\n",
        "  df_segnale['target'] = np.ones((1,df_segnale.shape[0]))[0] # lab = 1\n",
        "  df_fondo['target'] = np.ones((1,df_fondo.shape[0]))[0]*0 # lab = 0\n",
        "\n",
        "  tot_df = pd.concat([df_segnale, df_fondo], axis=0, ignore_index=False)\n",
        "  # il dataframe che ne risulta preserva gli indici di entrambi che segnalano quindi 2k eventi\n",
        "  return tot_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzVIWhdIDDfK",
        "outputId": "b941dc92-f0de-446d-c190-7751bc04c200"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n"
          ]
        }
      ],
      "source": [
        "tot_df = target(df_stepone, df_stepone_fondo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KK9AnGz5aUY0"
      },
      "outputs": [],
      "source": [
        "def indice_ridotto(df):\n",
        "  indice_ridotto = []\n",
        "  for i in range(int(df.shape[0]/max_n_slot)):\n",
        "    for j in range(max_n_slot):\n",
        "      indice_ridotto.append(i)\n",
        "  df.index = indice_ridotto\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPwo05Qs3QDK"
      },
      "outputs": [],
      "source": [
        "tot_df = indice_ridotto(tot_df)\n",
        "\n",
        "# devo fare lo shuffle sugli eventi, non sulle righe.\n",
        "# Quindi facciamo lo shuffle sugli indici\n",
        "\n",
        "index_list = list(np.array(list(range(int(tot_df.shape[0]/max_n_slot))))) # creo la lista degli indici\n",
        "np.random.shuffle(index_list) # shuffle non ritorna niente, agisce su index_list\n",
        "\n",
        "tot_df = tot_df.loc[index_list]\n",
        "#.sort_index()\n",
        "\n",
        "# tot_df.to_csv('tot_df_7.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fMgXHS97aoe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9f6a1d60-3782-40b1-a505-f0531c93ef57"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       muons_pt    muons_e  electrons_pt  electrons_e  \\\n",
              "1051  27.620361  81.199272    -10.000000   -10.000000   \n",
              "1051  23.156866  27.434654    -10.000000   -10.000000   \n",
              "1051 -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "1051 -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "1051 -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "1051 -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "1051 -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "1051 -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "1051 -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "1051 -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "1051 -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "1051 -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "1051 -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "1051 -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "1051 -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "1051 -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "1051 -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "1051 -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "1051 -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "1676 -10.000000 -10.000000     29.631136    36.176971   \n",
              "1676 -10.000000 -10.000000     29.960835    63.366901   \n",
              "1676 -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "1676 -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "1676 -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "1676 -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "1676 -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "1676 -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "1676 -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "1676 -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "1676 -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "1676 -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "1676 -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "1676 -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "1676 -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "1676 -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "1676 -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "1676 -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "1676 -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "248   47.655804  88.702911     42.209152    42.313957   \n",
              "248  -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "248  -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "248  -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "248  -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "248  -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "248  -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "248  -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "248  -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "248  -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "248  -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "248  -10.000000 -10.000000    -10.000000   -10.000000   \n",
              "\n",
              "      electrons_isTightElectron  muons_isTightMuon    jets_pt      jets_e  \\\n",
              "1051                        0.0                1.0  27.620361   81.199272   \n",
              "1051                        0.0                1.0  23.156866   27.434654   \n",
              "1051                        0.0                0.0 -10.000000  -10.000000   \n",
              "1051                        0.0                0.0 -10.000000  -10.000000   \n",
              "1051                        0.0                0.0 -10.000000  -10.000000   \n",
              "1051                        0.0                0.0 -10.000000  -10.000000   \n",
              "1051                        0.0                0.0 -10.000000  -10.000000   \n",
              "1051                        0.0                0.0 -10.000000  -10.000000   \n",
              "1051                        0.0                0.0 -10.000000  -10.000000   \n",
              "1051                        0.0                0.0 -10.000000  -10.000000   \n",
              "1051                        0.0                0.0 -10.000000  -10.000000   \n",
              "1051                        0.0                0.0 -10.000000  -10.000000   \n",
              "1051                        0.0                0.0 -10.000000  -10.000000   \n",
              "1051                        0.0                0.0 -10.000000  -10.000000   \n",
              "1051                        0.0                0.0 -10.000000  -10.000000   \n",
              "1051                        0.0                0.0 -10.000000  -10.000000   \n",
              "1051                        0.0                0.0 -10.000000  -10.000000   \n",
              "1051                        0.0                0.0 -10.000000  -10.000000   \n",
              "1051                        0.0                0.0 -10.000000  -10.000000   \n",
              "1676                        1.0                0.0  46.530571   58.499062   \n",
              "1676                        1.0                0.0  33.505123   70.467567   \n",
              "1676                        0.0                0.0 -10.000000  -10.000000   \n",
              "1676                        0.0                0.0 -10.000000  -10.000000   \n",
              "1676                        0.0                0.0 -10.000000  -10.000000   \n",
              "1676                        0.0                0.0 -10.000000  -10.000000   \n",
              "1676                        0.0                0.0 -10.000000  -10.000000   \n",
              "1676                        0.0                0.0 -10.000000  -10.000000   \n",
              "1676                        0.0                0.0 -10.000000  -10.000000   \n",
              "1676                        0.0                0.0 -10.000000  -10.000000   \n",
              "1676                        0.0                0.0 -10.000000  -10.000000   \n",
              "1676                        0.0                0.0 -10.000000  -10.000000   \n",
              "1676                        0.0                0.0 -10.000000  -10.000000   \n",
              "1676                        0.0                0.0 -10.000000  -10.000000   \n",
              "1676                        0.0                0.0 -10.000000  -10.000000   \n",
              "1676                        0.0                0.0 -10.000000  -10.000000   \n",
              "1676                        0.0                0.0 -10.000000  -10.000000   \n",
              "1676                        0.0                0.0 -10.000000  -10.000000   \n",
              "1676                        0.0                0.0 -10.000000  -10.000000   \n",
              "248                         1.0                1.0  54.442425  135.037140   \n",
              "248                         0.0                0.0  51.762115   99.159889   \n",
              "248                         0.0                0.0  51.296329  101.607071   \n",
              "248                         0.0                0.0  42.504478   42.667797   \n",
              "248                         0.0                0.0 -10.000000  -10.000000   \n",
              "248                         0.0                0.0 -10.000000  -10.000000   \n",
              "248                         0.0                0.0 -10.000000  -10.000000   \n",
              "248                         0.0                0.0 -10.000000  -10.000000   \n",
              "248                         0.0                0.0 -10.000000  -10.000000   \n",
              "248                         0.0                0.0 -10.000000  -10.000000   \n",
              "248                         0.0                0.0 -10.000000  -10.000000   \n",
              "248                         0.0                0.0 -10.000000  -10.000000   \n",
              "\n",
              "         met_pt    met_phi  muons_eta  muons_phi  electrons_eta  \\\n",
              "1051   3.806244  -2.233869   1.741230  -1.789123     -10.000000   \n",
              "1051 -10.000000 -10.000000  -0.598831   1.321169     -10.000000   \n",
              "1051 -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "1051 -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "1051 -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "1051 -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "1051 -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "1051 -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "1051 -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "1051 -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "1051 -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "1051 -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "1051 -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "1051 -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "1051 -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "1051 -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "1051 -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "1051 -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "1051 -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "1676  15.534855  -0.819230 -10.000000 -10.000000      -0.653031   \n",
              "1676 -10.000000 -10.000000 -10.000000 -10.000000       1.380940   \n",
              "1676 -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "1676 -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "1676 -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "1676 -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "1676 -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "1676 -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "1676 -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "1676 -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "1676 -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "1676 -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "1676 -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "1676 -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "1676 -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "1676 -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "1676 -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "1676 -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "1676 -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "248   41.181572  -0.065052  -1.232911  -2.819821      -0.070456   \n",
              "248  -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "248  -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "248  -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "248  -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "248  -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "248  -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "248  -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "248  -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "248  -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "248  -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "248  -10.000000 -10.000000 -10.000000 -10.000000     -10.000000   \n",
              "\n",
              "      electrons_phi   jets_eta   jets_phi  top_label  target  \n",
              "1051     -10.000000   1.741230  -1.789123          1     0.0  \n",
              "1051     -10.000000  -0.598831   1.321169          1     0.0  \n",
              "1051     -10.000000 -10.000000 -10.000000          1     0.0  \n",
              "1051     -10.000000 -10.000000 -10.000000          1     0.0  \n",
              "1051     -10.000000 -10.000000 -10.000000          1     0.0  \n",
              "1051     -10.000000 -10.000000 -10.000000          1     0.0  \n",
              "1051     -10.000000 -10.000000 -10.000000          1     0.0  \n",
              "1051     -10.000000 -10.000000 -10.000000          1     0.0  \n",
              "1051     -10.000000 -10.000000 -10.000000          1     0.0  \n",
              "1051     -10.000000 -10.000000 -10.000000          1     0.0  \n",
              "1051     -10.000000 -10.000000 -10.000000          1     0.0  \n",
              "1051     -10.000000 -10.000000 -10.000000          1     0.0  \n",
              "1051     -10.000000 -10.000000 -10.000000          1     0.0  \n",
              "1051     -10.000000 -10.000000 -10.000000          1     0.0  \n",
              "1051     -10.000000 -10.000000 -10.000000          1     0.0  \n",
              "1051     -10.000000 -10.000000 -10.000000          1     0.0  \n",
              "1051     -10.000000 -10.000000 -10.000000          1     0.0  \n",
              "1051     -10.000000 -10.000000 -10.000000          1     0.0  \n",
              "1051     -10.000000 -10.000000 -10.000000          1     0.0  \n",
              "1676      -2.966456  -0.694681  -2.960791          1     0.0  \n",
              "1676       0.199553   1.371609   0.211122          1     0.0  \n",
              "1676     -10.000000 -10.000000 -10.000000          1     0.0  \n",
              "1676     -10.000000 -10.000000 -10.000000          1     0.0  \n",
              "1676     -10.000000 -10.000000 -10.000000          1     0.0  \n",
              "1676     -10.000000 -10.000000 -10.000000          1     0.0  \n",
              "1676     -10.000000 -10.000000 -10.000000          1     0.0  \n",
              "1676     -10.000000 -10.000000 -10.000000          1     0.0  \n",
              "1676     -10.000000 -10.000000 -10.000000          1     0.0  \n",
              "1676     -10.000000 -10.000000 -10.000000          1     0.0  \n",
              "1676     -10.000000 -10.000000 -10.000000          1     0.0  \n",
              "1676     -10.000000 -10.000000 -10.000000          1     0.0  \n",
              "1676     -10.000000 -10.000000 -10.000000          1     0.0  \n",
              "1676     -10.000000 -10.000000 -10.000000          1     0.0  \n",
              "1676     -10.000000 -10.000000 -10.000000          1     0.0  \n",
              "1676     -10.000000 -10.000000 -10.000000          1     0.0  \n",
              "1676     -10.000000 -10.000000 -10.000000          1     0.0  \n",
              "1676     -10.000000 -10.000000 -10.000000          1     0.0  \n",
              "1676     -10.000000 -10.000000 -10.000000          1     0.0  \n",
              "248       -2.949490  -1.555142  -0.780664          1     1.0  \n",
              "248      -10.000000  -1.263992  -2.808602          1     1.0  \n",
              "248      -10.000000  -1.300499   1.498806          1     1.0  \n",
              "248      -10.000000  -0.069875  -2.953954          1     1.0  \n",
              "248      -10.000000 -10.000000 -10.000000          1     1.0  \n",
              "248      -10.000000 -10.000000 -10.000000          1     1.0  \n",
              "248      -10.000000 -10.000000 -10.000000          1     1.0  \n",
              "248      -10.000000 -10.000000 -10.000000          1     1.0  \n",
              "248      -10.000000 -10.000000 -10.000000          1     1.0  \n",
              "248      -10.000000 -10.000000 -10.000000          1     1.0  \n",
              "248      -10.000000 -10.000000 -10.000000          1     1.0  \n",
              "248      -10.000000 -10.000000 -10.000000          1     1.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2d654eb0-37c9-44b0-b1de-ae46ae15d6ba\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>muons_pt</th>\n",
              "      <th>muons_e</th>\n",
              "      <th>electrons_pt</th>\n",
              "      <th>electrons_e</th>\n",
              "      <th>electrons_isTightElectron</th>\n",
              "      <th>muons_isTightMuon</th>\n",
              "      <th>jets_pt</th>\n",
              "      <th>jets_e</th>\n",
              "      <th>met_pt</th>\n",
              "      <th>met_phi</th>\n",
              "      <th>muons_eta</th>\n",
              "      <th>muons_phi</th>\n",
              "      <th>electrons_eta</th>\n",
              "      <th>electrons_phi</th>\n",
              "      <th>jets_eta</th>\n",
              "      <th>jets_phi</th>\n",
              "      <th>top_label</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1051</th>\n",
              "      <td>27.620361</td>\n",
              "      <td>81.199272</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>27.620361</td>\n",
              "      <td>81.199272</td>\n",
              "      <td>3.806244</td>\n",
              "      <td>-2.233869</td>\n",
              "      <td>1.741230</td>\n",
              "      <td>-1.789123</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1.741230</td>\n",
              "      <td>-1.789123</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1051</th>\n",
              "      <td>23.156866</td>\n",
              "      <td>27.434654</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>23.156866</td>\n",
              "      <td>27.434654</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-0.598831</td>\n",
              "      <td>1.321169</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-0.598831</td>\n",
              "      <td>1.321169</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1051</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1051</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1051</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1051</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1051</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1051</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1051</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1051</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1051</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1051</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1051</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1051</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1051</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1051</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1051</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1051</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1051</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1676</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>29.631136</td>\n",
              "      <td>36.176971</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>46.530571</td>\n",
              "      <td>58.499062</td>\n",
              "      <td>15.534855</td>\n",
              "      <td>-0.819230</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-0.653031</td>\n",
              "      <td>-2.966456</td>\n",
              "      <td>-0.694681</td>\n",
              "      <td>-2.960791</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1676</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>29.960835</td>\n",
              "      <td>63.366901</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>33.505123</td>\n",
              "      <td>70.467567</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1.380940</td>\n",
              "      <td>0.199553</td>\n",
              "      <td>1.371609</td>\n",
              "      <td>0.211122</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1676</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1676</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1676</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1676</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1676</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1676</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1676</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1676</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1676</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1676</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1676</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1676</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1676</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1676</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1676</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1676</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1676</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>47.655804</td>\n",
              "      <td>88.702911</td>\n",
              "      <td>42.209152</td>\n",
              "      <td>42.313957</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>54.442425</td>\n",
              "      <td>135.037140</td>\n",
              "      <td>41.181572</td>\n",
              "      <td>-0.065052</td>\n",
              "      <td>-1.232911</td>\n",
              "      <td>-2.819821</td>\n",
              "      <td>-0.070456</td>\n",
              "      <td>-2.949490</td>\n",
              "      <td>-1.555142</td>\n",
              "      <td>-0.780664</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>51.762115</td>\n",
              "      <td>99.159889</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-1.263992</td>\n",
              "      <td>-2.808602</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>51.296329</td>\n",
              "      <td>101.607071</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-1.300499</td>\n",
              "      <td>1.498806</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>42.504478</td>\n",
              "      <td>42.667797</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-0.069875</td>\n",
              "      <td>-2.953954</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d654eb0-37c9-44b0-b1de-ae46ae15d6ba')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2d654eb0-37c9-44b0-b1de-ae46ae15d6ba button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2d654eb0-37c9-44b0-b1de-ae46ae15d6ba');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "tot_df.head(50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cj58rgImijmZ"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXWmF3tcWBlA"
      },
      "outputs": [],
      "source": [
        "tot_df = pd.read_csv('tot_df_2.csv')\n",
        "# tot_df['Unnamed: 0']\n",
        "tot_df.index = tot_df['Unnamed: 0']\n",
        "tot_df = tot_df.drop(['Unnamed: 0'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vznkGBh4Brrr"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.layers.core import Activation\n",
        "import keras.backend as K\n",
        "from keras.layers import Dense, LSTM, Dropout, Masking, Bidirectional\n",
        "from keras.models import Sequential, load_model, Model, Input\n",
        "from tensorflow.keras.optimizers import Adam,SGD\n",
        "import tensorflow.keras.losses as loss\n",
        "from tensorflow.keras.metrics import Recall, Precision, AUC\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgxXYmjSFNZM"
      },
      "outputs": [],
      "source": [
        "def shape_sequence(arr, step):\n",
        "  '''\n",
        "  questa funzione prende in input il dataset (arr),\n",
        "  il numero massimo di particelle in un evento (step)\n",
        "  e l'indice da cui comincia la ricerca (start = 0)\n",
        "  '''\n",
        "  #track=[]\n",
        "  start = 0\n",
        "  out = list()\n",
        "  for i in range(start, arr.shape[0], max_n_slot):\n",
        "      low_lim = i\n",
        "      up_lim = low_lim + step\n",
        "      out.append(arr[low_lim: up_lim])\n",
        "      # print(arr[low_lim: up_lim])\n",
        "\n",
        "      if up_lim == arr.shape[0]: # condizione sull'ultimo evento\n",
        "        break\n",
        "\n",
        "\n",
        "  out_seq = np.array(out)\n",
        "\n",
        "  return out_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "by3KnML3DE6x"
      },
      "outputs": [],
      "source": [
        "# trasformo il dataframe in lista\n",
        "x_col = list(tot_df.columns)\n",
        "\n",
        "# rimuovo la colonna della variabile target\n",
        "x_col.remove('target')\n",
        "x_col.remove('electrons_isTightElectron')\n",
        "x_col.remove('muons_isTightMuon')\n",
        "# x_col.remove('met_pt')\n",
        "# x_col.remove('met_phi')\n",
        "# x_col.remove('jets_pt')\n",
        "# x_col.remove('jets_eta')\n",
        "# x_col.remove('jets_phi')\n",
        "\n",
        "x_col.remove('top_label')\n",
        "X = tot_df[x_col].values\n",
        "\n",
        "# definisco la colonna della variabile target\n",
        "y = tot_df['target'].values\n",
        "\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# std = StandardScaler()\n",
        "# X = std.fit_transform(X)\n",
        "\n",
        "# preprocessing per LSTM\n",
        "X= shape_sequence(X, 4)\n",
        "y= shape_sequence(y, 4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtBZpsSEJz8-"
      },
      "outputs": [],
      "source": [
        "# splitto il dataset in training e test set\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeJ8IQvj5e7n",
        "outputId": "dbce905a-ec5c-4290-b259-b2a3275d6752"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "51/51 - 5s - loss: 0.5410 - accuracy: 0.6325 - val_loss: 0.4425 - val_accuracy: 0.8494 - lr: 0.0100 - 5s/epoch - 105ms/step\n",
            "Epoch 2/15\n",
            "51/51 - 0s - loss: 0.4025 - accuracy: 0.8826 - val_loss: 0.3759 - val_accuracy: 0.8914 - lr: 0.0100 - 354ms/epoch - 7ms/step\n",
            "Epoch 3/15\n",
            "51/51 - 0s - loss: 0.3521 - accuracy: 0.8894 - val_loss: 0.3373 - val_accuracy: 0.8914 - lr: 0.0100 - 339ms/epoch - 7ms/step\n",
            "Epoch 4/15\n",
            "51/51 - 0s - loss: 0.3232 - accuracy: 0.8975 - val_loss: 0.3103 - val_accuracy: 0.9037 - lr: 0.0100 - 304ms/epoch - 6ms/step\n",
            "Epoch 5/15\n",
            "51/51 - 0s - loss: 0.2962 - accuracy: 0.9074 - val_loss: 0.2813 - val_accuracy: 0.9136 - lr: 0.0100 - 302ms/epoch - 6ms/step\n",
            "Epoch 6/15\n",
            "51/51 - 0s - loss: 0.2696 - accuracy: 0.9135 - val_loss: 0.2555 - val_accuracy: 0.9284 - lr: 0.0100 - 308ms/epoch - 6ms/step\n",
            "Epoch 7/15\n",
            "51/51 - 0s - loss: 0.2576 - accuracy: 0.9240 - val_loss: 0.2332 - val_accuracy: 0.9358 - lr: 0.0100 - 307ms/epoch - 6ms/step\n",
            "Epoch 8/15\n",
            "51/51 - 0s - loss: 0.2426 - accuracy: 0.9209 - val_loss: 0.2251 - val_accuracy: 0.9333 - lr: 0.0100 - 302ms/epoch - 6ms/step\n",
            "Epoch 9/15\n",
            "51/51 - 0s - loss: 0.2284 - accuracy: 0.9333 - val_loss: 0.2068 - val_accuracy: 0.9481 - lr: 0.0100 - 325ms/epoch - 6ms/step\n",
            "Epoch 10/15\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "51/51 - 0s - loss: 0.2436 - accuracy: 0.9339 - val_loss: 0.1738 - val_accuracy: 0.9383 - lr: 0.0100 - 306ms/epoch - 6ms/step\n",
            "Epoch 11/15\n",
            "51/51 - 0s - loss: 0.2277 - accuracy: 0.9351 - val_loss: 0.2023 - val_accuracy: 0.9506 - lr: 1.0000e-03 - 338ms/epoch - 7ms/step\n",
            "Epoch 12/15\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "51/51 - 0s - loss: 0.2331 - accuracy: 0.9419 - val_loss: 0.1984 - val_accuracy: 0.9531 - lr: 1.0000e-03 - 321ms/epoch - 6ms/step\n",
            "Epoch 13/15\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "51/51 - 0s - loss: 0.2312 - accuracy: 0.9413 - val_loss: 0.1984 - val_accuracy: 0.9531 - lr: 1.0000e-04 - 341ms/epoch - 7ms/step\n",
            "Epoch 14/15\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
            "51/51 - 0s - loss: 0.2310 - accuracy: 0.9419 - val_loss: 0.1984 - val_accuracy: 0.9531 - lr: 1.0000e-05 - 308ms/epoch - 6ms/step\n",
            "Epoch 15/15\n",
            "\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "51/51 - 0s - loss: 0.2310 - accuracy: 0.9419 - val_loss: 0.1984 - val_accuracy: 0.9531 - lr: 1.0000e-06 - 312ms/epoch - 6ms/step\n"
          ]
        }
      ],
      "source": [
        "def create_model(X_train, y_train):\n",
        "\n",
        "  shape = X_train.shape[1] # dimensione dell'evento\n",
        "  feat_length = X_train.shape[2] # numero di features\n",
        "  numberOfLSTMunits = 1\n",
        "\n",
        "  input = Input(shape=(shape, feat_length))\n",
        "  state_h_0 = LSTM(shape*3, return_sequences=True) (input)\n",
        "  # state_h = LSTM(shape*2, return_sequences=True) (state_h_0)\n",
        "  state_h = Dense(shape, activation='tanh') (state_h_0)\n",
        "  state_h_2 = LSTM(numberOfLSTMunits) (state_h)\n",
        "  # state_h_3 = Dense(1, activation='relu') (state_h_2)\n",
        "  model = Model(inputs=input, outputs=state_h_2)\n",
        "  model.summary()\n",
        "  opt=SGD()\n",
        "  model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "model_666 = create_model(X_train, y_train)\n",
        "# mcp_save = ModelCheckpoint('/content', save_best_only=True, monitor='accuracy', mode='min')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=1, min_lr=1e-7, verbose=1)\n",
        "history = model_666.fit(X_train, y_train, epochs=15, verbose=2, validation_data=(X_test, y_test), callbacks=[reduce_lr])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoyTo-u4GYu4"
      },
      "outputs": [],
      "source": [
        "def reduce_Y(y):\n",
        "  one_y = []\n",
        "  for i in y:\n",
        "    one_y.append(i[0])\n",
        "  return np.array(one_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSnzcTtw0UWP"
      },
      "outputs": [],
      "source": [
        "def count_label(d_set):\n",
        "  count_0 = 0\n",
        "  count_1 = 0\n",
        "  for i in d_set:\n",
        "    if i[0]==0:\n",
        "      count_0 = count_0 + 1\n",
        "    else:\n",
        "      count_1 = count_1 + 1\n",
        "  print('fondo: ', count_0)\n",
        "  print('segnale ', count_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKnV3G4PtDKR"
      },
      "outputs": [],
      "source": [
        "# shape = X_train.shape[1] # dimensione dell'evento\n",
        "# feat_length = X_train.shape[2] # numero di features\n",
        "\n",
        "# model_1 = Sequential()\n",
        "# # model_1.add(Masking(mask_value=-10, input_shape=(shape, feat_length)))\n",
        "# model_1.add(model)\n",
        "# model_1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, min_lr=1e-7, verbose=1)\n",
        "# # mcp_save = ModelCheckpoint('/content', save_best_only=True, monitor='accuracy', mode='min')\n",
        "# history_1 = model.fit(X_train, y_train, epochs=15, verbose=2, validation_data=(X_test, y_test),steps_per_epoch=15, callbacks=[reduce_lr])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uoPRcFr-PMoc"
      },
      "outputs": [],
      "source": [
        "y_test = reduce_Y(y_test)\n",
        "y_train = reduce_Y(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORPpyi0Dlegd"
      },
      "outputs": [],
      "source": [
        "y_pred = model_666.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8Px56haVxA8"
      },
      "outputs": [],
      "source": [
        "# Definizione fondo e segnale\n",
        "\n",
        "d0 = model_666.predict(X_train[np.where(y_train>0.5)])\n",
        "d1 = model_666.predict(X_train[np.where(y_train<0.5)])\n",
        "\n",
        "d2 = model_666.predict(X_test[np.where(y_test>0.5)])\n",
        "d3 = model_666.predict(X_test[np.where(y_test<0.5)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "VvvzGqQkVr6q",
        "outputId": "d88890ad-e76c-42ca-8a76-853bcb11b0fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fc64386ed50>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plot fondo e segnale\n",
        "fig, ax = plt.subplots()\n",
        "ax.hist(d0, color='r', alpha=0.5, range=(0,1), bins=30, histtype='stepfilled', label='Signal (t\\\n",
        "rain)')\n",
        "ax.hist(d1, color='b', alpha=0.5, range=(0,1), bins=30, histtype='stepfilled', label='Backgroun\\\n",
        "d (train)')\n",
        "hist, bins = np.histogram(d2, bins=30, range=(0,1))\n",
        "scale = len(d2) / sum(hist)\n",
        "err = np.sqrt(hist * scale) / scale\n",
        "center = (bins[:-1] + bins[1:]) / 2\n",
        "ax.errorbar(center, hist, yerr=err, fmt='o', c='r', label='Signal (test)')\n",
        "hist, bins = np.histogram(d3, bins=30, range=(0,1))\n",
        "scale = len(d3) / sum(hist)\n",
        "err = np.sqrt(hist * scale) / scale\n",
        "ax.errorbar(center, hist, yerr=err, fmt='o', c='b', label='Background (test)')\n",
        "ax.set_xlabel(\"Output\")\n",
        "ax.set_ylabel(\"Arbitrary units\")\n",
        "# ax.set_title()\n",
        "ax.legend(loc='best')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hGE5JT-tKYL"
      },
      "outputs": [],
      "source": [
        "y_pred_ = []\n",
        "for i in list(y_pred):\n",
        "  if i<0.5 and i>-0.2:\n",
        "    y_pred_.append(0)\n",
        "  else:\n",
        "    y_pred_.append(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVVRlW_7rqMi"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "confusion_matrix=confusion_matrix(y_test, y_pred_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "sWq9IlDr2Hy7",
        "outputId": "c5d25983-048f-4cb6-80b0-dcf786f28664"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix)\n",
        "\n",
        "disp.plot(cmap=plt.cm.Greens)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "HxE8-AJoVYW1",
        "outputId": "faf837a3-95f2-4d01-f818-70b8098687af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fc64324c950>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Roc\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "roc_auc = auc(fpr,tpr)\n",
        "\n",
        "# Roc plot\n",
        "fig_roc, ax_roc = plt.subplots(figsize=(7, 5))\n",
        "ax_roc.plot(fpr, tpr, lw=2, color='purple',label='full training (auc = %.3f)' % (roc_auc))\n",
        "ax_roc.plot([0, 1], [0, 1], linestyle='--', lw=2, color='k', label='random chance')\n",
        "ax_roc.set_xlim([0, 1.0])\n",
        "ax_roc.set_ylim([0, 1.0])\n",
        "ax_roc.set_xlabel('false positive rate')\n",
        "ax_roc.set_ylabel('true positive rate')\n",
        "ax_roc.set_title('Receiver Operating Curve')\n",
        "ax_roc.grid(True)\n",
        "ax_roc.legend()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIrZTFr7KnW5"
      },
      "outputs": [],
      "source": [
        "y_pred_1 = []\n",
        "for i in y_pred:\n",
        "  if i<0.4 and i>-0.1:\n",
        "    y_pred_1.append(0)\n",
        "  else:\n",
        "    y_pred_1.append(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyPArIAppCAt"
      },
      "outputs": [],
      "source": [
        "def accuracy_between_lists(listtrue,listpred):\n",
        "  count=0\n",
        "  for i in range(len(listtrue)):\n",
        "    if listtrue[i]==listpred[i]:\n",
        "      count=count+1\n",
        "  score=count/len(listtrue)\n",
        "  return score\n",
        "\n",
        "# accuracy_between_lists(y_test_1, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBkmARPtrqhZ"
      },
      "outputs": [],
      "source": [
        "def round_list(list):\n",
        "  for i in range(len(list)):\n",
        "    if list[i]>=0.5:\n",
        "      list[i]=1.0\n",
        "    else:\n",
        "      list[i]=0.0\n",
        "  return list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVlMcWurxgFI"
      },
      "outputs": [],
      "source": [
        "# y_pred_model1=model1.predict(X_test)\n",
        "# y_pred_model1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OQd-tXvZiom",
        "outputId": "9d8f75d2-b600-4bac-c728-915eb85f5c27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 - 1s - loss: 0.1984 - accuracy: 0.9531 - 937ms/epoch - 72ms/step\n",
            "Accuracy: 95.31%\n"
          ]
        }
      ],
      "source": [
        "scores = model_666.evaluate(X_test, y_test, verbose=2)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ag0lyGWq0sxW"
      },
      "outputs": [],
      "source": [
        "def lstm_test_evaluation_graphs(history):\n",
        "    # summarize history for accuracy\n",
        "    fig_acc = plt.figure(figsize=(10, 10))\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()\n",
        "    # fig_acc.savefig(\"model_accuracy.png\")\n",
        "\n",
        "    # summarize history for Loss\n",
        "    fig_acc = plt.figure(figsize=(10, 10))\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()\n",
        "    # fig_acc.savefig(\"model_regression_loss.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6ApCO4djMEHH",
        "outputId": "0f53e61f-342f-446b-af96-a58eff00f3be"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "lstm_test_evaluation_graphs(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gbcy6sLbJMXK"
      },
      "source": [
        "# **Genetic Algorithm**: ☯"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O56hca8rJRtq",
        "outputId": "ca20e992-e459-4ac3-b69e-5f203d935082"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: deap in /usr/local/lib/python3.7/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deap) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install deap\n",
        "from deap import base\n",
        "from deap import creator\n",
        "from deap import tools\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YEh1F0NK__X"
      },
      "source": [
        "Individual creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGTYQa_8KfkJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d68ae9b7-10a1-44da-973b-4864757b4ec7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/deap/creator.py:141: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
            "  RuntimeWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/deap/creator.py:141: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
            "  RuntimeWarning)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "toolbox=base.Toolbox()\n",
        "toolbox.register(\"attr\", random.randint, 0, 3)\n",
        "\n",
        "\n",
        "toolbox.register(\"individual\", tools.initRepeat, creator.Individual,\n",
        "                 toolbox.attr,7)\n",
        "\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hECuHpIULLzE"
      },
      "source": [
        "Fitness function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVTSQnfRLNmm"
      },
      "outputs": [],
      "source": [
        "# global tot_df\n",
        "\n",
        "def EvaluateFeatures(individual):\n",
        "  tot_df = pd.read_csv('tot_df_2.csv')\n",
        "  # tot_df['Unnamed: 0']\n",
        "  tot_df.index = tot_df['Unnamed: 0']\n",
        "  tot_df = tot_df.drop(['Unnamed: 0'], axis=1)\n",
        "  #shuffle sul dataframe\n",
        "  index_list = list(np.array(list(range(int(tot_df.shape[0]/max_n_slot))))) # creo la lista degli indici\n",
        "  np.random.shuffle(index_list) # shuffle non ritorna niente, agisce su index_list\n",
        "\n",
        "  tot_df = tot_df.loc[index_list]\n",
        "\n",
        "  x_col = list(tot_df.columns)\n",
        "\n",
        "  # rimuovo la colonna della variabile target\n",
        "  x_col.remove('target')\n",
        "  x_col.remove('electrons_isTightElectron')\n",
        "  x_col.remove('muons_isTightMuon')\n",
        "  x_col.remove('top_label')\n",
        "  X = tot_df[x_col].values\n",
        "\n",
        "  # definisco la colonna della variabile target\n",
        "  y = tot_df['target'].values\n",
        "\n",
        "  # preprocessing per LSTM\n",
        "  X= shape_sequence(X, 4)\n",
        "  y= shape_sequence(y, 4)\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=False)\n",
        "\n",
        "  model1=create_model(X_train,y_train)\n",
        "\n",
        "  shape=X_train.shape[1]\n",
        "  feat_length=X_train.shape[2]\n",
        "\n",
        "#l'individuo sarà una lista di 6 componenti fatta di numeri random da 0 a 4\n",
        "#per esempio l'individuo: [0,0,0,0,0,0] corrisponde a scegliere\n",
        "#[1,sigmoid,sigmoid,LSTM(feat_length),0,5]\n",
        "\n",
        "#la struttura generale dell'individuo è quindi:\n",
        "#[n_layers,activation,rec_activation,layers,semifinal_layer,number_epochs]\n",
        "  lista_of_activation=['sigmoid','tanh','softmax','relu']  #individual[0]\n",
        "  lista_first_condition=[0,0,1,1] #individual[1]\n",
        "  lista_second_condition=[0,1,2,3] #individual[2]\n",
        "  lista_condizione_finale=[0,0,1,1] #individual[3]\n",
        "  lista_interi_m=[1,2,3,4] #individual[4]\n",
        "  lista_interi_n=[1,2,3,4] #individual[5]\n",
        "  list_number_of_epochs=[10,15,20,25] #individual[6]\n",
        "\n",
        "  input = Input(shape=(shape, feat_length))\n",
        "  if lista_first_condition[individual[1]] == 1:\n",
        "    if lista_second_condition[individual[2]]==0:\n",
        "      state_h_0 = LSTM(shape*lista_interi_m[individual[4]], return_sequences=True) (input)\n",
        "      state_h = LSTM(shape*lista_interi_n[individual[5]], return_sequences=True) (state_h_0)\n",
        "    elif lista_second_condition[individual[2]]==1:\n",
        "      state_h_0 = Dense(shape*lista_interi_m[individual[4]], activation=lista_of_activation[individual[0]]) (input)\n",
        "      state_h = Dense(shape*lista_interi_n[individual[5]], activation=lista_of_activation[individual[0]]) (state_h_0)\n",
        "    elif lista_second_condition[individual[2]]==2:\n",
        "      state_h_0 = LSTM(shape*lista_interi_m[individual[4]], return_sequences=True) (input)\n",
        "      state_h = Dense(shape*lista_interi_n[individual[5]], activation=lista_of_activation[individual[0]]) (state_h_0)\n",
        "    elif lista_second_condition[individual[2]]==3:\n",
        "      state_h_0 = Dense(shape*lista_interi_m[individual[4]], activation=lista_of_activation[individual[0]]) (input)\n",
        "      state_h = LSTM(shape*lista_interi_m[individual[4]], return_sequences=True) (state_h_0)\n",
        "  else:\n",
        "    if lista_condizione_finale[individual[3]]==0:\n",
        "      state_h = LSTM(shape*lista_interi_n[individual[5]], return_sequences=True) (input)\n",
        "    else:\n",
        "      state_h = Dense(shape*lista_interi_n[individual[5]], activation=lista_of_activation[individual[0]]) (input)\n",
        "\n",
        "  state_h_2 = LSTM(1) (state_h)\n",
        "  model = Model(inputs=input, outputs=state_h_2)\n",
        "\n",
        "  reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=1, min_lr=1e-7, verbose=2)\n",
        "  opt=SGD(lr=0.01)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "  model.fit(X_train, y_train, epochs=list_number_of_epochs[individual[5]], validation_data=(X_test, y_test), callbacks=[reduce_lr], verbose=2)\n",
        "  score = model.evaluate(X_test, y_test)\n",
        "  return (score[1],)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2vIg0Ntdr0q"
      },
      "outputs": [],
      "source": [
        "toolbox.register(\"evaluate\", EvaluateFeatures)\n",
        "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
        "toolbox.register(\"mutate\", tools.mutUniformInt,low=0,up=3, indpb=0.2)\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "\n",
        "stats = tools.Statistics(key=lambda ind: ind.fitness.values)\n",
        "stats.register(\"avg\", np.mean)\n",
        "stats.register(\"std\", np.std)\n",
        "stats.register(\"min\", np.min)\n",
        "stats.register(\"max\", np.max)\n",
        "\n",
        "logbook=tools.Logbook()\n",
        "random.seed(69)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bE74sNL5ex1t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "58e7bf79-f077-4b52-d416-d3c5ceab5a6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start of evolution\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mOutput streaming troncato alle ultime 5000 righe.\u001b[0m\n",
            "Epoch 24/25\n",
            "45/45 - 0s - loss: 0.5903 - accuracy: 0.5565 - val_loss: 0.5937 - val_accuracy: 0.5691 - lr: 1.0000e-07 - 377ms/epoch - 8ms/step\n",
            "Epoch 25/25\n",
            "45/45 - 0s - loss: 0.5903 - accuracy: 0.5565 - val_loss: 0.5937 - val_accuracy: 0.5691 - lr: 1.0000e-07 - 385ms/epoch - 9ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.5937 - accuracy: 0.5691\n",
            "Model: \"model_189\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_190 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_385 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_137 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_386 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "45/45 - 5s - loss: 0.8062 - accuracy: 0.5240 - val_loss: 0.5777 - val_accuracy: 0.5576 - lr: 0.0100 - 5s/epoch - 102ms/step\n",
            "Epoch 2/25\n",
            "45/45 - 0s - loss: 0.5150 - accuracy: 0.6674 - val_loss: 0.5143 - val_accuracy: 0.8832 - lr: 0.0100 - 326ms/epoch - 7ms/step\n",
            "Epoch 3/25\n",
            "45/45 - 0s - loss: 0.4518 - accuracy: 0.8785 - val_loss: 0.4717 - val_accuracy: 0.8816 - lr: 0.0100 - 314ms/epoch - 7ms/step\n",
            "Epoch 4/25\n",
            "45/45 - 0s - loss: 0.4050 - accuracy: 0.8757 - val_loss: 0.4336 - val_accuracy: 0.8816 - lr: 0.0100 - 283ms/epoch - 6ms/step\n",
            "Epoch 5/25\n",
            "45/45 - 0s - loss: 0.3727 - accuracy: 0.8849 - val_loss: 0.4303 - val_accuracy: 0.8914 - lr: 0.0100 - 293ms/epoch - 7ms/step\n",
            "Epoch 6/25\n",
            "45/45 - 0s - loss: 0.3617 - accuracy: 0.8934 - val_loss: 0.4215 - val_accuracy: 0.8931 - lr: 0.0100 - 290ms/epoch - 6ms/step\n",
            "Epoch 7/25\n",
            "45/45 - 0s - loss: 0.3422 - accuracy: 0.8997 - val_loss: 0.3901 - val_accuracy: 0.8997 - lr: 0.0100 - 316ms/epoch - 7ms/step\n",
            "Epoch 8/25\n",
            "45/45 - 0s - loss: 0.3321 - accuracy: 0.9054 - val_loss: 0.4012 - val_accuracy: 0.9013 - lr: 0.0100 - 310ms/epoch - 7ms/step\n",
            "Epoch 9/25\n",
            "45/45 - 0s - loss: 0.3242 - accuracy: 0.8948 - val_loss: 0.3676 - val_accuracy: 0.9030 - lr: 0.0100 - 280ms/epoch - 6ms/step\n",
            "Epoch 10/25\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.3350 - accuracy: 0.8969 - val_loss: 0.3870 - val_accuracy: 0.9013 - lr: 0.0100 - 292ms/epoch - 6ms/step\n",
            "Epoch 11/25\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 0.3250 - accuracy: 0.8983 - val_loss: 0.3708 - val_accuracy: 0.8980 - lr: 1.0000e-03 - 290ms/epoch - 6ms/step\n",
            "Epoch 12/25\n",
            "45/45 - 0s - loss: 0.3227 - accuracy: 0.8962 - val_loss: 0.3706 - val_accuracy: 0.8980 - lr: 1.0000e-04 - 288ms/epoch - 6ms/step\n",
            "Epoch 13/25\n",
            "45/45 - 0s - loss: 0.3224 - accuracy: 0.8969 - val_loss: 0.3704 - val_accuracy: 0.8980 - lr: 1.0000e-04 - 306ms/epoch - 7ms/step\n",
            "Epoch 14/25\n",
            "45/45 - 0s - loss: 0.3222 - accuracy: 0.8969 - val_loss: 0.3703 - val_accuracy: 0.8980 - lr: 1.0000e-04 - 288ms/epoch - 6ms/step\n",
            "Epoch 15/25\n",
            "45/45 - 0s - loss: 0.3219 - accuracy: 0.8969 - val_loss: 0.3701 - val_accuracy: 0.8980 - lr: 1.0000e-04 - 276ms/epoch - 6ms/step\n",
            "Epoch 16/25\n",
            "45/45 - 0s - loss: 0.3217 - accuracy: 0.8969 - val_loss: 0.3700 - val_accuracy: 0.8980 - lr: 1.0000e-04 - 307ms/epoch - 7ms/step\n",
            "Epoch 17/25\n",
            "45/45 - 0s - loss: 0.3214 - accuracy: 0.8969 - val_loss: 0.3699 - val_accuracy: 0.8997 - lr: 1.0000e-04 - 278ms/epoch - 6ms/step\n",
            "Epoch 18/25\n",
            "45/45 - 0s - loss: 0.3212 - accuracy: 0.8969 - val_loss: 0.3699 - val_accuracy: 0.8997 - lr: 1.0000e-04 - 287ms/epoch - 6ms/step\n",
            "Epoch 19/25\n",
            "45/45 - 0s - loss: 0.3210 - accuracy: 0.8969 - val_loss: 0.3699 - val_accuracy: 0.8997 - lr: 1.0000e-04 - 306ms/epoch - 7ms/step\n",
            "Epoch 20/25\n",
            "45/45 - 0s - loss: 0.3208 - accuracy: 0.8969 - val_loss: 0.3699 - val_accuracy: 0.8980 - lr: 1.0000e-04 - 328ms/epoch - 7ms/step\n",
            "Epoch 21/25\n",
            "45/45 - 0s - loss: 0.3206 - accuracy: 0.8976 - val_loss: 0.3700 - val_accuracy: 0.8997 - lr: 1.0000e-04 - 321ms/epoch - 7ms/step\n",
            "Epoch 22/25\n",
            "45/45 - 0s - loss: 0.3203 - accuracy: 0.8969 - val_loss: 0.3701 - val_accuracy: 0.8997 - lr: 1.0000e-04 - 301ms/epoch - 7ms/step\n",
            "Epoch 23/25\n",
            "45/45 - 0s - loss: 0.3201 - accuracy: 0.8969 - val_loss: 0.3704 - val_accuracy: 0.8997 - lr: 1.0000e-04 - 331ms/epoch - 7ms/step\n",
            "Epoch 24/25\n",
            "45/45 - 0s - loss: 0.3199 - accuracy: 0.8969 - val_loss: 0.3710 - val_accuracy: 0.8997 - lr: 1.0000e-04 - 270ms/epoch - 6ms/step\n",
            "Epoch 25/25\n",
            "45/45 - 0s - loss: 0.3198 - accuracy: 0.8969 - val_loss: 0.3722 - val_accuracy: 0.8997 - lr: 1.0000e-04 - 271ms/epoch - 6ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3722 - accuracy: 0.8997\n",
            "Model: \"model_191\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_192 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_389 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_138 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_390 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "45/45 - 5s - loss: 0.6428 - accuracy: 0.6285 - val_loss: 0.5265 - val_accuracy: 0.7829 - lr: 0.0100 - 5s/epoch - 105ms/step\n",
            "Epoch 2/20\n",
            "45/45 - 0s - loss: 0.4636 - accuracy: 0.8277 - val_loss: 0.5245 - val_accuracy: 0.8618 - lr: 0.0100 - 284ms/epoch - 6ms/step\n",
            "Epoch 3/20\n",
            "45/45 - 0s - loss: 0.4560 - accuracy: 0.8771 - val_loss: 0.4333 - val_accuracy: 0.8618 - lr: 0.0100 - 302ms/epoch - 7ms/step\n",
            "Epoch 4/20\n",
            "45/45 - 0s - loss: 0.3913 - accuracy: 0.8905 - val_loss: 0.4015 - val_accuracy: 0.8701 - lr: 0.0100 - 319ms/epoch - 7ms/step\n",
            "Epoch 5/20\n",
            "45/45 - 0s - loss: 0.3499 - accuracy: 0.8898 - val_loss: 0.3572 - val_accuracy: 0.8750 - lr: 0.0100 - 305ms/epoch - 7ms/step\n",
            "Epoch 6/20\n",
            "45/45 - 0s - loss: 0.3372 - accuracy: 0.8983 - val_loss: 0.3462 - val_accuracy: 0.8783 - lr: 0.0100 - 279ms/epoch - 6ms/step\n",
            "Epoch 7/20\n",
            "45/45 - 0s - loss: 0.3209 - accuracy: 0.9089 - val_loss: 0.3865 - val_accuracy: 0.8684 - lr: 0.0100 - 324ms/epoch - 7ms/step\n",
            "Epoch 8/20\n",
            "45/45 - 0s - loss: 0.3199 - accuracy: 0.9068 - val_loss: 0.3487 - val_accuracy: 0.8816 - lr: 0.0100 - 284ms/epoch - 6ms/step\n",
            "Epoch 9/20\n",
            "45/45 - 0s - loss: 0.3062 - accuracy: 0.9117 - val_loss: 0.3382 - val_accuracy: 0.8849 - lr: 0.0100 - 304ms/epoch - 7ms/step\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.3081 - accuracy: 0.9089 - val_loss: 0.4013 - val_accuracy: 0.8832 - lr: 0.0100 - 337ms/epoch - 7ms/step\n",
            "Epoch 11/20\n",
            "45/45 - 0s - loss: 0.2936 - accuracy: 0.9188 - val_loss: 0.3514 - val_accuracy: 0.8882 - lr: 1.0000e-03 - 300ms/epoch - 7ms/step\n",
            "Epoch 12/20\n",
            "45/45 - 0s - loss: 0.2833 - accuracy: 0.9202 - val_loss: 0.3497 - val_accuracy: 0.8882 - lr: 1.0000e-03 - 310ms/epoch - 7ms/step\n",
            "Epoch 13/20\n",
            "45/45 - 0s - loss: 0.2813 - accuracy: 0.9202 - val_loss: 0.3501 - val_accuracy: 0.8898 - lr: 1.0000e-03 - 304ms/epoch - 7ms/step\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 0.2812 - accuracy: 0.9223 - val_loss: 0.3485 - val_accuracy: 0.8914 - lr: 1.0000e-03 - 312ms/epoch - 7ms/step\n",
            "Epoch 15/20\n",
            "45/45 - 0s - loss: 0.2789 - accuracy: 0.9223 - val_loss: 0.3486 - val_accuracy: 0.8914 - lr: 1.0000e-04 - 272ms/epoch - 6ms/step\n",
            "Epoch 16/20\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "45/45 - 0s - loss: 0.2788 - accuracy: 0.9223 - val_loss: 0.3487 - val_accuracy: 0.8914 - lr: 1.0000e-04 - 289ms/epoch - 6ms/step\n",
            "Epoch 17/20\n",
            "45/45 - 0s - loss: 0.2786 - accuracy: 0.9223 - val_loss: 0.3487 - val_accuracy: 0.8914 - lr: 1.0000e-05 - 299ms/epoch - 7ms/step\n",
            "Epoch 18/20\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
            "45/45 - 0s - loss: 0.2786 - accuracy: 0.9223 - val_loss: 0.3487 - val_accuracy: 0.8914 - lr: 1.0000e-05 - 294ms/epoch - 7ms/step\n",
            "Epoch 19/20\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "45/45 - 0s - loss: 0.2786 - accuracy: 0.9223 - val_loss: 0.3487 - val_accuracy: 0.8914 - lr: 1.0000e-06 - 293ms/epoch - 7ms/step\n",
            "Epoch 20/20\n",
            "45/45 - 0s - loss: 0.2786 - accuracy: 0.9223 - val_loss: 0.3487 - val_accuracy: 0.8914 - lr: 1.0000e-07 - 295ms/epoch - 7ms/step\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3487 - accuracy: 0.8914\n",
            "Model: \"model_193\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_194 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_393 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_139 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_394 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "45/45 - 5s - loss: 0.5610 - accuracy: 0.6914 - val_loss: 0.4231 - val_accuracy: 0.8651 - lr: 0.0100 - 5s/epoch - 105ms/step\n",
            "Epoch 2/25\n",
            "45/45 - 0s - loss: 0.4115 - accuracy: 0.8877 - val_loss: 0.3764 - val_accuracy: 0.8602 - lr: 0.0100 - 297ms/epoch - 7ms/step\n",
            "Epoch 3/25\n",
            "45/45 - 0s - loss: 0.3734 - accuracy: 0.8821 - val_loss: 0.3474 - val_accuracy: 0.8618 - lr: 0.0100 - 312ms/epoch - 7ms/step\n",
            "Epoch 4/25\n",
            "45/45 - 0s - loss: 0.3481 - accuracy: 0.8842 - val_loss: 0.3589 - val_accuracy: 0.8602 - lr: 0.0100 - 289ms/epoch - 6ms/step\n",
            "Epoch 5/25\n",
            "45/45 - 0s - loss: 0.3420 - accuracy: 0.8806 - val_loss: 0.3479 - val_accuracy: 0.8602 - lr: 0.0100 - 293ms/epoch - 7ms/step\n",
            "Epoch 6/25\n",
            "45/45 - 0s - loss: 0.3205 - accuracy: 0.8849 - val_loss: 0.4113 - val_accuracy: 0.8865 - lr: 0.0100 - 297ms/epoch - 7ms/step\n",
            "Epoch 7/25\n",
            "45/45 - 0s - loss: 0.3086 - accuracy: 0.8912 - val_loss: 0.3244 - val_accuracy: 0.8602 - lr: 0.0100 - 305ms/epoch - 7ms/step\n",
            "Epoch 8/25\n",
            "45/45 - 0s - loss: 0.2814 - accuracy: 0.8919 - val_loss: 0.2775 - val_accuracy: 0.8832 - lr: 0.0100 - 301ms/epoch - 7ms/step\n",
            "Epoch 9/25\n",
            "45/45 - 0s - loss: 0.2623 - accuracy: 0.9040 - val_loss: 0.3046 - val_accuracy: 0.8602 - lr: 0.0100 - 322ms/epoch - 7ms/step\n",
            "Epoch 10/25\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.2671 - accuracy: 0.8898 - val_loss: 0.2819 - val_accuracy: 0.8931 - lr: 0.0100 - 299ms/epoch - 7ms/step\n",
            "Epoch 11/25\n",
            "45/45 - 0s - loss: 0.2524 - accuracy: 0.9040 - val_loss: 0.2746 - val_accuracy: 0.8882 - lr: 1.0000e-03 - 308ms/epoch - 7ms/step\n",
            "Epoch 12/25\n",
            "45/45 - 0s - loss: 0.2469 - accuracy: 0.9040 - val_loss: 0.2729 - val_accuracy: 0.8865 - lr: 1.0000e-03 - 299ms/epoch - 7ms/step\n",
            "Epoch 13/25\n",
            "45/45 - 0s - loss: 0.2454 - accuracy: 0.9082 - val_loss: 0.2711 - val_accuracy: 0.8849 - lr: 1.0000e-03 - 304ms/epoch - 7ms/step\n",
            "Epoch 14/25\n",
            "45/45 - 0s - loss: 0.2434 - accuracy: 0.9089 - val_loss: 0.2706 - val_accuracy: 0.8849 - lr: 1.0000e-03 - 301ms/epoch - 7ms/step\n",
            "Epoch 15/25\n",
            "45/45 - 0s - loss: 0.2422 - accuracy: 0.9103 - val_loss: 0.2682 - val_accuracy: 0.8914 - lr: 1.0000e-03 - 313ms/epoch - 7ms/step\n",
            "Epoch 16/25\n",
            "45/45 - 0s - loss: 0.2407 - accuracy: 0.9103 - val_loss: 0.2672 - val_accuracy: 0.8865 - lr: 1.0000e-03 - 276ms/epoch - 6ms/step\n",
            "Epoch 17/25\n",
            "45/45 - 0s - loss: 0.2392 - accuracy: 0.9138 - val_loss: 0.2655 - val_accuracy: 0.8898 - lr: 1.0000e-03 - 296ms/epoch - 7ms/step\n",
            "Epoch 18/25\n",
            "45/45 - 0s - loss: 0.2373 - accuracy: 0.9145 - val_loss: 0.2629 - val_accuracy: 0.8964 - lr: 1.0000e-03 - 322ms/epoch - 7ms/step\n",
            "Epoch 19/25\n",
            "45/45 - 0s - loss: 0.2361 - accuracy: 0.9181 - val_loss: 0.2474 - val_accuracy: 0.8914 - lr: 1.0000e-03 - 319ms/epoch - 7ms/step\n",
            "Epoch 20/25\n",
            "45/45 - 0s - loss: 0.2350 - accuracy: 0.9153 - val_loss: 0.2421 - val_accuracy: 0.8964 - lr: 1.0000e-03 - 337ms/epoch - 7ms/step\n",
            "Epoch 21/25\n",
            "45/45 - 0s - loss: 0.2338 - accuracy: 0.9181 - val_loss: 0.2593 - val_accuracy: 0.9046 - lr: 1.0000e-03 - 326ms/epoch - 7ms/step\n",
            "Epoch 22/25\n",
            "45/45 - 0s - loss: 0.2325 - accuracy: 0.9188 - val_loss: 0.2587 - val_accuracy: 0.9013 - lr: 1.0000e-03 - 295ms/epoch - 7ms/step\n",
            "Epoch 23/25\n",
            "45/45 - 0s - loss: 0.2310 - accuracy: 0.9174 - val_loss: 0.2575 - val_accuracy: 0.9046 - lr: 1.0000e-03 - 327ms/epoch - 7ms/step\n",
            "Epoch 24/25\n",
            "45/45 - 0s - loss: 0.2294 - accuracy: 0.9202 - val_loss: 0.2395 - val_accuracy: 0.9013 - lr: 1.0000e-03 - 314ms/epoch - 7ms/step\n",
            "Epoch 25/25\n",
            "45/45 - 0s - loss: 0.2287 - accuracy: 0.9181 - val_loss: 0.2360 - val_accuracy: 0.8980 - lr: 1.0000e-03 - 295ms/epoch - 7ms/step\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2360 - accuracy: 0.8980\n",
            "Model: \"model_195\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_196 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_397 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_141 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_398 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "45/45 - 7s - loss: 0.8391 - accuracy: 0.5268 - val_loss: 0.7295 - val_accuracy: 0.5510 - lr: 0.0100 - 7s/epoch - 150ms/step\n",
            "Epoch 2/25\n",
            "45/45 - 0s - loss: 0.7204 - accuracy: 0.5268 - val_loss: 0.6781 - val_accuracy: 0.5510 - lr: 0.0100 - 393ms/epoch - 9ms/step\n",
            "Epoch 3/25\n",
            "45/45 - 0s - loss: 0.6775 - accuracy: 0.5268 - val_loss: 0.6454 - val_accuracy: 0.5510 - lr: 0.0100 - 382ms/epoch - 8ms/step\n",
            "Epoch 4/25\n",
            "45/45 - 0s - loss: 0.6447 - accuracy: 0.5268 - val_loss: 0.6162 - val_accuracy: 0.5510 - lr: 0.0100 - 384ms/epoch - 9ms/step\n",
            "Epoch 5/25\n",
            "45/45 - 0s - loss: 0.6110 - accuracy: 0.5268 - val_loss: 0.5800 - val_accuracy: 0.5510 - lr: 0.0100 - 367ms/epoch - 8ms/step\n",
            "Epoch 6/25\n",
            "45/45 - 0s - loss: 0.5737 - accuracy: 0.5268 - val_loss: 0.5355 - val_accuracy: 0.5510 - lr: 0.0100 - 395ms/epoch - 9ms/step\n",
            "Epoch 7/25\n",
            "45/45 - 0s - loss: 0.5382 - accuracy: 0.6045 - val_loss: 0.4893 - val_accuracy: 0.6612 - lr: 0.0100 - 395ms/epoch - 9ms/step\n",
            "Epoch 8/25\n",
            "45/45 - 0s - loss: 0.4926 - accuracy: 0.7535 - val_loss: 0.4465 - val_accuracy: 0.8141 - lr: 0.0100 - 404ms/epoch - 9ms/step\n",
            "Epoch 9/25\n",
            "45/45 - 0s - loss: 0.4590 - accuracy: 0.8482 - val_loss: 0.4183 - val_accuracy: 0.8651 - lr: 0.0100 - 368ms/epoch - 8ms/step\n",
            "Epoch 10/25\n",
            "45/45 - 0s - loss: 0.4313 - accuracy: 0.8736 - val_loss: 0.3893 - val_accuracy: 0.8849 - lr: 0.0100 - 396ms/epoch - 9ms/step\n",
            "Epoch 11/25\n",
            "45/45 - 0s - loss: 0.4038 - accuracy: 0.8891 - val_loss: 0.3595 - val_accuracy: 0.9112 - lr: 0.0100 - 377ms/epoch - 8ms/step\n",
            "Epoch 12/25\n",
            "45/45 - 0s - loss: 0.3887 - accuracy: 0.9004 - val_loss: 0.3423 - val_accuracy: 0.8947 - lr: 0.0100 - 401ms/epoch - 9ms/step\n",
            "Epoch 13/25\n",
            "45/45 - 0s - loss: 0.3656 - accuracy: 0.9025 - val_loss: 0.3188 - val_accuracy: 0.9013 - lr: 0.0100 - 395ms/epoch - 9ms/step\n",
            "Epoch 14/25\n",
            "45/45 - 0s - loss: 0.3486 - accuracy: 0.9061 - val_loss: 0.3264 - val_accuracy: 0.9145 - lr: 0.0100 - 356ms/epoch - 8ms/step\n",
            "Epoch 15/25\n",
            "45/45 - 0s - loss: 0.3393 - accuracy: 0.9011 - val_loss: 0.3021 - val_accuracy: 0.9013 - lr: 0.0100 - 370ms/epoch - 8ms/step\n",
            "Epoch 16/25\n",
            "45/45 - 0s - loss: 0.3261 - accuracy: 0.8919 - val_loss: 0.3067 - val_accuracy: 0.8602 - lr: 0.0100 - 374ms/epoch - 8ms/step\n",
            "Epoch 17/25\n",
            "45/45 - 0s - loss: 0.3257 - accuracy: 0.8686 - val_loss: 0.2921 - val_accuracy: 0.8799 - lr: 0.0100 - 390ms/epoch - 9ms/step\n",
            "Epoch 18/25\n",
            "45/45 - 0s - loss: 0.3084 - accuracy: 0.8912 - val_loss: 0.2963 - val_accuracy: 0.8947 - lr: 0.0100 - 357ms/epoch - 8ms/step\n",
            "Epoch 19/25\n",
            "45/45 - 0s - loss: 0.3052 - accuracy: 0.8948 - val_loss: 0.2758 - val_accuracy: 0.9178 - lr: 0.0100 - 381ms/epoch - 8ms/step\n",
            "Epoch 20/25\n",
            "45/45 - 0s - loss: 0.3043 - accuracy: 0.9075 - val_loss: 0.2756 - val_accuracy: 0.9161 - lr: 0.0100 - 396ms/epoch - 9ms/step\n",
            "Epoch 21/25\n",
            "45/45 - 0s - loss: 0.2887 - accuracy: 0.9061 - val_loss: 0.2784 - val_accuracy: 0.9293 - lr: 0.0100 - 380ms/epoch - 8ms/step\n",
            "Epoch 22/25\n",
            "45/45 - 0s - loss: 0.2821 - accuracy: 0.9174 - val_loss: 0.2755 - val_accuracy: 0.9309 - lr: 0.0100 - 358ms/epoch - 8ms/step\n",
            "Epoch 23/25\n",
            "\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.2961 - accuracy: 0.8997 - val_loss: 0.2939 - val_accuracy: 0.9161 - lr: 0.0100 - 422ms/epoch - 9ms/step\n",
            "Epoch 24/25\n",
            "45/45 - 0s - loss: 0.2778 - accuracy: 0.9145 - val_loss: 0.2855 - val_accuracy: 0.9227 - lr: 1.0000e-03 - 371ms/epoch - 8ms/step\n",
            "Epoch 25/25\n",
            "45/45 - 0s - loss: 0.2700 - accuracy: 0.9103 - val_loss: 0.2819 - val_accuracy: 0.9293 - lr: 1.0000e-03 - 396ms/epoch - 9ms/step\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2819 - accuracy: 0.9293\n",
            "Model: \"model_197\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_198 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_402 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_142 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_403 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "45/45 - 5s - loss: 0.7094 - accuracy: 0.5275 - val_loss: 0.5303 - val_accuracy: 0.5493 - lr: 0.0100 - 5s/epoch - 118ms/step\n",
            "Epoch 2/20\n",
            "45/45 - 0s - loss: 0.5336 - accuracy: 0.5692 - val_loss: 0.5018 - val_accuracy: 0.7368 - lr: 0.0100 - 320ms/epoch - 7ms/step\n",
            "Epoch 3/20\n",
            "45/45 - 0s - loss: 0.4781 - accuracy: 0.8093 - val_loss: 0.4341 - val_accuracy: 0.8569 - lr: 0.0100 - 279ms/epoch - 6ms/step\n",
            "Epoch 4/20\n",
            "45/45 - 0s - loss: 0.4117 - accuracy: 0.8679 - val_loss: 0.4074 - val_accuracy: 0.8651 - lr: 0.0100 - 275ms/epoch - 6ms/step\n",
            "Epoch 5/20\n",
            "45/45 - 0s - loss: 0.3763 - accuracy: 0.8736 - val_loss: 0.3870 - val_accuracy: 0.8701 - lr: 0.0100 - 313ms/epoch - 7ms/step\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.3955 - accuracy: 0.8234 - val_loss: 0.6318 - val_accuracy: 0.4507 - lr: 0.0100 - 271ms/epoch - 6ms/step\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 0.6095 - accuracy: 0.5085 - val_loss: 0.6186 - val_accuracy: 0.5329 - lr: 1.0000e-03 - 287ms/epoch - 6ms/step\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "45/45 - 0s - loss: 0.6016 - accuracy: 0.5671 - val_loss: 0.6171 - val_accuracy: 0.5362 - lr: 1.0000e-04 - 318ms/epoch - 7ms/step\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
            "45/45 - 0s - loss: 0.6007 - accuracy: 0.5692 - val_loss: 0.6169 - val_accuracy: 0.5493 - lr: 1.0000e-05 - 309ms/epoch - 7ms/step\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "45/45 - 0s - loss: 0.6006 - accuracy: 0.5847 - val_loss: 0.6169 - val_accuracy: 0.5493 - lr: 1.0000e-06 - 317ms/epoch - 7ms/step\n",
            "Epoch 11/20\n",
            "45/45 - 0s - loss: 0.6006 - accuracy: 0.5869 - val_loss: 0.6169 - val_accuracy: 0.5493 - lr: 1.0000e-07 - 269ms/epoch - 6ms/step\n",
            "Epoch 12/20\n",
            "45/45 - 0s - loss: 0.6006 - accuracy: 0.5869 - val_loss: 0.6169 - val_accuracy: 0.5493 - lr: 1.0000e-07 - 305ms/epoch - 7ms/step\n",
            "Epoch 13/20\n",
            "45/45 - 0s - loss: 0.6006 - accuracy: 0.5876 - val_loss: 0.6169 - val_accuracy: 0.5493 - lr: 1.0000e-07 - 275ms/epoch - 6ms/step\n",
            "Epoch 14/20\n",
            "45/45 - 0s - loss: 0.6006 - accuracy: 0.5876 - val_loss: 0.6169 - val_accuracy: 0.5493 - lr: 1.0000e-07 - 298ms/epoch - 7ms/step\n",
            "Epoch 15/20\n",
            "45/45 - 0s - loss: 0.6006 - accuracy: 0.5883 - val_loss: 0.6169 - val_accuracy: 0.5493 - lr: 1.0000e-07 - 278ms/epoch - 6ms/step\n",
            "Epoch 16/20\n",
            "45/45 - 0s - loss: 0.6006 - accuracy: 0.5897 - val_loss: 0.6169 - val_accuracy: 0.5493 - lr: 1.0000e-07 - 308ms/epoch - 7ms/step\n",
            "Epoch 17/20\n",
            "45/45 - 0s - loss: 0.6006 - accuracy: 0.5897 - val_loss: 0.6169 - val_accuracy: 0.5493 - lr: 1.0000e-07 - 273ms/epoch - 6ms/step\n",
            "Epoch 18/20\n",
            "45/45 - 0s - loss: 0.6006 - accuracy: 0.5897 - val_loss: 0.6169 - val_accuracy: 0.5493 - lr: 1.0000e-07 - 300ms/epoch - 7ms/step\n",
            "Epoch 19/20\n",
            "45/45 - 0s - loss: 0.6006 - accuracy: 0.5904 - val_loss: 0.6169 - val_accuracy: 0.5493 - lr: 1.0000e-07 - 312ms/epoch - 7ms/step\n",
            "Epoch 20/20\n",
            "45/45 - 0s - loss: 0.6006 - accuracy: 0.5904 - val_loss: 0.6169 - val_accuracy: 0.5493 - lr: 1.0000e-07 - 271ms/epoch - 6ms/step\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.6169 - accuracy: 0.5493\n",
            "Model: \"model_199\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_200 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_406 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_143 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_407 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "45/45 - 5s - loss: 0.8507 - accuracy: 0.6003 - val_loss: 0.4371 - val_accuracy: 0.8158 - lr: 0.0100 - 5s/epoch - 104ms/step\n",
            "Epoch 2/25\n",
            "45/45 - 0s - loss: 0.4181 - accuracy: 0.8524 - val_loss: 0.3754 - val_accuracy: 0.8766 - lr: 0.0100 - 308ms/epoch - 7ms/step\n",
            "Epoch 3/25\n",
            "45/45 - 0s - loss: 0.3572 - accuracy: 0.8743 - val_loss: 0.3508 - val_accuracy: 0.8750 - lr: 0.0100 - 285ms/epoch - 6ms/step\n",
            "Epoch 4/25\n",
            "45/45 - 0s - loss: 0.3366 - accuracy: 0.8743 - val_loss: 0.3393 - val_accuracy: 0.8799 - lr: 0.0100 - 300ms/epoch - 7ms/step\n",
            "Epoch 5/25\n",
            "45/45 - 0s - loss: 0.3295 - accuracy: 0.8856 - val_loss: 0.3100 - val_accuracy: 0.8964 - lr: 0.0100 - 275ms/epoch - 6ms/step\n",
            "Epoch 6/25\n",
            "45/45 - 0s - loss: 0.3043 - accuracy: 0.8983 - val_loss: 0.2886 - val_accuracy: 0.9062 - lr: 0.0100 - 299ms/epoch - 7ms/step\n",
            "Epoch 7/25\n",
            "45/45 - 0s - loss: 0.2758 - accuracy: 0.9117 - val_loss: 0.3190 - val_accuracy: 0.9079 - lr: 0.0100 - 286ms/epoch - 6ms/step\n",
            "Epoch 8/25\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.2894 - accuracy: 0.9096 - val_loss: 0.2817 - val_accuracy: 0.8947 - lr: 0.0100 - 288ms/epoch - 6ms/step\n",
            "Epoch 9/25\n",
            "45/45 - 0s - loss: 0.2727 - accuracy: 0.9061 - val_loss: 0.2766 - val_accuracy: 0.8964 - lr: 1.0000e-03 - 286ms/epoch - 6ms/step\n",
            "Epoch 10/25\n",
            "45/45 - 0s - loss: 0.2673 - accuracy: 0.9068 - val_loss: 0.2736 - val_accuracy: 0.9013 - lr: 1.0000e-03 - 294ms/epoch - 7ms/step\n",
            "Epoch 11/25\n",
            "45/45 - 0s - loss: 0.2642 - accuracy: 0.9124 - val_loss: 0.2720 - val_accuracy: 0.9062 - lr: 1.0000e-03 - 335ms/epoch - 7ms/step\n",
            "Epoch 12/25\n",
            "45/45 - 0s - loss: 0.2617 - accuracy: 0.9160 - val_loss: 0.2712 - val_accuracy: 0.9079 - lr: 1.0000e-03 - 388ms/epoch - 9ms/step\n",
            "Epoch 13/25\n",
            "45/45 - 0s - loss: 0.2598 - accuracy: 0.9153 - val_loss: 0.2714 - val_accuracy: 0.9079 - lr: 1.0000e-03 - 442ms/epoch - 10ms/step\n",
            "Epoch 14/25\n",
            "45/45 - 0s - loss: 0.2580 - accuracy: 0.9153 - val_loss: 0.2896 - val_accuracy: 0.9079 - lr: 1.0000e-03 - 402ms/epoch - 9ms/step\n",
            "Epoch 15/25\n",
            "45/45 - 0s - loss: 0.2561 - accuracy: 0.9160 - val_loss: 0.2883 - val_accuracy: 0.9095 - lr: 1.0000e-03 - 382ms/epoch - 8ms/step\n",
            "Epoch 16/25\n",
            "45/45 - 0s - loss: 0.2545 - accuracy: 0.9202 - val_loss: 0.2871 - val_accuracy: 0.9079 - lr: 1.0000e-03 - 420ms/epoch - 9ms/step\n",
            "Epoch 17/25\n",
            "45/45 - 0s - loss: 0.2530 - accuracy: 0.9195 - val_loss: 0.2858 - val_accuracy: 0.9079 - lr: 1.0000e-03 - 322ms/epoch - 7ms/step\n",
            "Epoch 18/25\n",
            "45/45 - 0s - loss: 0.2516 - accuracy: 0.9202 - val_loss: 0.2849 - val_accuracy: 0.9079 - lr: 1.0000e-03 - 312ms/epoch - 7ms/step\n",
            "Epoch 19/25\n",
            "45/45 - 0s - loss: 0.2505 - accuracy: 0.9188 - val_loss: 0.2835 - val_accuracy: 0.9079 - lr: 1.0000e-03 - 319ms/epoch - 7ms/step\n",
            "Epoch 20/25\n",
            "45/45 - 0s - loss: 0.2492 - accuracy: 0.9202 - val_loss: 0.2825 - val_accuracy: 0.9079 - lr: 1.0000e-03 - 308ms/epoch - 7ms/step\n",
            "Epoch 21/25\n",
            "45/45 - 0s - loss: 0.2482 - accuracy: 0.9188 - val_loss: 0.2816 - val_accuracy: 0.9095 - lr: 1.0000e-03 - 311ms/epoch - 7ms/step\n",
            "Epoch 22/25\n",
            "45/45 - 0s - loss: 0.2472 - accuracy: 0.9202 - val_loss: 0.2809 - val_accuracy: 0.9095 - lr: 1.0000e-03 - 318ms/epoch - 7ms/step\n",
            "Epoch 23/25\n",
            "45/45 - 0s - loss: 0.2462 - accuracy: 0.9195 - val_loss: 0.2798 - val_accuracy: 0.9112 - lr: 1.0000e-03 - 281ms/epoch - 6ms/step\n",
            "Epoch 24/25\n",
            "45/45 - 0s - loss: 0.2454 - accuracy: 0.9195 - val_loss: 0.2795 - val_accuracy: 0.9112 - lr: 1.0000e-03 - 311ms/epoch - 7ms/step\n",
            "Epoch 25/25\n",
            "45/45 - 0s - loss: 0.2447 - accuracy: 0.9188 - val_loss: 0.2783 - val_accuracy: 0.9095 - lr: 1.0000e-03 - 308ms/epoch - 7ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2783 - accuracy: 0.9095\n",
            "Model: \"model_201\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_202 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_410 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_144 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_411 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "45/45 - 5s - loss: 0.8714 - accuracy: 0.5275 - val_loss: 0.6149 - val_accuracy: 0.5493 - lr: 0.0100 - 5s/epoch - 120ms/step\n",
            "Epoch 2/20\n",
            "45/45 - 0s - loss: 0.5599 - accuracy: 0.5275 - val_loss: 0.5243 - val_accuracy: 0.5493 - lr: 0.0100 - 271ms/epoch - 6ms/step\n",
            "Epoch 3/20\n",
            "45/45 - 0s - loss: 0.4883 - accuracy: 0.5530 - val_loss: 0.4739 - val_accuracy: 0.7418 - lr: 0.0100 - 289ms/epoch - 6ms/step\n",
            "Epoch 4/20\n",
            "45/45 - 0s - loss: 0.4422 - accuracy: 0.8227 - val_loss: 0.4417 - val_accuracy: 0.8750 - lr: 0.0100 - 320ms/epoch - 7ms/step\n",
            "Epoch 5/20\n",
            "45/45 - 0s - loss: 0.4091 - accuracy: 0.8863 - val_loss: 0.4124 - val_accuracy: 0.8766 - lr: 0.0100 - 283ms/epoch - 6ms/step\n",
            "Epoch 6/20\n",
            "45/45 - 0s - loss: 0.3815 - accuracy: 0.8955 - val_loss: 0.3888 - val_accuracy: 0.8684 - lr: 0.0100 - 325ms/epoch - 7ms/step\n",
            "Epoch 7/20\n",
            "45/45 - 0s - loss: 0.3594 - accuracy: 0.8856 - val_loss: 0.3693 - val_accuracy: 0.8651 - lr: 0.0100 - 306ms/epoch - 7ms/step\n",
            "Epoch 8/20\n",
            "45/45 - 0s - loss: 0.3418 - accuracy: 0.8785 - val_loss: 0.3554 - val_accuracy: 0.8618 - lr: 0.0100 - 315ms/epoch - 7ms/step\n",
            "Epoch 9/20\n",
            "45/45 - 0s - loss: 0.3273 - accuracy: 0.8785 - val_loss: 0.3431 - val_accuracy: 0.8635 - lr: 0.0100 - 328ms/epoch - 7ms/step\n",
            "Epoch 10/20\n",
            "45/45 - 0s - loss: 0.3151 - accuracy: 0.8799 - val_loss: 0.3335 - val_accuracy: 0.8734 - lr: 0.0100 - 273ms/epoch - 6ms/step\n",
            "Epoch 11/20\n",
            "45/45 - 0s - loss: 0.3018 - accuracy: 0.8877 - val_loss: 0.3199 - val_accuracy: 0.8734 - lr: 0.0100 - 287ms/epoch - 6ms/step\n",
            "Epoch 12/20\n",
            "45/45 - 0s - loss: 0.2891 - accuracy: 0.8955 - val_loss: 0.3018 - val_accuracy: 0.8849 - lr: 0.0100 - 276ms/epoch - 6ms/step\n",
            "Epoch 13/20\n",
            "45/45 - 0s - loss: 0.2740 - accuracy: 0.9025 - val_loss: 0.2905 - val_accuracy: 0.8914 - lr: 0.0100 - 281ms/epoch - 6ms/step\n",
            "Epoch 14/20\n",
            "45/45 - 0s - loss: 0.2610 - accuracy: 0.9082 - val_loss: 0.2780 - val_accuracy: 0.8947 - lr: 0.0100 - 308ms/epoch - 7ms/step\n",
            "Epoch 15/20\n",
            "45/45 - 0s - loss: 0.2468 - accuracy: 0.9174 - val_loss: 0.2747 - val_accuracy: 0.8898 - lr: 0.0100 - 302ms/epoch - 7ms/step\n",
            "Epoch 16/20\n",
            "45/45 - 0s - loss: 0.2457 - accuracy: 0.9103 - val_loss: 0.2764 - val_accuracy: 0.8980 - lr: 0.0100 - 282ms/epoch - 6ms/step\n",
            "Epoch 17/20\n",
            "45/45 - 0s - loss: 0.2434 - accuracy: 0.9202 - val_loss: 0.2634 - val_accuracy: 0.9112 - lr: 0.0100 - 287ms/epoch - 6ms/step\n",
            "Epoch 18/20\n",
            "45/45 - 0s - loss: 0.2278 - accuracy: 0.9216 - val_loss: 0.2555 - val_accuracy: 0.9046 - lr: 0.0100 - 276ms/epoch - 6ms/step\n",
            "Epoch 19/20\n",
            "45/45 - 0s - loss: 0.2202 - accuracy: 0.9251 - val_loss: 0.2496 - val_accuracy: 0.9128 - lr: 0.0100 - 270ms/epoch - 6ms/step\n",
            "Epoch 20/20\n",
            "45/45 - 0s - loss: 0.2119 - accuracy: 0.9294 - val_loss: 0.2394 - val_accuracy: 0.9145 - lr: 0.0100 - 314ms/epoch - 7ms/step\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2394 - accuracy: 0.9145\n",
            "Model: \"model_203\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_204 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_414 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_145 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_415 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "45/45 - 5s - loss: 1.0457 - accuracy: 0.5374 - val_loss: 0.6325 - val_accuracy: 0.5263 - lr: 0.0100 - 5s/epoch - 105ms/step\n",
            "Epoch 2/25\n",
            "45/45 - 0s - loss: 0.5265 - accuracy: 0.6624 - val_loss: 0.4346 - val_accuracy: 0.8684 - lr: 0.0100 - 298ms/epoch - 7ms/step\n",
            "Epoch 3/25\n",
            "45/45 - 0s - loss: 0.4470 - accuracy: 0.8665 - val_loss: 0.4329 - val_accuracy: 0.8684 - lr: 0.0100 - 307ms/epoch - 7ms/step\n",
            "Epoch 4/25\n",
            "45/45 - 0s - loss: 0.4144 - accuracy: 0.8764 - val_loss: 0.4065 - val_accuracy: 0.8684 - lr: 0.0100 - 289ms/epoch - 6ms/step\n",
            "Epoch 5/25\n",
            "45/45 - 0s - loss: 0.3917 - accuracy: 0.8764 - val_loss: 0.3896 - val_accuracy: 0.8684 - lr: 0.0100 - 279ms/epoch - 6ms/step\n",
            "Epoch 6/25\n",
            "45/45 - 0s - loss: 0.3751 - accuracy: 0.8771 - val_loss: 0.3742 - val_accuracy: 0.8701 - lr: 0.0100 - 313ms/epoch - 7ms/step\n",
            "Epoch 7/25\n",
            "45/45 - 0s - loss: 0.3604 - accuracy: 0.8757 - val_loss: 0.3600 - val_accuracy: 0.8701 - lr: 0.0100 - 280ms/epoch - 6ms/step\n",
            "Epoch 8/25\n",
            "45/45 - 0s - loss: 0.3435 - accuracy: 0.8799 - val_loss: 0.3464 - val_accuracy: 0.8766 - lr: 0.0100 - 297ms/epoch - 7ms/step\n",
            "Epoch 9/25\n",
            "45/45 - 0s - loss: 0.3322 - accuracy: 0.8821 - val_loss: 0.3379 - val_accuracy: 0.8832 - lr: 0.0100 - 274ms/epoch - 6ms/step\n",
            "Epoch 10/25\n",
            "45/45 - 0s - loss: 0.3238 - accuracy: 0.8877 - val_loss: 0.3238 - val_accuracy: 0.8832 - lr: 0.0100 - 278ms/epoch - 6ms/step\n",
            "Epoch 11/25\n",
            "45/45 - 0s - loss: 0.3142 - accuracy: 0.8863 - val_loss: 0.3187 - val_accuracy: 0.8980 - lr: 0.0100 - 278ms/epoch - 6ms/step\n",
            "Epoch 12/25\n",
            "45/45 - 0s - loss: 0.3075 - accuracy: 0.8898 - val_loss: 0.3112 - val_accuracy: 0.8914 - lr: 0.0100 - 297ms/epoch - 7ms/step\n",
            "Epoch 13/25\n",
            "45/45 - 0s - loss: 0.3017 - accuracy: 0.8934 - val_loss: 0.3078 - val_accuracy: 0.8931 - lr: 0.0100 - 268ms/epoch - 6ms/step\n",
            "Epoch 14/25\n",
            "45/45 - 0s - loss: 0.2944 - accuracy: 0.8948 - val_loss: 0.3002 - val_accuracy: 0.8980 - lr: 0.0100 - 298ms/epoch - 7ms/step\n",
            "Epoch 15/25\n",
            "45/45 - 0s - loss: 0.2872 - accuracy: 0.8976 - val_loss: 0.2960 - val_accuracy: 0.8964 - lr: 0.0100 - 275ms/epoch - 6ms/step\n",
            "Epoch 16/25\n",
            "45/45 - 0s - loss: 0.2827 - accuracy: 0.8983 - val_loss: 0.2936 - val_accuracy: 0.9030 - lr: 0.0100 - 309ms/epoch - 7ms/step\n",
            "Epoch 17/25\n",
            "45/45 - 0s - loss: 0.2785 - accuracy: 0.8997 - val_loss: 0.2866 - val_accuracy: 0.9013 - lr: 0.0100 - 281ms/epoch - 6ms/step\n",
            "Epoch 18/25\n",
            "45/45 - 0s - loss: 0.2774 - accuracy: 0.9011 - val_loss: 0.2930 - val_accuracy: 0.8832 - lr: 0.0100 - 294ms/epoch - 7ms/step\n",
            "Epoch 19/25\n",
            "45/45 - 0s - loss: 0.2751 - accuracy: 0.8990 - val_loss: 0.2759 - val_accuracy: 0.9013 - lr: 0.0100 - 291ms/epoch - 6ms/step\n",
            "Epoch 20/25\n",
            "45/45 - 0s - loss: 0.2661 - accuracy: 0.9040 - val_loss: 0.2717 - val_accuracy: 0.9013 - lr: 0.0100 - 288ms/epoch - 6ms/step\n",
            "Epoch 21/25\n",
            "45/45 - 0s - loss: 0.2620 - accuracy: 0.9075 - val_loss: 0.2744 - val_accuracy: 0.8997 - lr: 0.0100 - 290ms/epoch - 6ms/step\n",
            "Epoch 22/25\n",
            "\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.2632 - accuracy: 0.9061 - val_loss: 0.2696 - val_accuracy: 0.9079 - lr: 0.0100 - 300ms/epoch - 7ms/step\n",
            "Epoch 23/25\n",
            "45/45 - 0s - loss: 0.2598 - accuracy: 0.9054 - val_loss: 0.2686 - val_accuracy: 0.9079 - lr: 1.0000e-03 - 298ms/epoch - 7ms/step\n",
            "Epoch 24/25\n",
            "45/45 - 0s - loss: 0.2586 - accuracy: 0.9054 - val_loss: 0.2675 - val_accuracy: 0.9079 - lr: 1.0000e-03 - 313ms/epoch - 7ms/step\n",
            "Epoch 25/25\n",
            "45/45 - 0s - loss: 0.2581 - accuracy: 0.9047 - val_loss: 0.2652 - val_accuracy: 0.9095 - lr: 1.0000e-03 - 313ms/epoch - 7ms/step\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2652 - accuracy: 0.9095\n",
            "Model: \"model_205\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_206 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_418 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_146 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_419 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "45/45 - 7s - loss: 0.6839 - accuracy: 0.5311 - val_loss: 0.6264 - val_accuracy: 0.5559 - lr: 0.0100 - 7s/epoch - 166ms/step\n",
            "Epoch 2/25\n",
            "45/45 - 0s - loss: 0.6005 - accuracy: 0.6328 - val_loss: 0.5684 - val_accuracy: 0.7138 - lr: 0.0100 - 404ms/epoch - 9ms/step\n",
            "Epoch 3/25\n",
            "45/45 - 0s - loss: 0.5305 - accuracy: 0.7832 - val_loss: 0.4988 - val_accuracy: 0.8158 - lr: 0.0100 - 381ms/epoch - 8ms/step\n",
            "Epoch 4/25\n",
            "45/45 - 0s - loss: 0.4500 - accuracy: 0.8227 - val_loss: 0.4083 - val_accuracy: 0.8454 - lr: 0.0100 - 377ms/epoch - 8ms/step\n",
            "Epoch 5/25\n",
            "45/45 - 0s - loss: 0.3651 - accuracy: 0.8814 - val_loss: 0.3551 - val_accuracy: 0.9030 - lr: 0.0100 - 415ms/epoch - 9ms/step\n",
            "Epoch 6/25\n",
            "45/45 - 0s - loss: 0.3242 - accuracy: 0.9160 - val_loss: 0.3138 - val_accuracy: 0.8947 - lr: 0.0100 - 382ms/epoch - 8ms/step\n",
            "Epoch 7/25\n",
            "45/45 - 0s - loss: 0.2809 - accuracy: 0.9230 - val_loss: 0.2808 - val_accuracy: 0.9211 - lr: 0.0100 - 409ms/epoch - 9ms/step\n",
            "Epoch 8/25\n",
            "45/45 - 0s - loss: 0.2725 - accuracy: 0.9273 - val_loss: 0.2611 - val_accuracy: 0.9260 - lr: 0.0100 - 412ms/epoch - 9ms/step\n",
            "Epoch 9/25\n",
            "45/45 - 0s - loss: 0.2558 - accuracy: 0.9315 - val_loss: 0.3301 - val_accuracy: 0.9013 - lr: 0.0100 - 381ms/epoch - 8ms/step\n",
            "Epoch 10/25\n",
            "45/45 - 0s - loss: 0.2434 - accuracy: 0.9280 - val_loss: 0.2726 - val_accuracy: 0.9243 - lr: 0.0100 - 377ms/epoch - 8ms/step\n",
            "Epoch 11/25\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.2487 - accuracy: 0.9329 - val_loss: 0.2321 - val_accuracy: 0.9260 - lr: 0.0100 - 388ms/epoch - 9ms/step\n",
            "Epoch 12/25\n",
            "45/45 - 0s - loss: 0.2218 - accuracy: 0.9414 - val_loss: 0.2396 - val_accuracy: 0.9227 - lr: 1.0000e-03 - 396ms/epoch - 9ms/step\n",
            "Epoch 13/25\n",
            "45/45 - 0s - loss: 0.2192 - accuracy: 0.9364 - val_loss: 0.2373 - val_accuracy: 0.9243 - lr: 1.0000e-03 - 373ms/epoch - 8ms/step\n",
            "Epoch 14/25\n",
            "45/45 - 0s - loss: 0.2069 - accuracy: 0.9400 - val_loss: 0.2200 - val_accuracy: 0.9326 - lr: 1.0000e-03 - 386ms/epoch - 9ms/step\n",
            "Epoch 15/25\n",
            "45/45 - 0s - loss: 0.2041 - accuracy: 0.9421 - val_loss: 0.2390 - val_accuracy: 0.9293 - lr: 1.0000e-03 - 364ms/epoch - 8ms/step\n",
            "Epoch 16/25\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 0.2152 - accuracy: 0.9379 - val_loss: 0.2289 - val_accuracy: 0.9293 - lr: 1.0000e-03 - 378ms/epoch - 8ms/step\n",
            "Epoch 17/25\n",
            "\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "45/45 - 0s - loss: 0.2123 - accuracy: 0.9357 - val_loss: 0.2269 - val_accuracy: 0.9326 - lr: 1.0000e-04 - 396ms/epoch - 9ms/step\n",
            "Epoch 18/25\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
            "45/45 - 0s - loss: 0.2106 - accuracy: 0.9371 - val_loss: 0.2267 - val_accuracy: 0.9309 - lr: 1.0000e-05 - 358ms/epoch - 8ms/step\n",
            "Epoch 19/25\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "45/45 - 0s - loss: 0.2104 - accuracy: 0.9371 - val_loss: 0.2267 - val_accuracy: 0.9309 - lr: 1.0000e-06 - 373ms/epoch - 8ms/step\n",
            "Epoch 20/25\n",
            "45/45 - 0s - loss: 0.2104 - accuracy: 0.9371 - val_loss: 0.2267 - val_accuracy: 0.9309 - lr: 1.0000e-07 - 403ms/epoch - 9ms/step\n",
            "Epoch 21/25\n",
            "45/45 - 0s - loss: 0.2104 - accuracy: 0.9371 - val_loss: 0.2267 - val_accuracy: 0.9309 - lr: 1.0000e-07 - 366ms/epoch - 8ms/step\n",
            "Epoch 22/25\n",
            "45/45 - 0s - loss: 0.2104 - accuracy: 0.9371 - val_loss: 0.2267 - val_accuracy: 0.9309 - lr: 1.0000e-07 - 387ms/epoch - 9ms/step\n",
            "Epoch 23/25\n",
            "45/45 - 0s - loss: 0.2104 - accuracy: 0.9371 - val_loss: 0.2267 - val_accuracy: 0.9309 - lr: 1.0000e-07 - 373ms/epoch - 8ms/step\n",
            "Epoch 24/25\n",
            "45/45 - 0s - loss: 0.2104 - accuracy: 0.9371 - val_loss: 0.2267 - val_accuracy: 0.9309 - lr: 1.0000e-07 - 374ms/epoch - 8ms/step\n",
            "Epoch 25/25\n",
            "45/45 - 0s - loss: 0.2104 - accuracy: 0.9371 - val_loss: 0.2267 - val_accuracy: 0.9309 - lr: 1.0000e-07 - 385ms/epoch - 9ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2267 - accuracy: 0.9309\n",
            "Model: \"model_207\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_208 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_423 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_147 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_424 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "45/45 - 5s - loss: 0.8133 - accuracy: 0.5261 - val_loss: 0.5000 - val_accuracy: 0.5477 - lr: 0.0100 - 5s/epoch - 103ms/step\n",
            "Epoch 2/25\n",
            "45/45 - 0s - loss: 0.4957 - accuracy: 0.7444 - val_loss: 0.4326 - val_accuracy: 0.8717 - lr: 0.0100 - 303ms/epoch - 7ms/step\n",
            "Epoch 3/25\n",
            "45/45 - 0s - loss: 0.4123 - accuracy: 0.8891 - val_loss: 0.3898 - val_accuracy: 0.8734 - lr: 0.0100 - 281ms/epoch - 6ms/step\n",
            "Epoch 4/25\n",
            "45/45 - 0s - loss: 0.3818 - accuracy: 0.8849 - val_loss: 0.3605 - val_accuracy: 0.8734 - lr: 0.0100 - 292ms/epoch - 6ms/step\n",
            "Epoch 5/25\n",
            "45/45 - 0s - loss: 0.3513 - accuracy: 0.8863 - val_loss: 0.3421 - val_accuracy: 0.8766 - lr: 0.0100 - 295ms/epoch - 7ms/step\n",
            "Epoch 6/25\n",
            "45/45 - 0s - loss: 0.3291 - accuracy: 0.8969 - val_loss: 0.3439 - val_accuracy: 0.8816 - lr: 0.0100 - 310ms/epoch - 7ms/step\n",
            "Epoch 7/25\n",
            "45/45 - 0s - loss: 0.3094 - accuracy: 0.9047 - val_loss: 0.3330 - val_accuracy: 0.8734 - lr: 0.0100 - 271ms/epoch - 6ms/step\n",
            "Epoch 8/25\n",
            "45/45 - 0s - loss: 0.2940 - accuracy: 0.9117 - val_loss: 0.3163 - val_accuracy: 0.8832 - lr: 0.0100 - 293ms/epoch - 7ms/step\n",
            "Epoch 9/25\n",
            "45/45 - 0s - loss: 0.2771 - accuracy: 0.9174 - val_loss: 0.3074 - val_accuracy: 0.8766 - lr: 0.0100 - 286ms/epoch - 6ms/step\n",
            "Epoch 10/25\n",
            "45/45 - 0s - loss: 0.2698 - accuracy: 0.9167 - val_loss: 0.3032 - val_accuracy: 0.8914 - lr: 0.0100 - 292ms/epoch - 6ms/step\n",
            "Epoch 11/25\n",
            "45/45 - 0s - loss: 0.2544 - accuracy: 0.9188 - val_loss: 0.2888 - val_accuracy: 0.8997 - lr: 0.0100 - 306ms/epoch - 7ms/step\n",
            "Epoch 12/25\n",
            "45/45 - 0s - loss: 0.2406 - accuracy: 0.9237 - val_loss: 0.2790 - val_accuracy: 0.8931 - lr: 0.0100 - 312ms/epoch - 7ms/step\n",
            "Epoch 13/25\n",
            "45/45 - 0s - loss: 0.2359 - accuracy: 0.9251 - val_loss: 0.3097 - val_accuracy: 0.8980 - lr: 0.0100 - 304ms/epoch - 7ms/step\n",
            "Epoch 14/25\n",
            "45/45 - 0s - loss: 0.2308 - accuracy: 0.9167 - val_loss: 0.2594 - val_accuracy: 0.9030 - lr: 0.0100 - 275ms/epoch - 6ms/step\n",
            "Epoch 15/25\n",
            "45/45 - 0s - loss: 0.2239 - accuracy: 0.9223 - val_loss: 0.2672 - val_accuracy: 0.9030 - lr: 0.0100 - 285ms/epoch - 6ms/step\n",
            "Epoch 16/25\n",
            "45/45 - 0s - loss: 0.2185 - accuracy: 0.9258 - val_loss: 0.3344 - val_accuracy: 0.8701 - lr: 0.0100 - 303ms/epoch - 7ms/step\n",
            "Epoch 17/25\n",
            "\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.2561 - accuracy: 0.8948 - val_loss: 0.2861 - val_accuracy: 0.8832 - lr: 0.0100 - 283ms/epoch - 6ms/step\n",
            "Epoch 18/25\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 0.2427 - accuracy: 0.9047 - val_loss: 0.2825 - val_accuracy: 0.8849 - lr: 1.0000e-03 - 309ms/epoch - 7ms/step\n",
            "Epoch 19/25\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "45/45 - 0s - loss: 0.2407 - accuracy: 0.9068 - val_loss: 0.2823 - val_accuracy: 0.8849 - lr: 1.0000e-04 - 284ms/epoch - 6ms/step\n",
            "Epoch 20/25\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
            "45/45 - 0s - loss: 0.2405 - accuracy: 0.9068 - val_loss: 0.2823 - val_accuracy: 0.8849 - lr: 1.0000e-05 - 283ms/epoch - 6ms/step\n",
            "Epoch 21/25\n",
            "\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "45/45 - 0s - loss: 0.2405 - accuracy: 0.9068 - val_loss: 0.2823 - val_accuracy: 0.8849 - lr: 1.0000e-06 - 285ms/epoch - 6ms/step\n",
            "Epoch 22/25\n",
            "45/45 - 0s - loss: 0.2405 - accuracy: 0.9068 - val_loss: 0.2823 - val_accuracy: 0.8849 - lr: 1.0000e-07 - 279ms/epoch - 6ms/step\n",
            "Epoch 23/25\n",
            "45/45 - 0s - loss: 0.2405 - accuracy: 0.9068 - val_loss: 0.2823 - val_accuracy: 0.8849 - lr: 1.0000e-07 - 331ms/epoch - 7ms/step\n",
            "Epoch 24/25\n",
            "45/45 - 0s - loss: 0.2405 - accuracy: 0.9068 - val_loss: 0.2823 - val_accuracy: 0.8849 - lr: 1.0000e-07 - 281ms/epoch - 6ms/step\n",
            "Epoch 25/25\n",
            "45/45 - 0s - loss: 0.2405 - accuracy: 0.9068 - val_loss: 0.2823 - val_accuracy: 0.8849 - lr: 1.0000e-07 - 287ms/epoch - 6ms/step\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2823 - accuracy: 0.8849\n",
            "Model: \"model_209\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_210 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_427 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_148 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_428 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "45/45 - 8s - loss: 1.6000 - accuracy: 0.5410 - val_loss: 0.6286 - val_accuracy: 0.5181 - lr: 0.0100 - 8s/epoch - 167ms/step\n",
            "Epoch 2/25\n",
            "45/45 - 0s - loss: 0.5838 - accuracy: 0.5452 - val_loss: 0.5619 - val_accuracy: 0.5872 - lr: 0.0100 - 394ms/epoch - 9ms/step\n",
            "Epoch 3/25\n",
            "45/45 - 0s - loss: 0.5324 - accuracy: 0.7648 - val_loss: 0.5194 - val_accuracy: 0.8503 - lr: 0.0100 - 382ms/epoch - 8ms/step\n",
            "Epoch 4/25\n",
            "45/45 - 0s - loss: 0.4835 - accuracy: 0.8411 - val_loss: 0.4658 - val_accuracy: 0.8553 - lr: 0.0100 - 376ms/epoch - 8ms/step\n",
            "Epoch 5/25\n",
            "45/45 - 0s - loss: 0.4320 - accuracy: 0.8806 - val_loss: 0.4196 - val_accuracy: 0.8766 - lr: 0.0100 - 408ms/epoch - 9ms/step\n",
            "Epoch 6/25\n",
            "45/45 - 0s - loss: 0.3843 - accuracy: 0.9054 - val_loss: 0.3744 - val_accuracy: 0.8849 - lr: 0.0100 - 369ms/epoch - 8ms/step\n",
            "Epoch 7/25\n",
            "45/45 - 0s - loss: 0.3468 - accuracy: 0.9124 - val_loss: 0.3460 - val_accuracy: 0.8980 - lr: 0.0100 - 365ms/epoch - 8ms/step\n",
            "Epoch 8/25\n",
            "45/45 - 0s - loss: 0.3178 - accuracy: 0.9181 - val_loss: 0.3448 - val_accuracy: 0.9062 - lr: 0.0100 - 386ms/epoch - 9ms/step\n",
            "Epoch 9/25\n",
            "45/45 - 0s - loss: 0.3088 - accuracy: 0.9195 - val_loss: 0.2962 - val_accuracy: 0.9095 - lr: 0.0100 - 391ms/epoch - 9ms/step\n",
            "Epoch 10/25\n",
            "45/45 - 0s - loss: 0.2839 - accuracy: 0.9258 - val_loss: 0.2713 - val_accuracy: 0.9013 - lr: 0.0100 - 377ms/epoch - 8ms/step\n",
            "Epoch 11/25\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.3215 - accuracy: 0.9068 - val_loss: 0.3456 - val_accuracy: 0.8997 - lr: 0.0100 - 384ms/epoch - 9ms/step\n",
            "Epoch 12/25\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 0.2934 - accuracy: 0.9131 - val_loss: 0.3048 - val_accuracy: 0.9161 - lr: 1.0000e-03 - 378ms/epoch - 8ms/step\n",
            "Epoch 13/25\n",
            "45/45 - 0s - loss: 0.2686 - accuracy: 0.9244 - val_loss: 0.3039 - val_accuracy: 0.9161 - lr: 1.0000e-04 - 428ms/epoch - 10ms/step\n",
            "Epoch 14/25\n",
            "45/45 - 0s - loss: 0.2672 - accuracy: 0.9244 - val_loss: 0.3031 - val_accuracy: 0.9145 - lr: 1.0000e-04 - 435ms/epoch - 10ms/step\n",
            "Epoch 15/25\n",
            "45/45 - 1s - loss: 0.2660 - accuracy: 0.9244 - val_loss: 0.3025 - val_accuracy: 0.9161 - lr: 1.0000e-04 - 541ms/epoch - 12ms/step\n",
            "Epoch 16/25\n",
            "45/45 - 1s - loss: 0.2649 - accuracy: 0.9237 - val_loss: 0.3018 - val_accuracy: 0.9161 - lr: 1.0000e-04 - 530ms/epoch - 12ms/step\n",
            "Epoch 17/25\n",
            "45/45 - 1s - loss: 0.2640 - accuracy: 0.9244 - val_loss: 0.3012 - val_accuracy: 0.9145 - lr: 1.0000e-04 - 538ms/epoch - 12ms/step\n",
            "Epoch 18/25\n",
            "45/45 - 1s - loss: 0.2631 - accuracy: 0.9266 - val_loss: 0.3008 - val_accuracy: 0.9145 - lr: 1.0000e-04 - 526ms/epoch - 12ms/step\n",
            "Epoch 19/25\n",
            "45/45 - 0s - loss: 0.2622 - accuracy: 0.9251 - val_loss: 0.3002 - val_accuracy: 0.9145 - lr: 1.0000e-04 - 405ms/epoch - 9ms/step\n",
            "Epoch 20/25\n",
            "45/45 - 0s - loss: 0.2614 - accuracy: 0.9258 - val_loss: 0.2997 - val_accuracy: 0.9145 - lr: 1.0000e-04 - 390ms/epoch - 9ms/step\n",
            "Epoch 21/25\n",
            "45/45 - 0s - loss: 0.2606 - accuracy: 0.9258 - val_loss: 0.2993 - val_accuracy: 0.9128 - lr: 1.0000e-04 - 378ms/epoch - 8ms/step\n",
            "Epoch 22/25\n",
            "45/45 - 0s - loss: 0.2599 - accuracy: 0.9266 - val_loss: 0.2988 - val_accuracy: 0.9145 - lr: 1.0000e-04 - 381ms/epoch - 8ms/step\n",
            "Epoch 23/25\n",
            "45/45 - 0s - loss: 0.2591 - accuracy: 0.9280 - val_loss: 0.2984 - val_accuracy: 0.9128 - lr: 1.0000e-04 - 385ms/epoch - 9ms/step\n",
            "Epoch 24/25\n",
            "45/45 - 0s - loss: 0.2584 - accuracy: 0.9294 - val_loss: 0.2979 - val_accuracy: 0.9128 - lr: 1.0000e-04 - 396ms/epoch - 9ms/step\n",
            "Epoch 25/25\n",
            "45/45 - 0s - loss: 0.2577 - accuracy: 0.9294 - val_loss: 0.2975 - val_accuracy: 0.9128 - lr: 1.0000e-04 - 396ms/epoch - 9ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2975 - accuracy: 0.9128\n",
            "Model: \"model_211\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_212 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_432 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_149 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_433 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "45/45 - 5s - loss: 0.6829 - accuracy: 0.5254 - val_loss: 0.5277 - val_accuracy: 0.5543 - lr: 0.0100 - 5s/epoch - 119ms/step\n",
            "Epoch 2/20\n",
            "45/45 - 0s - loss: 0.5258 - accuracy: 0.5290 - val_loss: 0.4797 - val_accuracy: 0.6760 - lr: 0.0100 - 277ms/epoch - 6ms/step\n",
            "Epoch 3/20\n",
            "45/45 - 0s - loss: 0.4824 - accuracy: 0.8234 - val_loss: 0.4470 - val_accuracy: 0.8980 - lr: 0.0100 - 287ms/epoch - 6ms/step\n",
            "Epoch 4/20\n",
            "45/45 - 0s - loss: 0.4556 - accuracy: 0.8715 - val_loss: 0.4111 - val_accuracy: 0.8914 - lr: 0.0100 - 296ms/epoch - 7ms/step\n",
            "Epoch 5/20\n",
            "45/45 - 0s - loss: 0.4091 - accuracy: 0.8701 - val_loss: 0.4025 - val_accuracy: 0.8914 - lr: 0.0100 - 288ms/epoch - 6ms/step\n",
            "Epoch 6/20\n",
            "45/45 - 0s - loss: 0.3862 - accuracy: 0.8750 - val_loss: 0.3845 - val_accuracy: 0.8898 - lr: 0.0100 - 342ms/epoch - 8ms/step\n",
            "Epoch 7/20\n",
            "45/45 - 0s - loss: 0.3666 - accuracy: 0.8757 - val_loss: 0.3810 - val_accuracy: 0.8964 - lr: 0.0100 - 314ms/epoch - 7ms/step\n",
            "Epoch 8/20\n",
            "45/45 - 0s - loss: 0.3521 - accuracy: 0.8771 - val_loss: 0.3756 - val_accuracy: 0.8931 - lr: 0.0100 - 337ms/epoch - 7ms/step\n",
            "Epoch 9/20\n",
            "45/45 - 0s - loss: 0.3397 - accuracy: 0.8814 - val_loss: 0.3248 - val_accuracy: 0.8997 - lr: 0.0100 - 325ms/epoch - 7ms/step\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.3445 - accuracy: 0.8898 - val_loss: 0.3253 - val_accuracy: 0.8947 - lr: 0.0100 - 341ms/epoch - 8ms/step\n",
            "Epoch 11/20\n",
            "45/45 - 0s - loss: 0.3288 - accuracy: 0.8821 - val_loss: 0.3237 - val_accuracy: 0.8931 - lr: 1.0000e-03 - 298ms/epoch - 7ms/step\n",
            "Epoch 12/20\n",
            "45/45 - 0s - loss: 0.3259 - accuracy: 0.8870 - val_loss: 0.3230 - val_accuracy: 0.8914 - lr: 1.0000e-03 - 288ms/epoch - 6ms/step\n",
            "Epoch 13/20\n",
            "45/45 - 0s - loss: 0.3241 - accuracy: 0.8849 - val_loss: 0.3227 - val_accuracy: 0.8914 - lr: 1.0000e-03 - 285ms/epoch - 6ms/step\n",
            "Epoch 14/20\n",
            "45/45 - 0s - loss: 0.3226 - accuracy: 0.8863 - val_loss: 0.3365 - val_accuracy: 0.8914 - lr: 1.0000e-03 - 319ms/epoch - 7ms/step\n",
            "Epoch 15/20\n",
            "45/45 - 0s - loss: 0.3212 - accuracy: 0.8870 - val_loss: 0.3363 - val_accuracy: 0.8898 - lr: 1.0000e-03 - 276ms/epoch - 6ms/step\n",
            "Epoch 16/20\n",
            "45/45 - 0s - loss: 0.3203 - accuracy: 0.8849 - val_loss: 0.3359 - val_accuracy: 0.8914 - lr: 1.0000e-03 - 326ms/epoch - 7ms/step\n",
            "Epoch 17/20\n",
            "45/45 - 0s - loss: 0.3192 - accuracy: 0.8863 - val_loss: 0.3347 - val_accuracy: 0.8931 - lr: 1.0000e-03 - 315ms/epoch - 7ms/step\n",
            "Epoch 18/20\n",
            "45/45 - 0s - loss: 0.3180 - accuracy: 0.8877 - val_loss: 0.3361 - val_accuracy: 0.8931 - lr: 1.0000e-03 - 277ms/epoch - 6ms/step\n",
            "Epoch 19/20\n",
            "45/45 - 0s - loss: 0.3168 - accuracy: 0.8863 - val_loss: 0.3470 - val_accuracy: 0.8931 - lr: 1.0000e-03 - 317ms/epoch - 7ms/step\n",
            "Epoch 20/20\n",
            "45/45 - 0s - loss: 0.3156 - accuracy: 0.8870 - val_loss: 0.3460 - val_accuracy: 0.8914 - lr: 1.0000e-03 - 289ms/epoch - 6ms/step\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3460 - accuracy: 0.8914\n",
            "Model: \"model_213\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_214 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_436 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_150 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_437 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "45/45 - 5s - loss: 0.4728 - accuracy: 0.8192 - val_loss: 0.3971 - val_accuracy: 0.8799 - lr: 0.0100 - 5s/epoch - 104ms/step\n",
            "Epoch 2/15\n",
            "45/45 - 0s - loss: 0.3656 - accuracy: 0.8849 - val_loss: 0.3718 - val_accuracy: 0.8914 - lr: 0.0100 - 299ms/epoch - 7ms/step\n",
            "Epoch 3/15\n",
            "45/45 - 0s - loss: 0.3400 - accuracy: 0.8835 - val_loss: 0.3599 - val_accuracy: 0.8964 - lr: 0.0100 - 284ms/epoch - 6ms/step\n",
            "Epoch 4/15\n",
            "45/45 - 0s - loss: 0.3381 - accuracy: 0.8856 - val_loss: 0.3493 - val_accuracy: 0.8964 - lr: 0.0100 - 309ms/epoch - 7ms/step\n",
            "Epoch 5/15\n",
            "45/45 - 0s - loss: 0.3359 - accuracy: 0.8877 - val_loss: 0.3433 - val_accuracy: 0.9062 - lr: 0.0100 - 275ms/epoch - 6ms/step\n",
            "Epoch 6/15\n",
            "45/45 - 0s - loss: 0.3090 - accuracy: 0.8955 - val_loss: 0.3258 - val_accuracy: 0.9062 - lr: 0.0100 - 283ms/epoch - 6ms/step\n",
            "Epoch 7/15\n",
            "45/45 - 0s - loss: 0.2991 - accuracy: 0.8976 - val_loss: 0.3005 - val_accuracy: 0.9079 - lr: 0.0100 - 321ms/epoch - 7ms/step\n",
            "Epoch 8/15\n",
            "45/45 - 0s - loss: 0.2963 - accuracy: 0.8919 - val_loss: 0.3067 - val_accuracy: 0.9128 - lr: 0.0100 - 314ms/epoch - 7ms/step\n",
            "Epoch 9/15\n",
            "45/45 - 0s - loss: 0.2875 - accuracy: 0.8990 - val_loss: 0.2989 - val_accuracy: 0.9227 - lr: 0.0100 - 287ms/epoch - 6ms/step\n",
            "Epoch 10/15\n",
            "45/45 - 0s - loss: 0.2832 - accuracy: 0.8969 - val_loss: 0.3016 - val_accuracy: 0.9211 - lr: 0.0100 - 315ms/epoch - 7ms/step\n",
            "Epoch 11/15\n",
            "45/45 - 0s - loss: 0.2817 - accuracy: 0.9004 - val_loss: 0.2962 - val_accuracy: 0.9243 - lr: 0.0100 - 280ms/epoch - 6ms/step\n",
            "Epoch 12/15\n",
            "45/45 - 0s - loss: 0.2781 - accuracy: 0.9025 - val_loss: 0.2752 - val_accuracy: 0.9211 - lr: 0.0100 - 299ms/epoch - 7ms/step\n",
            "Epoch 13/15\n",
            "45/45 - 0s - loss: 0.2728 - accuracy: 0.9032 - val_loss: 0.2842 - val_accuracy: 0.9260 - lr: 0.0100 - 304ms/epoch - 7ms/step\n",
            "Epoch 14/15\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.2870 - accuracy: 0.9054 - val_loss: 0.2853 - val_accuracy: 0.9178 - lr: 0.0100 - 285ms/epoch - 6ms/step\n",
            "Epoch 15/15\n",
            "45/45 - 0s - loss: 0.2644 - accuracy: 0.9047 - val_loss: 0.2825 - val_accuracy: 0.9243 - lr: 1.0000e-03 - 292ms/epoch - 6ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2825 - accuracy: 0.9243\n",
            "Model: \"model_215\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_216 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_440 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_151 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_441 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "45/45 - 7s - loss: 1.0507 - accuracy: 0.5268 - val_loss: 0.6082 - val_accuracy: 0.5510 - lr: 0.0100 - 7s/epoch - 165ms/step\n",
            "Epoch 2/20\n",
            "45/45 - 0s - loss: 0.5836 - accuracy: 0.5268 - val_loss: 0.5211 - val_accuracy: 0.5510 - lr: 0.0100 - 405ms/epoch - 9ms/step\n",
            "Epoch 3/20\n",
            "45/45 - 0s - loss: 0.5097 - accuracy: 0.6088 - val_loss: 0.4695 - val_accuracy: 0.8602 - lr: 0.0100 - 399ms/epoch - 9ms/step\n",
            "Epoch 4/20\n",
            "45/45 - 0s - loss: 0.4573 - accuracy: 0.8729 - val_loss: 0.4069 - val_accuracy: 0.8964 - lr: 0.0100 - 377ms/epoch - 8ms/step\n",
            "Epoch 5/20\n",
            "45/45 - 0s - loss: 0.4147 - accuracy: 0.8814 - val_loss: 0.3855 - val_accuracy: 0.8849 - lr: 0.0100 - 405ms/epoch - 9ms/step\n",
            "Epoch 6/20\n",
            "45/45 - 0s - loss: 0.3889 - accuracy: 0.8828 - val_loss: 0.3485 - val_accuracy: 0.8914 - lr: 0.0100 - 386ms/epoch - 9ms/step\n",
            "Epoch 7/20\n",
            "45/45 - 0s - loss: 0.3645 - accuracy: 0.8835 - val_loss: 0.3316 - val_accuracy: 0.8914 - lr: 0.0100 - 397ms/epoch - 9ms/step\n",
            "Epoch 8/20\n",
            "45/45 - 0s - loss: 0.3376 - accuracy: 0.8955 - val_loss: 0.3258 - val_accuracy: 0.8947 - lr: 0.0100 - 381ms/epoch - 8ms/step\n",
            "Epoch 9/20\n",
            "45/45 - 0s - loss: 0.3217 - accuracy: 0.8997 - val_loss: 0.3021 - val_accuracy: 0.9079 - lr: 0.0100 - 398ms/epoch - 9ms/step\n",
            "Epoch 10/20\n",
            "45/45 - 0s - loss: 0.3024 - accuracy: 0.9082 - val_loss: 0.3070 - val_accuracy: 0.9227 - lr: 0.0100 - 409ms/epoch - 9ms/step\n",
            "Epoch 11/20\n",
            "45/45 - 0s - loss: 0.2978 - accuracy: 0.9188 - val_loss: 0.3081 - val_accuracy: 0.9194 - lr: 0.0100 - 401ms/epoch - 9ms/step\n",
            "Epoch 12/20\n",
            "45/45 - 0s - loss: 0.2847 - accuracy: 0.9181 - val_loss: 0.2952 - val_accuracy: 0.9243 - lr: 0.0100 - 361ms/epoch - 8ms/step\n",
            "Epoch 13/20\n",
            "45/45 - 0s - loss: 0.2738 - accuracy: 0.9174 - val_loss: 0.2772 - val_accuracy: 0.9194 - lr: 0.0100 - 384ms/epoch - 9ms/step\n",
            "Epoch 14/20\n",
            "45/45 - 0s - loss: 0.2629 - accuracy: 0.9174 - val_loss: 0.2831 - val_accuracy: 0.9243 - lr: 0.0100 - 369ms/epoch - 8ms/step\n",
            "Epoch 15/20\n",
            "45/45 - 0s - loss: 0.2438 - accuracy: 0.9181 - val_loss: 0.2764 - val_accuracy: 0.9211 - lr: 0.0100 - 375ms/epoch - 8ms/step\n",
            "Epoch 16/20\n",
            "45/45 - 0s - loss: 0.2320 - accuracy: 0.9287 - val_loss: 0.2622 - val_accuracy: 0.9260 - lr: 0.0100 - 412ms/epoch - 9ms/step\n",
            "Epoch 17/20\n",
            "\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.2382 - accuracy: 0.9103 - val_loss: 0.2569 - val_accuracy: 0.9326 - lr: 0.0100 - 392ms/epoch - 9ms/step\n",
            "Epoch 18/20\n",
            "45/45 - 0s - loss: 0.2291 - accuracy: 0.9315 - val_loss: 0.2351 - val_accuracy: 0.9408 - lr: 1.0000e-03 - 384ms/epoch - 9ms/step\n",
            "Epoch 19/20\n",
            "45/45 - 0s - loss: 0.2245 - accuracy: 0.9329 - val_loss: 0.2486 - val_accuracy: 0.9408 - lr: 1.0000e-03 - 405ms/epoch - 9ms/step\n",
            "Epoch 20/20\n",
            "45/45 - 0s - loss: 0.2157 - accuracy: 0.9343 - val_loss: 0.2381 - val_accuracy: 0.9276 - lr: 1.0000e-03 - 413ms/epoch - 9ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2381 - accuracy: 0.9276\n",
            "Model: \"model_217\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_218 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_445 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_152 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_446 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "45/45 - 7s - loss: 0.8516 - accuracy: 0.5339 - val_loss: 0.6713 - val_accuracy: 0.5345 - lr: 0.0100 - 7s/epoch - 146ms/step\n",
            "Epoch 2/15\n",
            "45/45 - 0s - loss: 0.6627 - accuracy: 0.5339 - val_loss: 0.6452 - val_accuracy: 0.5345 - lr: 0.0100 - 368ms/epoch - 8ms/step\n",
            "Epoch 3/15\n",
            "45/45 - 0s - loss: 0.6410 - accuracy: 0.5339 - val_loss: 0.6265 - val_accuracy: 0.5345 - lr: 0.0100 - 374ms/epoch - 8ms/step\n",
            "Epoch 4/15\n",
            "45/45 - 0s - loss: 0.6244 - accuracy: 0.5339 - val_loss: 0.6111 - val_accuracy: 0.5345 - lr: 0.0100 - 403ms/epoch - 9ms/step\n",
            "Epoch 5/15\n",
            "45/45 - 0s - loss: 0.6100 - accuracy: 0.5339 - val_loss: 0.5974 - val_accuracy: 0.5345 - lr: 0.0100 - 368ms/epoch - 8ms/step\n",
            "Epoch 6/15\n",
            "45/45 - 0s - loss: 0.5968 - accuracy: 0.5438 - val_loss: 0.5842 - val_accuracy: 0.6102 - lr: 0.0100 - 392ms/epoch - 9ms/step\n",
            "Epoch 7/15\n",
            "45/45 - 0s - loss: 0.5842 - accuracy: 0.7500 - val_loss: 0.5715 - val_accuracy: 0.8339 - lr: 0.0100 - 379ms/epoch - 8ms/step\n",
            "Epoch 8/15\n",
            "45/45 - 0s - loss: 0.5716 - accuracy: 0.8326 - val_loss: 0.5583 - val_accuracy: 0.8651 - lr: 0.0100 - 374ms/epoch - 8ms/step\n",
            "Epoch 9/15\n",
            "45/45 - 0s - loss: 0.5582 - accuracy: 0.8503 - val_loss: 0.5440 - val_accuracy: 0.8865 - lr: 0.0100 - 409ms/epoch - 9ms/step\n",
            "Epoch 10/15\n",
            "45/45 - 0s - loss: 0.5441 - accuracy: 0.8602 - val_loss: 0.5283 - val_accuracy: 0.8914 - lr: 0.0100 - 390ms/epoch - 9ms/step\n",
            "Epoch 11/15\n",
            "45/45 - 0s - loss: 0.5278 - accuracy: 0.8799 - val_loss: 0.5105 - val_accuracy: 0.8964 - lr: 0.0100 - 379ms/epoch - 8ms/step\n",
            "Epoch 12/15\n",
            "45/45 - 0s - loss: 0.5109 - accuracy: 0.8814 - val_loss: 0.4941 - val_accuracy: 0.9030 - lr: 0.0100 - 395ms/epoch - 9ms/step\n",
            "Epoch 13/15\n",
            "45/45 - 0s - loss: 0.4956 - accuracy: 0.8941 - val_loss: 0.4783 - val_accuracy: 0.9046 - lr: 0.0100 - 368ms/epoch - 8ms/step\n",
            "Epoch 14/15\n",
            "45/45 - 0s - loss: 0.4801 - accuracy: 0.8990 - val_loss: 0.4624 - val_accuracy: 0.9079 - lr: 0.0100 - 399ms/epoch - 9ms/step\n",
            "Epoch 15/15\n",
            "45/45 - 0s - loss: 0.4650 - accuracy: 0.9054 - val_loss: 0.4467 - val_accuracy: 0.9128 - lr: 0.0100 - 369ms/epoch - 8ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.9128\n",
            "Model: \"model_219\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_220 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_450 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_153 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_451 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "45/45 - 6s - loss: 0.8193 - accuracy: 0.5282 - val_loss: 0.6942 - val_accuracy: 0.5477 - lr: 0.0100 - 6s/epoch - 124ms/step\n",
            "Epoch 2/25\n",
            "45/45 - 0s - loss: 0.6850 - accuracy: 0.5282 - val_loss: 0.6608 - val_accuracy: 0.5477 - lr: 0.0100 - 308ms/epoch - 7ms/step\n",
            "Epoch 3/25\n",
            "45/45 - 0s - loss: 0.6487 - accuracy: 0.5282 - val_loss: 0.6301 - val_accuracy: 0.5477 - lr: 0.0100 - 283ms/epoch - 6ms/step\n",
            "Epoch 4/25\n",
            "45/45 - 0s - loss: 0.6147 - accuracy: 0.5282 - val_loss: 0.5989 - val_accuracy: 0.5477 - lr: 0.0100 - 311ms/epoch - 7ms/step\n",
            "Epoch 5/25\n",
            "45/45 - 0s - loss: 0.5761 - accuracy: 0.5381 - val_loss: 0.5643 - val_accuracy: 0.5938 - lr: 0.0100 - 312ms/epoch - 7ms/step\n",
            "Epoch 6/25\n",
            "45/45 - 0s - loss: 0.5416 - accuracy: 0.7846 - val_loss: 0.5366 - val_accuracy: 0.8224 - lr: 0.0100 - 327ms/epoch - 7ms/step\n",
            "Epoch 7/25\n",
            "45/45 - 0s - loss: 0.5116 - accuracy: 0.8686 - val_loss: 0.5102 - val_accuracy: 0.8618 - lr: 0.0100 - 324ms/epoch - 7ms/step\n",
            "Epoch 8/25\n",
            "45/45 - 0s - loss: 0.4823 - accuracy: 0.8969 - val_loss: 0.4830 - val_accuracy: 0.8701 - lr: 0.0100 - 289ms/epoch - 6ms/step\n",
            "Epoch 9/25\n",
            "45/45 - 0s - loss: 0.4520 - accuracy: 0.9004 - val_loss: 0.4546 - val_accuracy: 0.8750 - lr: 0.0100 - 315ms/epoch - 7ms/step\n",
            "Epoch 10/25\n",
            "45/45 - 0s - loss: 0.4201 - accuracy: 0.8983 - val_loss: 0.4246 - val_accuracy: 0.8717 - lr: 0.0100 - 295ms/epoch - 7ms/step\n",
            "Epoch 11/25\n",
            "45/45 - 0s - loss: 0.3878 - accuracy: 0.8983 - val_loss: 0.3967 - val_accuracy: 0.8750 - lr: 0.0100 - 293ms/epoch - 7ms/step\n",
            "Epoch 12/25\n",
            "45/45 - 0s - loss: 0.3610 - accuracy: 0.8983 - val_loss: 0.3745 - val_accuracy: 0.8766 - lr: 0.0100 - 287ms/epoch - 6ms/step\n",
            "Epoch 13/25\n",
            "45/45 - 0s - loss: 0.3380 - accuracy: 0.8997 - val_loss: 0.3538 - val_accuracy: 0.8717 - lr: 0.0100 - 316ms/epoch - 7ms/step\n",
            "Epoch 14/25\n",
            "45/45 - 0s - loss: 0.3154 - accuracy: 0.9032 - val_loss: 0.3518 - val_accuracy: 0.8799 - lr: 0.0100 - 317ms/epoch - 7ms/step\n",
            "Epoch 15/25\n",
            "45/45 - 0s - loss: 0.3110 - accuracy: 0.9032 - val_loss: 0.3307 - val_accuracy: 0.8783 - lr: 0.0100 - 280ms/epoch - 6ms/step\n",
            "Epoch 16/25\n",
            "45/45 - 0s - loss: 0.2941 - accuracy: 0.9082 - val_loss: 0.3136 - val_accuracy: 0.8865 - lr: 0.0100 - 295ms/epoch - 7ms/step\n",
            "Epoch 17/25\n",
            "45/45 - 0s - loss: 0.2838 - accuracy: 0.9110 - val_loss: 0.3042 - val_accuracy: 0.8898 - lr: 0.0100 - 283ms/epoch - 6ms/step\n",
            "Epoch 18/25\n",
            "45/45 - 0s - loss: 0.2746 - accuracy: 0.9138 - val_loss: 0.2981 - val_accuracy: 0.8882 - lr: 0.0100 - 301ms/epoch - 7ms/step\n",
            "Epoch 19/25\n",
            "45/45 - 0s - loss: 0.2673 - accuracy: 0.9117 - val_loss: 0.3290 - val_accuracy: 0.8569 - lr: 0.0100 - 295ms/epoch - 7ms/step\n",
            "Epoch 20/25\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.2726 - accuracy: 0.9096 - val_loss: 0.2992 - val_accuracy: 0.9030 - lr: 0.0100 - 288ms/epoch - 6ms/step\n",
            "Epoch 21/25\n",
            "45/45 - 0s - loss: 0.2603 - accuracy: 0.9153 - val_loss: 0.2980 - val_accuracy: 0.9013 - lr: 1.0000e-03 - 297ms/epoch - 7ms/step\n",
            "Epoch 22/25\n",
            "45/45 - 0s - loss: 0.2591 - accuracy: 0.9167 - val_loss: 0.2970 - val_accuracy: 0.9062 - lr: 1.0000e-03 - 286ms/epoch - 6ms/step\n",
            "Epoch 23/25\n",
            "45/45 - 0s - loss: 0.2580 - accuracy: 0.9160 - val_loss: 0.2960 - val_accuracy: 0.9079 - lr: 1.0000e-03 - 298ms/epoch - 7ms/step\n",
            "Epoch 24/25\n",
            "45/45 - 0s - loss: 0.2570 - accuracy: 0.9167 - val_loss: 0.2950 - val_accuracy: 0.9079 - lr: 1.0000e-03 - 292ms/epoch - 6ms/step\n",
            "Epoch 25/25\n",
            "45/45 - 0s - loss: 0.2562 - accuracy: 0.9195 - val_loss: 0.2942 - val_accuracy: 0.9062 - lr: 1.0000e-03 - 313ms/epoch - 7ms/step\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2942 - accuracy: 0.9062\n",
            "Model: \"model_221\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_222 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_454 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_155 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_455 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "45/45 - 5s - loss: 0.5332 - accuracy: 0.7980 - val_loss: 0.3607 - val_accuracy: 0.9095 - lr: 0.0100 - 5s/epoch - 103ms/step\n",
            "Epoch 2/20\n",
            "45/45 - 0s - loss: 0.3873 - accuracy: 0.9004 - val_loss: 0.3768 - val_accuracy: 0.8997 - lr: 0.0100 - 305ms/epoch - 7ms/step\n",
            "Epoch 3/20\n",
            "45/45 - 0s - loss: 0.3425 - accuracy: 0.9040 - val_loss: 0.3396 - val_accuracy: 0.9046 - lr: 0.0100 - 332ms/epoch - 7ms/step\n",
            "Epoch 4/20\n",
            "45/45 - 0s - loss: 0.3321 - accuracy: 0.9018 - val_loss: 0.3292 - val_accuracy: 0.8898 - lr: 0.0100 - 326ms/epoch - 7ms/step\n",
            "Epoch 5/20\n",
            "45/45 - 0s - loss: 0.3047 - accuracy: 0.8927 - val_loss: 0.2985 - val_accuracy: 0.8964 - lr: 0.0100 - 278ms/epoch - 6ms/step\n",
            "Epoch 6/20\n",
            "45/45 - 0s - loss: 0.2778 - accuracy: 0.9082 - val_loss: 0.2706 - val_accuracy: 0.9145 - lr: 0.0100 - 276ms/epoch - 6ms/step\n",
            "Epoch 7/20\n",
            "45/45 - 0s - loss: 0.2654 - accuracy: 0.9110 - val_loss: 0.2818 - val_accuracy: 0.8980 - lr: 0.0100 - 322ms/epoch - 7ms/step\n",
            "Epoch 8/20\n",
            "45/45 - 0s - loss: 0.2570 - accuracy: 0.9145 - val_loss: 0.2606 - val_accuracy: 0.9194 - lr: 0.0100 - 321ms/epoch - 7ms/step\n",
            "Epoch 9/20\n",
            "45/45 - 0s - loss: 0.2567 - accuracy: 0.9124 - val_loss: 0.2713 - val_accuracy: 0.9062 - lr: 0.0100 - 288ms/epoch - 6ms/step\n",
            "Epoch 10/20\n",
            "45/45 - 0s - loss: 0.2464 - accuracy: 0.9202 - val_loss: 0.2495 - val_accuracy: 0.9095 - lr: 0.0100 - 307ms/epoch - 7ms/step\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.2741 - accuracy: 0.9195 - val_loss: 0.2720 - val_accuracy: 0.8964 - lr: 0.0100 - 305ms/epoch - 7ms/step\n",
            "Epoch 12/20\n",
            "45/45 - 0s - loss: 0.2414 - accuracy: 0.9160 - val_loss: 0.2473 - val_accuracy: 0.9178 - lr: 1.0000e-03 - 276ms/epoch - 6ms/step\n",
            "Epoch 13/20\n",
            "45/45 - 0s - loss: 0.2305 - accuracy: 0.9223 - val_loss: 0.2403 - val_accuracy: 0.9211 - lr: 1.0000e-03 - 275ms/epoch - 6ms/step\n",
            "Epoch 14/20\n",
            "45/45 - 0s - loss: 0.2259 - accuracy: 0.9223 - val_loss: 0.2409 - val_accuracy: 0.9194 - lr: 1.0000e-03 - 276ms/epoch - 6ms/step\n",
            "Epoch 15/20\n",
            "45/45 - 0s - loss: 0.2238 - accuracy: 0.9237 - val_loss: 0.2412 - val_accuracy: 0.9194 - lr: 1.0000e-03 - 287ms/epoch - 6ms/step\n",
            "Epoch 16/20\n",
            "45/45 - 0s - loss: 0.2226 - accuracy: 0.9216 - val_loss: 0.2394 - val_accuracy: 0.9194 - lr: 1.0000e-03 - 266ms/epoch - 6ms/step\n",
            "Epoch 17/20\n",
            "45/45 - 0s - loss: 0.2219 - accuracy: 0.9251 - val_loss: 0.2407 - val_accuracy: 0.9194 - lr: 1.0000e-03 - 270ms/epoch - 6ms/step\n",
            "Epoch 18/20\n",
            "45/45 - 0s - loss: 0.2212 - accuracy: 0.9223 - val_loss: 0.2399 - val_accuracy: 0.9178 - lr: 1.0000e-03 - 281ms/epoch - 6ms/step\n",
            "Epoch 19/20\n",
            "45/45 - 0s - loss: 0.2201 - accuracy: 0.9237 - val_loss: 0.2379 - val_accuracy: 0.9178 - lr: 1.0000e-03 - 294ms/epoch - 7ms/step\n",
            "Epoch 20/20\n",
            "45/45 - 0s - loss: 0.2198 - accuracy: 0.9266 - val_loss: 0.2377 - val_accuracy: 0.9178 - lr: 1.0000e-03 - 306ms/epoch - 7ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2377 - accuracy: 0.9178\n",
            "Model: \"model_223\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_224 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_458 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_156 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_459 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "45/45 - 5s - loss: 0.6409 - accuracy: 0.7196 - val_loss: 0.3921 - val_accuracy: 0.8799 - lr: 0.0100 - 5s/epoch - 121ms/step\n",
            "Epoch 2/20\n",
            "45/45 - 0s - loss: 0.4186 - accuracy: 0.8715 - val_loss: 0.3722 - val_accuracy: 0.8882 - lr: 0.0100 - 312ms/epoch - 7ms/step\n",
            "Epoch 3/20\n",
            "45/45 - 0s - loss: 0.3750 - accuracy: 0.8729 - val_loss: 0.3179 - val_accuracy: 0.8882 - lr: 0.0100 - 276ms/epoch - 6ms/step\n",
            "Epoch 4/20\n",
            "45/45 - 0s - loss: 0.3458 - accuracy: 0.8785 - val_loss: 0.3042 - val_accuracy: 0.8997 - lr: 0.0100 - 319ms/epoch - 7ms/step\n",
            "Epoch 5/20\n",
            "45/45 - 0s - loss: 0.3258 - accuracy: 0.8835 - val_loss: 0.3217 - val_accuracy: 0.9128 - lr: 0.0100 - 289ms/epoch - 6ms/step\n",
            "Epoch 6/20\n",
            "45/45 - 0s - loss: 0.3175 - accuracy: 0.8863 - val_loss: 0.3046 - val_accuracy: 0.9112 - lr: 0.0100 - 312ms/epoch - 7ms/step\n",
            "Epoch 7/20\n",
            "45/45 - 0s - loss: 0.3107 - accuracy: 0.8919 - val_loss: 0.2905 - val_accuracy: 0.9079 - lr: 0.0100 - 300ms/epoch - 7ms/step\n",
            "Epoch 8/20\n",
            "45/45 - 0s - loss: 0.2920 - accuracy: 0.8877 - val_loss: 0.2833 - val_accuracy: 0.9112 - lr: 0.0100 - 307ms/epoch - 7ms/step\n",
            "Epoch 9/20\n",
            "45/45 - 0s - loss: 0.2908 - accuracy: 0.8948 - val_loss: 0.2718 - val_accuracy: 0.9079 - lr: 0.0100 - 285ms/epoch - 6ms/step\n",
            "Epoch 10/20\n",
            "45/45 - 0s - loss: 0.2811 - accuracy: 0.8990 - val_loss: 0.2646 - val_accuracy: 0.9079 - lr: 0.0100 - 309ms/epoch - 7ms/step\n",
            "Epoch 11/20\n",
            "45/45 - 0s - loss: 0.2666 - accuracy: 0.8969 - val_loss: 0.3115 - val_accuracy: 0.8980 - lr: 0.0100 - 322ms/epoch - 7ms/step\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.2819 - accuracy: 0.8990 - val_loss: 0.2260 - val_accuracy: 0.9046 - lr: 0.0100 - 275ms/epoch - 6ms/step\n",
            "Epoch 13/20\n",
            "45/45 - 0s - loss: 0.2561 - accuracy: 0.8948 - val_loss: 0.2263 - val_accuracy: 0.9062 - lr: 1.0000e-03 - 281ms/epoch - 6ms/step\n",
            "Epoch 14/20\n",
            "45/45 - 0s - loss: 0.2535 - accuracy: 0.8976 - val_loss: 0.2277 - val_accuracy: 0.9095 - lr: 1.0000e-03 - 280ms/epoch - 6ms/step\n",
            "Epoch 15/20\n",
            "45/45 - 0s - loss: 0.2518 - accuracy: 0.8983 - val_loss: 0.2436 - val_accuracy: 0.9112 - lr: 1.0000e-03 - 274ms/epoch - 6ms/step\n",
            "Epoch 16/20\n",
            "45/45 - 0s - loss: 0.2501 - accuracy: 0.9018 - val_loss: 0.2445 - val_accuracy: 0.9095 - lr: 1.0000e-03 - 311ms/epoch - 7ms/step\n",
            "Epoch 17/20\n",
            "45/45 - 0s - loss: 0.2486 - accuracy: 0.9018 - val_loss: 0.2620 - val_accuracy: 0.9112 - lr: 1.0000e-03 - 314ms/epoch - 7ms/step\n",
            "Epoch 18/20\n",
            "45/45 - 0s - loss: 0.2476 - accuracy: 0.9047 - val_loss: 0.2612 - val_accuracy: 0.9128 - lr: 1.0000e-03 - 274ms/epoch - 6ms/step\n",
            "Epoch 19/20\n",
            "45/45 - 0s - loss: 0.2464 - accuracy: 0.9047 - val_loss: 0.2608 - val_accuracy: 0.9112 - lr: 1.0000e-03 - 286ms/epoch - 6ms/step\n",
            "Epoch 20/20\n",
            "45/45 - 0s - loss: 0.2452 - accuracy: 0.9054 - val_loss: 0.2591 - val_accuracy: 0.9161 - lr: 1.0000e-03 - 298ms/epoch - 7ms/step\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2591 - accuracy: 0.9161\n",
            "  Evaluated 28 individuals\n",
            "  Min 0.5345394611358643\n",
            "  Max 0.9342105388641357\n",
            "  Avg 0.8695723672707876\n",
            "  Std 0.10852035950932658\n",
            "-- Generation 4 --\n",
            "Model: \"model_225\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_226 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_462 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_157 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_463 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "45/45 - 5s - loss: 1.6292 - accuracy: 0.5325 - val_loss: 0.6270 - val_accuracy: 0.5378 - lr: 0.0100 - 5s/epoch - 102ms/step\n",
            "Epoch 2/20\n",
            "45/45 - 0s - loss: 0.5747 - accuracy: 0.5346 - val_loss: 0.5475 - val_accuracy: 0.5526 - lr: 0.0100 - 286ms/epoch - 6ms/step\n",
            "Epoch 3/20\n",
            "45/45 - 0s - loss: 0.5036 - accuracy: 0.6370 - val_loss: 0.5023 - val_accuracy: 0.7451 - lr: 0.0100 - 308ms/epoch - 7ms/step\n",
            "Epoch 4/20\n",
            "45/45 - 0s - loss: 0.4647 - accuracy: 0.8475 - val_loss: 0.4771 - val_accuracy: 0.8470 - lr: 0.0100 - 312ms/epoch - 7ms/step\n",
            "Epoch 5/20\n",
            "45/45 - 0s - loss: 0.4399 - accuracy: 0.8785 - val_loss: 0.4602 - val_accuracy: 0.8454 - lr: 0.0100 - 285ms/epoch - 6ms/step\n",
            "Epoch 6/20\n",
            "45/45 - 0s - loss: 0.4207 - accuracy: 0.8884 - val_loss: 0.4472 - val_accuracy: 0.8421 - lr: 0.0100 - 267ms/epoch - 6ms/step\n",
            "Epoch 7/20\n",
            "45/45 - 0s - loss: 0.4059 - accuracy: 0.8905 - val_loss: 0.4368 - val_accuracy: 0.8405 - lr: 0.0100 - 272ms/epoch - 6ms/step\n",
            "Epoch 8/20\n",
            "45/45 - 0s - loss: 0.3940 - accuracy: 0.8905 - val_loss: 0.4284 - val_accuracy: 0.8405 - lr: 0.0100 - 268ms/epoch - 6ms/step\n",
            "Epoch 9/20\n",
            "45/45 - 0s - loss: 0.3836 - accuracy: 0.8912 - val_loss: 0.4222 - val_accuracy: 0.8405 - lr: 0.0100 - 322ms/epoch - 7ms/step\n",
            "Epoch 10/20\n",
            "45/45 - 0s - loss: 0.3744 - accuracy: 0.8898 - val_loss: 0.4164 - val_accuracy: 0.8405 - lr: 0.0100 - 306ms/epoch - 7ms/step\n",
            "Epoch 11/20\n",
            "45/45 - 0s - loss: 0.3668 - accuracy: 0.8884 - val_loss: 0.4116 - val_accuracy: 0.8405 - lr: 0.0100 - 288ms/epoch - 6ms/step\n",
            "Epoch 12/20\n",
            "45/45 - 0s - loss: 0.3602 - accuracy: 0.8891 - val_loss: 0.4076 - val_accuracy: 0.8405 - lr: 0.0100 - 324ms/epoch - 7ms/step\n",
            "Epoch 13/20\n",
            "45/45 - 0s - loss: 0.3545 - accuracy: 0.8891 - val_loss: 0.4072 - val_accuracy: 0.8405 - lr: 0.0100 - 306ms/epoch - 7ms/step\n",
            "Epoch 14/20\n",
            "45/45 - 0s - loss: 0.3489 - accuracy: 0.8884 - val_loss: 0.3995 - val_accuracy: 0.8405 - lr: 0.0100 - 304ms/epoch - 7ms/step\n",
            "Epoch 15/20\n",
            "45/45 - 0s - loss: 0.3439 - accuracy: 0.8884 - val_loss: 0.3994 - val_accuracy: 0.8405 - lr: 0.0100 - 299ms/epoch - 7ms/step\n",
            "Epoch 16/20\n",
            "45/45 - 0s - loss: 0.3394 - accuracy: 0.8884 - val_loss: 0.3988 - val_accuracy: 0.8405 - lr: 0.0100 - 304ms/epoch - 7ms/step\n",
            "Epoch 17/20\n",
            "45/45 - 0s - loss: 0.3356 - accuracy: 0.8884 - val_loss: 0.3906 - val_accuracy: 0.8405 - lr: 0.0100 - 276ms/epoch - 6ms/step\n",
            "Epoch 18/20\n",
            "45/45 - 0s - loss: 0.3313 - accuracy: 0.8884 - val_loss: 0.3910 - val_accuracy: 0.8405 - lr: 0.0100 - 302ms/epoch - 7ms/step\n",
            "Epoch 19/20\n",
            "45/45 - 0s - loss: 0.3272 - accuracy: 0.8884 - val_loss: 0.3841 - val_accuracy: 0.8405 - lr: 0.0100 - 294ms/epoch - 7ms/step\n",
            "Epoch 20/20\n",
            "45/45 - 0s - loss: 0.3253 - accuracy: 0.8884 - val_loss: 0.3842 - val_accuracy: 0.8405 - lr: 0.0100 - 281ms/epoch - 6ms/step\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3842 - accuracy: 0.8405\n",
            "Model: \"model_227\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_228 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_466 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_158 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_467 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "45/45 - 5s - loss: 1.1902 - accuracy: 0.5318 - val_loss: 0.6125 - val_accuracy: 0.5378 - lr: 0.0100 - 5s/epoch - 106ms/step\n",
            "Epoch 2/15\n",
            "45/45 - 0s - loss: 0.5531 - accuracy: 0.5346 - val_loss: 0.5535 - val_accuracy: 0.5543 - lr: 0.0100 - 280ms/epoch - 6ms/step\n",
            "Epoch 3/15\n",
            "45/45 - 0s - loss: 0.5012 - accuracy: 0.6751 - val_loss: 0.5135 - val_accuracy: 0.7664 - lr: 0.0100 - 303ms/epoch - 7ms/step\n",
            "Epoch 4/15\n",
            "45/45 - 0s - loss: 0.4660 - accuracy: 0.7938 - val_loss: 0.4838 - val_accuracy: 0.8109 - lr: 0.0100 - 297ms/epoch - 7ms/step\n",
            "Epoch 5/15\n",
            "45/45 - 0s - loss: 0.4391 - accuracy: 0.8425 - val_loss: 0.4589 - val_accuracy: 0.8520 - lr: 0.0100 - 308ms/epoch - 7ms/step\n",
            "Epoch 6/15\n",
            "45/45 - 0s - loss: 0.4131 - accuracy: 0.8686 - val_loss: 0.4359 - val_accuracy: 0.8684 - lr: 0.0100 - 291ms/epoch - 6ms/step\n",
            "Epoch 7/15\n",
            "45/45 - 0s - loss: 0.3938 - accuracy: 0.8849 - val_loss: 0.4301 - val_accuracy: 0.8635 - lr: 0.0100 - 304ms/epoch - 7ms/step\n",
            "Epoch 8/15\n",
            "45/45 - 0s - loss: 0.3730 - accuracy: 0.8863 - val_loss: 0.4012 - val_accuracy: 0.8586 - lr: 0.0100 - 312ms/epoch - 7ms/step\n",
            "Epoch 9/15\n",
            "45/45 - 0s - loss: 0.3566 - accuracy: 0.8912 - val_loss: 0.4010 - val_accuracy: 0.8668 - lr: 0.0100 - 303ms/epoch - 7ms/step\n",
            "Epoch 10/15\n",
            "45/45 - 0s - loss: 0.3436 - accuracy: 0.8905 - val_loss: 0.3904 - val_accuracy: 0.8717 - lr: 0.0100 - 277ms/epoch - 6ms/step\n",
            "Epoch 11/15\n",
            "45/45 - 0s - loss: 0.3383 - accuracy: 0.8941 - val_loss: 0.3623 - val_accuracy: 0.8717 - lr: 0.0100 - 286ms/epoch - 6ms/step\n",
            "Epoch 12/15\n",
            "45/45 - 0s - loss: 0.3254 - accuracy: 0.8934 - val_loss: 0.3908 - val_accuracy: 0.8783 - lr: 0.0100 - 275ms/epoch - 6ms/step\n",
            "Epoch 13/15\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.3263 - accuracy: 0.8948 - val_loss: 0.3653 - val_accuracy: 0.8816 - lr: 0.0100 - 270ms/epoch - 6ms/step\n",
            "Epoch 14/15\n",
            "45/45 - 0s - loss: 0.3067 - accuracy: 0.8997 - val_loss: 0.3650 - val_accuracy: 0.8783 - lr: 1.0000e-03 - 295ms/epoch - 7ms/step\n",
            "Epoch 15/15\n",
            "45/45 - 0s - loss: 0.3056 - accuracy: 0.8976 - val_loss: 0.3651 - val_accuracy: 0.8766 - lr: 1.0000e-03 - 297ms/epoch - 7ms/step\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3651 - accuracy: 0.8766\n",
            "Model: \"model_229\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_230 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_470 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_159 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_471 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "45/45 - 5s - loss: 1.4844 - accuracy: 0.5374 - val_loss: 0.6999 - val_accuracy: 0.5263 - lr: 0.0100 - 5s/epoch - 117ms/step\n",
            "Epoch 2/25\n",
            "45/45 - 0s - loss: 0.6909 - accuracy: 0.5374 - val_loss: 0.6884 - val_accuracy: 0.5263 - lr: 0.0100 - 294ms/epoch - 7ms/step\n",
            "Epoch 3/25\n",
            "45/45 - 0s - loss: 0.6805 - accuracy: 0.5374 - val_loss: 0.6784 - val_accuracy: 0.5263 - lr: 0.0100 - 286ms/epoch - 6ms/step\n",
            "Epoch 4/25\n",
            "45/45 - 0s - loss: 0.6712 - accuracy: 0.5374 - val_loss: 0.6691 - val_accuracy: 0.5263 - lr: 0.0100 - 315ms/epoch - 7ms/step\n",
            "Epoch 5/25\n",
            "45/45 - 0s - loss: 0.6623 - accuracy: 0.5374 - val_loss: 0.6601 - val_accuracy: 0.5263 - lr: 0.0100 - 296ms/epoch - 7ms/step\n",
            "Epoch 6/25\n",
            "45/45 - 0s - loss: 0.6537 - accuracy: 0.5374 - val_loss: 0.6515 - val_accuracy: 0.5263 - lr: 0.0100 - 316ms/epoch - 7ms/step\n",
            "Epoch 7/25\n",
            "45/45 - 0s - loss: 0.6453 - accuracy: 0.5374 - val_loss: 0.6428 - val_accuracy: 0.5263 - lr: 0.0100 - 315ms/epoch - 7ms/step\n",
            "Epoch 8/25\n",
            "45/45 - 0s - loss: 0.6369 - accuracy: 0.5374 - val_loss: 0.6345 - val_accuracy: 0.5263 - lr: 0.0100 - 298ms/epoch - 7ms/step\n",
            "Epoch 9/25\n",
            "45/45 - 0s - loss: 0.6287 - accuracy: 0.8425 - val_loss: 0.6261 - val_accuracy: 0.8684 - lr: 0.0100 - 295ms/epoch - 7ms/step\n",
            "Epoch 10/25\n",
            "45/45 - 0s - loss: 0.6204 - accuracy: 0.8771 - val_loss: 0.6178 - val_accuracy: 0.8684 - lr: 0.0100 - 312ms/epoch - 7ms/step\n",
            "Epoch 11/25\n",
            "45/45 - 0s - loss: 0.6120 - accuracy: 0.8771 - val_loss: 0.6096 - val_accuracy: 0.8684 - lr: 0.0100 - 319ms/epoch - 7ms/step\n",
            "Epoch 12/25\n",
            "45/45 - 0s - loss: 0.6038 - accuracy: 0.8771 - val_loss: 0.6014 - val_accuracy: 0.8684 - lr: 0.0100 - 281ms/epoch - 6ms/step\n",
            "Epoch 13/25\n",
            "45/45 - 0s - loss: 0.5955 - accuracy: 0.8771 - val_loss: 0.5930 - val_accuracy: 0.8684 - lr: 0.0100 - 287ms/epoch - 6ms/step\n",
            "Epoch 14/25\n",
            "45/45 - 0s - loss: 0.5871 - accuracy: 0.8771 - val_loss: 0.5846 - val_accuracy: 0.8684 - lr: 0.0100 - 280ms/epoch - 6ms/step\n",
            "Epoch 15/25\n",
            "45/45 - 0s - loss: 0.5786 - accuracy: 0.8771 - val_loss: 0.5761 - val_accuracy: 0.8684 - lr: 0.0100 - 306ms/epoch - 7ms/step\n",
            "Epoch 16/25\n",
            "45/45 - 0s - loss: 0.5700 - accuracy: 0.8771 - val_loss: 0.5675 - val_accuracy: 0.8684 - lr: 0.0100 - 310ms/epoch - 7ms/step\n",
            "Epoch 17/25\n",
            "45/45 - 0s - loss: 0.5615 - accuracy: 0.8771 - val_loss: 0.5591 - val_accuracy: 0.8684 - lr: 0.0100 - 327ms/epoch - 7ms/step\n",
            "Epoch 18/25\n",
            "45/45 - 0s - loss: 0.5530 - accuracy: 0.8771 - val_loss: 0.5507 - val_accuracy: 0.8684 - lr: 0.0100 - 323ms/epoch - 7ms/step\n",
            "Epoch 19/25\n",
            "45/45 - 0s - loss: 0.5445 - accuracy: 0.8771 - val_loss: 0.5422 - val_accuracy: 0.8684 - lr: 0.0100 - 290ms/epoch - 6ms/step\n",
            "Epoch 20/25\n",
            "45/45 - 0s - loss: 0.5361 - accuracy: 0.8771 - val_loss: 0.5338 - val_accuracy: 0.8684 - lr: 0.0100 - 314ms/epoch - 7ms/step\n",
            "Epoch 21/25\n",
            "45/45 - 0s - loss: 0.5276 - accuracy: 0.8771 - val_loss: 0.5255 - val_accuracy: 0.8684 - lr: 0.0100 - 314ms/epoch - 7ms/step\n",
            "Epoch 22/25\n",
            "45/45 - 0s - loss: 0.5192 - accuracy: 0.8771 - val_loss: 0.5173 - val_accuracy: 0.8684 - lr: 0.0100 - 338ms/epoch - 8ms/step\n",
            "Epoch 23/25\n",
            "45/45 - 0s - loss: 0.5110 - accuracy: 0.8771 - val_loss: 0.5092 - val_accuracy: 0.8684 - lr: 0.0100 - 329ms/epoch - 7ms/step\n",
            "Epoch 24/25\n",
            "45/45 - 0s - loss: 0.5028 - accuracy: 0.8771 - val_loss: 0.5013 - val_accuracy: 0.8684 - lr: 0.0100 - 298ms/epoch - 7ms/step\n",
            "Epoch 25/25\n",
            "45/45 - 0s - loss: 0.4948 - accuracy: 0.8771 - val_loss: 0.4935 - val_accuracy: 0.8684 - lr: 0.0100 - 287ms/epoch - 6ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4935 - accuracy: 0.8684\n",
            "Model: \"model_231\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_232 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_474 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_161 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_475 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "45/45 - 5s - loss: 0.7545 - accuracy: 0.5290 - val_loss: 0.4885 - val_accuracy: 0.5461 - lr: 0.0100 - 5s/epoch - 104ms/step\n",
            "Epoch 2/25\n",
            "45/45 - 0s - loss: 0.4788 - accuracy: 0.6829 - val_loss: 0.4227 - val_accuracy: 0.8947 - lr: 0.0100 - 289ms/epoch - 6ms/step\n",
            "Epoch 3/25\n",
            "45/45 - 0s - loss: 0.4205 - accuracy: 0.8835 - val_loss: 0.3687 - val_accuracy: 0.9243 - lr: 0.0100 - 305ms/epoch - 7ms/step\n",
            "Epoch 4/25\n",
            "45/45 - 0s - loss: 0.3818 - accuracy: 0.8948 - val_loss: 0.3414 - val_accuracy: 0.9194 - lr: 0.0100 - 315ms/epoch - 7ms/step\n",
            "Epoch 5/25\n",
            "45/45 - 0s - loss: 0.3567 - accuracy: 0.8919 - val_loss: 0.3157 - val_accuracy: 0.9062 - lr: 0.0100 - 332ms/epoch - 7ms/step\n",
            "Epoch 6/25\n",
            "45/45 - 0s - loss: 0.3414 - accuracy: 0.8912 - val_loss: 0.2859 - val_accuracy: 0.9243 - lr: 0.0100 - 315ms/epoch - 7ms/step\n",
            "Epoch 7/25\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.3476 - accuracy: 0.8934 - val_loss: 0.2711 - val_accuracy: 0.9260 - lr: 0.0100 - 308ms/epoch - 7ms/step\n",
            "Epoch 8/25\n",
            "45/45 - 0s - loss: 0.3132 - accuracy: 0.9004 - val_loss: 0.2679 - val_accuracy: 0.9260 - lr: 1.0000e-03 - 288ms/epoch - 6ms/step\n",
            "Epoch 9/25\n",
            "45/45 - 0s - loss: 0.3111 - accuracy: 0.9018 - val_loss: 0.2656 - val_accuracy: 0.9227 - lr: 1.0000e-03 - 306ms/epoch - 7ms/step\n",
            "Epoch 10/25\n",
            "45/45 - 0s - loss: 0.3083 - accuracy: 0.9018 - val_loss: 0.2654 - val_accuracy: 0.9260 - lr: 1.0000e-03 - 290ms/epoch - 6ms/step\n",
            "Epoch 11/25\n",
            "45/45 - 0s - loss: 0.3080 - accuracy: 0.9018 - val_loss: 0.2623 - val_accuracy: 0.9260 - lr: 1.0000e-03 - 300ms/epoch - 7ms/step\n",
            "Epoch 12/25\n",
            "45/45 - 0s - loss: 0.3053 - accuracy: 0.9011 - val_loss: 0.2614 - val_accuracy: 0.9260 - lr: 1.0000e-03 - 292ms/epoch - 6ms/step\n",
            "Epoch 13/25\n",
            "45/45 - 0s - loss: 0.3038 - accuracy: 0.9032 - val_loss: 0.2598 - val_accuracy: 0.9260 - lr: 1.0000e-03 - 317ms/epoch - 7ms/step\n",
            "Epoch 14/25\n",
            "45/45 - 0s - loss: 0.2936 - accuracy: 0.9061 - val_loss: 0.2587 - val_accuracy: 0.9260 - lr: 1.0000e-03 - 335ms/epoch - 7ms/step\n",
            "Epoch 15/25\n",
            "45/45 - 0s - loss: 0.2909 - accuracy: 0.9025 - val_loss: 0.2581 - val_accuracy: 0.9260 - lr: 1.0000e-03 - 283ms/epoch - 6ms/step\n",
            "Epoch 16/25\n",
            "45/45 - 0s - loss: 0.2889 - accuracy: 0.9054 - val_loss: 0.2576 - val_accuracy: 0.9161 - lr: 1.0000e-03 - 274ms/epoch - 6ms/step\n",
            "Epoch 17/25\n",
            "45/45 - 0s - loss: 0.2876 - accuracy: 0.9032 - val_loss: 0.2540 - val_accuracy: 0.9260 - lr: 1.0000e-03 - 332ms/epoch - 7ms/step\n",
            "Epoch 18/25\n",
            "45/45 - 0s - loss: 0.2856 - accuracy: 0.9040 - val_loss: 0.2520 - val_accuracy: 0.9260 - lr: 1.0000e-03 - 283ms/epoch - 6ms/step\n",
            "Epoch 19/25\n",
            "45/45 - 0s - loss: 0.2842 - accuracy: 0.9047 - val_loss: 0.2510 - val_accuracy: 0.9260 - lr: 1.0000e-03 - 288ms/epoch - 6ms/step\n",
            "Epoch 20/25\n",
            "45/45 - 0s - loss: 0.2819 - accuracy: 0.9047 - val_loss: 0.2512 - val_accuracy: 0.9243 - lr: 1.0000e-03 - 316ms/epoch - 7ms/step\n",
            "Epoch 21/25\n",
            "45/45 - 0s - loss: 0.2812 - accuracy: 0.9068 - val_loss: 0.2473 - val_accuracy: 0.9260 - lr: 1.0000e-03 - 301ms/epoch - 7ms/step\n",
            "Epoch 22/25\n",
            "45/45 - 0s - loss: 0.2796 - accuracy: 0.9075 - val_loss: 0.2464 - val_accuracy: 0.9243 - lr: 1.0000e-03 - 269ms/epoch - 6ms/step\n",
            "Epoch 23/25\n",
            "45/45 - 0s - loss: 0.2784 - accuracy: 0.9047 - val_loss: 0.2446 - val_accuracy: 0.9260 - lr: 1.0000e-03 - 273ms/epoch - 6ms/step\n",
            "Epoch 24/25\n",
            "45/45 - 0s - loss: 0.2760 - accuracy: 0.9096 - val_loss: 0.2430 - val_accuracy: 0.9243 - lr: 1.0000e-03 - 315ms/epoch - 7ms/step\n",
            "Epoch 25/25\n",
            "\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 0.2762 - accuracy: 0.9054 - val_loss: 0.2412 - val_accuracy: 0.9276 - lr: 1.0000e-03 - 313ms/epoch - 7ms/step\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2412 - accuracy: 0.9276\n",
            "Model: \"model_233\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_234 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_478 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_162 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_479 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "45/45 - 8s - loss: 0.7325 - accuracy: 0.5290 - val_loss: 0.6019 - val_accuracy: 0.5461 - lr: 0.0100 - 8s/epoch - 168ms/step\n",
            "Epoch 2/20\n",
            "45/45 - 0s - loss: 0.5812 - accuracy: 0.6589 - val_loss: 0.5551 - val_accuracy: 0.8421 - lr: 0.0100 - 371ms/epoch - 8ms/step\n",
            "Epoch 3/20\n",
            "45/45 - 0s - loss: 0.5385 - accuracy: 0.8729 - val_loss: 0.5174 - val_accuracy: 0.8651 - lr: 0.0100 - 365ms/epoch - 8ms/step\n",
            "Epoch 4/20\n",
            "45/45 - 0s - loss: 0.5018 - accuracy: 0.8722 - val_loss: 0.4848 - val_accuracy: 0.8717 - lr: 0.0100 - 378ms/epoch - 8ms/step\n",
            "Epoch 5/20\n",
            "45/45 - 0s - loss: 0.4700 - accuracy: 0.8729 - val_loss: 0.4569 - val_accuracy: 0.8717 - lr: 0.0100 - 402ms/epoch - 9ms/step\n",
            "Epoch 6/20\n",
            "45/45 - 0s - loss: 0.4436 - accuracy: 0.8736 - val_loss: 0.4333 - val_accuracy: 0.8734 - lr: 0.0100 - 384ms/epoch - 9ms/step\n",
            "Epoch 7/20\n",
            "45/45 - 0s - loss: 0.4213 - accuracy: 0.8750 - val_loss: 0.4137 - val_accuracy: 0.8750 - lr: 0.0100 - 381ms/epoch - 8ms/step\n",
            "Epoch 8/20\n",
            "45/45 - 0s - loss: 0.4014 - accuracy: 0.8778 - val_loss: 0.3957 - val_accuracy: 0.8783 - lr: 0.0100 - 381ms/epoch - 8ms/step\n",
            "Epoch 9/20\n",
            "45/45 - 0s - loss: 0.3826 - accuracy: 0.8814 - val_loss: 0.3771 - val_accuracy: 0.8783 - lr: 0.0100 - 393ms/epoch - 9ms/step\n",
            "Epoch 10/20\n",
            "45/45 - 0s - loss: 0.3656 - accuracy: 0.8821 - val_loss: 0.3627 - val_accuracy: 0.8783 - lr: 0.0100 - 408ms/epoch - 9ms/step\n",
            "Epoch 11/20\n",
            "45/45 - 0s - loss: 0.3512 - accuracy: 0.8835 - val_loss: 0.3491 - val_accuracy: 0.8816 - lr: 0.0100 - 403ms/epoch - 9ms/step\n",
            "Epoch 12/20\n",
            "45/45 - 0s - loss: 0.3376 - accuracy: 0.8870 - val_loss: 0.3369 - val_accuracy: 0.8882 - lr: 0.0100 - 391ms/epoch - 9ms/step\n",
            "Epoch 13/20\n",
            "45/45 - 0s - loss: 0.3252 - accuracy: 0.8898 - val_loss: 0.3278 - val_accuracy: 0.8914 - lr: 0.0100 - 380ms/epoch - 8ms/step\n",
            "Epoch 14/20\n",
            "45/45 - 0s - loss: 0.3145 - accuracy: 0.8912 - val_loss: 0.3183 - val_accuracy: 0.8898 - lr: 0.0100 - 371ms/epoch - 8ms/step\n",
            "Epoch 15/20\n",
            "45/45 - 0s - loss: 0.3033 - accuracy: 0.8934 - val_loss: 0.3064 - val_accuracy: 0.8914 - lr: 0.0100 - 379ms/epoch - 8ms/step\n",
            "Epoch 16/20\n",
            "45/45 - 0s - loss: 0.2935 - accuracy: 0.8969 - val_loss: 0.2995 - val_accuracy: 0.8931 - lr: 0.0100 - 386ms/epoch - 9ms/step\n",
            "Epoch 17/20\n",
            "45/45 - 0s - loss: 0.2866 - accuracy: 0.8976 - val_loss: 0.3013 - val_accuracy: 0.8914 - lr: 0.0100 - 373ms/epoch - 8ms/step\n",
            "Epoch 18/20\n",
            "45/45 - 0s - loss: 0.2791 - accuracy: 0.8990 - val_loss: 0.2841 - val_accuracy: 0.8964 - lr: 0.0100 - 387ms/epoch - 9ms/step\n",
            "Epoch 19/20\n",
            "45/45 - 0s - loss: 0.2639 - accuracy: 0.9117 - val_loss: 0.3154 - val_accuracy: 0.8914 - lr: 0.0100 - 418ms/epoch - 9ms/step\n",
            "Epoch 20/20\n",
            "45/45 - 0s - loss: 0.2517 - accuracy: 0.9216 - val_loss: 0.3079 - val_accuracy: 0.8898 - lr: 0.0100 - 409ms/epoch - 9ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3079 - accuracy: 0.8898\n",
            "Model: \"model_235\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_236 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_483 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_163 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_484 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "45/45 - 7s - loss: 1.2845 - accuracy: 0.5311 - val_loss: 0.6190 - val_accuracy: 0.5411 - lr: 0.0100 - 7s/epoch - 147ms/step\n",
            "Epoch 2/25\n",
            "45/45 - 1s - loss: 0.5541 - accuracy: 0.5650 - val_loss: 0.5008 - val_accuracy: 0.6941 - lr: 0.0100 - 588ms/epoch - 13ms/step\n",
            "Epoch 3/25\n",
            "45/45 - 1s - loss: 0.4516 - accuracy: 0.8270 - val_loss: 0.4137 - val_accuracy: 0.8586 - lr: 0.0100 - 519ms/epoch - 12ms/step\n",
            "Epoch 4/25\n",
            "45/45 - 1s - loss: 0.3909 - accuracy: 0.8997 - val_loss: 0.3621 - val_accuracy: 0.8931 - lr: 0.0100 - 619ms/epoch - 14ms/step\n",
            "Epoch 5/25\n",
            "45/45 - 1s - loss: 0.3652 - accuracy: 0.9054 - val_loss: 0.3198 - val_accuracy: 0.9013 - lr: 0.0100 - 518ms/epoch - 12ms/step\n",
            "Epoch 6/25\n",
            "45/45 - 0s - loss: 0.3278 - accuracy: 0.9082 - val_loss: 0.4148 - val_accuracy: 0.8043 - lr: 0.0100 - 423ms/epoch - 9ms/step\n",
            "Epoch 7/25\n",
            "45/45 - 0s - loss: 0.2990 - accuracy: 0.9110 - val_loss: 0.2907 - val_accuracy: 0.9178 - lr: 0.0100 - 380ms/epoch - 8ms/step\n",
            "Epoch 8/25\n",
            "45/45 - 0s - loss: 0.2635 - accuracy: 0.9174 - val_loss: 0.2734 - val_accuracy: 0.9211 - lr: 0.0100 - 374ms/epoch - 8ms/step\n",
            "Epoch 9/25\n",
            "45/45 - 0s - loss: 0.2440 - accuracy: 0.9258 - val_loss: 0.2630 - val_accuracy: 0.9178 - lr: 0.0100 - 371ms/epoch - 8ms/step\n",
            "Epoch 10/25\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.2765 - accuracy: 0.8969 - val_loss: 0.5752 - val_accuracy: 0.5938 - lr: 0.0100 - 369ms/epoch - 8ms/step\n",
            "Epoch 11/25\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 0.4856 - accuracy: 0.7394 - val_loss: 0.4356 - val_accuracy: 0.8372 - lr: 1.0000e-03 - 403ms/epoch - 9ms/step\n",
            "Epoch 12/25\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "45/45 - 0s - loss: 0.4111 - accuracy: 0.8277 - val_loss: 0.4255 - val_accuracy: 0.8388 - lr: 1.0000e-04 - 384ms/epoch - 9ms/step\n",
            "Epoch 13/25\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
            "45/45 - 0s - loss: 0.4057 - accuracy: 0.8277 - val_loss: 0.4246 - val_accuracy: 0.8388 - lr: 1.0000e-05 - 365ms/epoch - 8ms/step\n",
            "Epoch 14/25\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "45/45 - 0s - loss: 0.4051 - accuracy: 0.8277 - val_loss: 0.4245 - val_accuracy: 0.8388 - lr: 1.0000e-06 - 397ms/epoch - 9ms/step\n",
            "Epoch 15/25\n",
            "45/45 - 0s - loss: 0.4051 - accuracy: 0.8277 - val_loss: 0.4245 - val_accuracy: 0.8388 - lr: 1.0000e-07 - 373ms/epoch - 8ms/step\n",
            "Epoch 16/25\n",
            "45/45 - 0s - loss: 0.4051 - accuracy: 0.8277 - val_loss: 0.4245 - val_accuracy: 0.8388 - lr: 1.0000e-07 - 370ms/epoch - 8ms/step\n",
            "Epoch 17/25\n",
            "45/45 - 0s - loss: 0.4051 - accuracy: 0.8277 - val_loss: 0.4245 - val_accuracy: 0.8388 - lr: 1.0000e-07 - 362ms/epoch - 8ms/step\n",
            "Epoch 18/25\n",
            "45/45 - 0s - loss: 0.4050 - accuracy: 0.8277 - val_loss: 0.4245 - val_accuracy: 0.8388 - lr: 1.0000e-07 - 358ms/epoch - 8ms/step\n",
            "Epoch 19/25\n",
            "45/45 - 0s - loss: 0.4050 - accuracy: 0.8277 - val_loss: 0.4245 - val_accuracy: 0.8388 - lr: 1.0000e-07 - 366ms/epoch - 8ms/step\n",
            "Epoch 20/25\n",
            "45/45 - 0s - loss: 0.4050 - accuracy: 0.8277 - val_loss: 0.4244 - val_accuracy: 0.8388 - lr: 1.0000e-07 - 377ms/epoch - 8ms/step\n",
            "Epoch 21/25\n",
            "45/45 - 0s - loss: 0.4050 - accuracy: 0.8277 - val_loss: 0.4244 - val_accuracy: 0.8388 - lr: 1.0000e-07 - 360ms/epoch - 8ms/step\n",
            "Epoch 22/25\n",
            "45/45 - 0s - loss: 0.4050 - accuracy: 0.8277 - val_loss: 0.4244 - val_accuracy: 0.8388 - lr: 1.0000e-07 - 360ms/epoch - 8ms/step\n",
            "Epoch 23/25\n",
            "45/45 - 0s - loss: 0.4050 - accuracy: 0.8277 - val_loss: 0.4244 - val_accuracy: 0.8388 - lr: 1.0000e-07 - 365ms/epoch - 8ms/step\n",
            "Epoch 24/25\n",
            "45/45 - 0s - loss: 0.4050 - accuracy: 0.8277 - val_loss: 0.4244 - val_accuracy: 0.8388 - lr: 1.0000e-07 - 361ms/epoch - 8ms/step\n",
            "Epoch 25/25\n",
            "45/45 - 0s - loss: 0.4050 - accuracy: 0.8277 - val_loss: 0.4244 - val_accuracy: 0.8388 - lr: 1.0000e-07 - 389ms/epoch - 9ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.8388\n",
            "Model: \"model_237\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_238 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_488 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_164 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_489 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "45/45 - 5s - loss: 0.6551 - accuracy: 0.5417 - val_loss: 0.5487 - val_accuracy: 0.5164 - lr: 0.0100 - 5s/epoch - 121ms/step\n",
            "Epoch 2/20\n",
            "45/45 - 0s - loss: 0.4939 - accuracy: 0.5671 - val_loss: 0.4600 - val_accuracy: 0.6793 - lr: 0.0100 - 292ms/epoch - 6ms/step\n",
            "Epoch 3/20\n",
            "45/45 - 0s - loss: 0.4315 - accuracy: 0.8347 - val_loss: 0.4036 - val_accuracy: 0.8898 - lr: 0.0100 - 270ms/epoch - 6ms/step\n",
            "Epoch 4/20\n",
            "45/45 - 0s - loss: 0.3996 - accuracy: 0.8976 - val_loss: 0.3730 - val_accuracy: 0.9112 - lr: 0.0100 - 299ms/epoch - 7ms/step\n",
            "Epoch 5/20\n",
            "45/45 - 0s - loss: 0.3719 - accuracy: 0.9061 - val_loss: 0.3577 - val_accuracy: 0.8750 - lr: 0.0100 - 265ms/epoch - 6ms/step\n",
            "Epoch 6/20\n",
            "45/45 - 0s - loss: 0.3514 - accuracy: 0.9096 - val_loss: 0.3371 - val_accuracy: 0.9145 - lr: 0.0100 - 300ms/epoch - 7ms/step\n",
            "Epoch 7/20\n",
            "45/45 - 0s - loss: 0.3109 - accuracy: 0.9174 - val_loss: 0.3433 - val_accuracy: 0.8750 - lr: 0.0100 - 286ms/epoch - 6ms/step\n",
            "Epoch 8/20\n",
            "45/45 - 0s - loss: 0.3025 - accuracy: 0.9138 - val_loss: 0.3254 - val_accuracy: 0.8964 - lr: 0.0100 - 304ms/epoch - 7ms/step\n",
            "Epoch 9/20\n",
            "45/45 - 0s - loss: 0.2923 - accuracy: 0.9145 - val_loss: 0.4051 - val_accuracy: 0.8158 - lr: 0.0100 - 304ms/epoch - 7ms/step\n",
            "Epoch 10/20\n",
            "45/45 - 0s - loss: 0.2732 - accuracy: 0.9216 - val_loss: 0.2853 - val_accuracy: 0.9161 - lr: 0.0100 - 307ms/epoch - 7ms/step\n",
            "Epoch 11/20\n",
            "45/45 - 0s - loss: 0.2677 - accuracy: 0.9244 - val_loss: 0.2936 - val_accuracy: 0.9178 - lr: 0.0100 - 314ms/epoch - 7ms/step\n",
            "Epoch 12/20\n",
            "45/45 - 0s - loss: 0.2671 - accuracy: 0.9174 - val_loss: 0.2824 - val_accuracy: 0.9227 - lr: 0.0100 - 335ms/epoch - 7ms/step\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.2693 - accuracy: 0.9061 - val_loss: 0.2756 - val_accuracy: 0.9194 - lr: 0.0100 - 311ms/epoch - 7ms/step\n",
            "Epoch 14/20\n",
            "45/45 - 0s - loss: 0.2574 - accuracy: 0.9145 - val_loss: 0.2738 - val_accuracy: 0.9211 - lr: 1.0000e-03 - 313ms/epoch - 7ms/step\n",
            "Epoch 15/20\n",
            "45/45 - 0s - loss: 0.2549 - accuracy: 0.9174 - val_loss: 0.2719 - val_accuracy: 0.9211 - lr: 1.0000e-03 - 301ms/epoch - 7ms/step\n",
            "Epoch 16/20\n",
            "45/45 - 0s - loss: 0.2541 - accuracy: 0.9153 - val_loss: 0.2714 - val_accuracy: 0.9243 - lr: 1.0000e-03 - 313ms/epoch - 7ms/step\n",
            "Epoch 17/20\n",
            "45/45 - 0s - loss: 0.2520 - accuracy: 0.9174 - val_loss: 0.2693 - val_accuracy: 0.9227 - lr: 1.0000e-03 - 277ms/epoch - 6ms/step\n",
            "Epoch 18/20\n",
            "45/45 - 0s - loss: 0.2502 - accuracy: 0.9209 - val_loss: 0.2683 - val_accuracy: 0.9260 - lr: 1.0000e-03 - 273ms/epoch - 6ms/step\n",
            "Epoch 19/20\n",
            "45/45 - 0s - loss: 0.2486 - accuracy: 0.9195 - val_loss: 0.2683 - val_accuracy: 0.9260 - lr: 1.0000e-03 - 305ms/epoch - 7ms/step\n",
            "Epoch 20/20\n",
            "45/45 - 0s - loss: 0.2466 - accuracy: 0.9209 - val_loss: 0.2859 - val_accuracy: 0.9260 - lr: 1.0000e-03 - 277ms/epoch - 6ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2859 - accuracy: 0.9260\n",
            "Model: \"model_239\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_240 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_492 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_165 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_493 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "45/45 - 7s - loss: 1.1313 - accuracy: 0.5374 - val_loss: 0.6679 - val_accuracy: 0.5263 - lr: 0.0100 - 7s/epoch - 161ms/step\n",
            "Epoch 2/25\n",
            "45/45 - 0s - loss: 0.6268 - accuracy: 0.5374 - val_loss: 0.6121 - val_accuracy: 0.5263 - lr: 0.0100 - 374ms/epoch - 8ms/step\n",
            "Epoch 3/25\n",
            "45/45 - 0s - loss: 0.5653 - accuracy: 0.5374 - val_loss: 0.5575 - val_accuracy: 0.5263 - lr: 0.0100 - 389ms/epoch - 9ms/step\n",
            "Epoch 4/25\n",
            "45/45 - 0s - loss: 0.5212 - accuracy: 0.5770 - val_loss: 0.5168 - val_accuracy: 0.6694 - lr: 0.0100 - 395ms/epoch - 9ms/step\n",
            "Epoch 5/25\n",
            "45/45 - 0s - loss: 0.4751 - accuracy: 0.7867 - val_loss: 0.4729 - val_accuracy: 0.8405 - lr: 0.0100 - 383ms/epoch - 9ms/step\n",
            "Epoch 6/25\n",
            "45/45 - 0s - loss: 0.4417 - accuracy: 0.8828 - val_loss: 0.4432 - val_accuracy: 0.8980 - lr: 0.0100 - 397ms/epoch - 9ms/step\n",
            "Epoch 7/25\n",
            "45/45 - 0s - loss: 0.4074 - accuracy: 0.9032 - val_loss: 0.4013 - val_accuracy: 0.9145 - lr: 0.0100 - 409ms/epoch - 9ms/step\n",
            "Epoch 8/25\n",
            "45/45 - 0s - loss: 0.3719 - accuracy: 0.9131 - val_loss: 0.3711 - val_accuracy: 0.9095 - lr: 0.0100 - 392ms/epoch - 9ms/step\n",
            "Epoch 9/25\n",
            "45/45 - 0s - loss: 0.3431 - accuracy: 0.9131 - val_loss: 0.3486 - val_accuracy: 0.9095 - lr: 0.0100 - 368ms/epoch - 8ms/step\n",
            "Epoch 10/25\n",
            "45/45 - 0s - loss: 0.3229 - accuracy: 0.9117 - val_loss: 0.3259 - val_accuracy: 0.9128 - lr: 0.0100 - 418ms/epoch - 9ms/step\n",
            "Epoch 11/25\n",
            "45/45 - 0s - loss: 0.3140 - accuracy: 0.9054 - val_loss: 0.3164 - val_accuracy: 0.9095 - lr: 0.0100 - 380ms/epoch - 8ms/step\n",
            "Epoch 12/25\n",
            "45/45 - 0s - loss: 0.2979 - accuracy: 0.9075 - val_loss: 0.3049 - val_accuracy: 0.9145 - lr: 0.0100 - 385ms/epoch - 9ms/step\n",
            "Epoch 13/25\n",
            "45/45 - 0s - loss: 0.2749 - accuracy: 0.9145 - val_loss: 0.3076 - val_accuracy: 0.9112 - lr: 0.0100 - 392ms/epoch - 9ms/step\n",
            "Epoch 14/25\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.2846 - accuracy: 0.9160 - val_loss: 0.2997 - val_accuracy: 0.9079 - lr: 0.0100 - 361ms/epoch - 8ms/step\n",
            "Epoch 15/25\n",
            "45/45 - 0s - loss: 0.2530 - accuracy: 0.9216 - val_loss: 0.2714 - val_accuracy: 0.9145 - lr: 1.0000e-03 - 385ms/epoch - 9ms/step\n",
            "Epoch 16/25\n",
            "45/45 - 0s - loss: 0.2484 - accuracy: 0.9223 - val_loss: 0.2703 - val_accuracy: 0.9178 - lr: 1.0000e-03 - 399ms/epoch - 9ms/step\n",
            "Epoch 17/25\n",
            "45/45 - 0s - loss: 0.2466 - accuracy: 0.9266 - val_loss: 0.2685 - val_accuracy: 0.9178 - lr: 1.0000e-03 - 360ms/epoch - 8ms/step\n",
            "Epoch 18/25\n",
            "45/45 - 0s - loss: 0.2456 - accuracy: 0.9237 - val_loss: 0.2677 - val_accuracy: 0.9178 - lr: 1.0000e-03 - 374ms/epoch - 8ms/step\n",
            "Epoch 19/25\n",
            "45/45 - 0s - loss: 0.2443 - accuracy: 0.9244 - val_loss: 0.2667 - val_accuracy: 0.9161 - lr: 1.0000e-03 - 365ms/epoch - 8ms/step\n",
            "Epoch 20/25\n",
            "45/45 - 0s - loss: 0.2431 - accuracy: 0.9244 - val_loss: 0.2657 - val_accuracy: 0.9178 - lr: 1.0000e-03 - 372ms/epoch - 8ms/step\n",
            "Epoch 21/25\n",
            "45/45 - 0s - loss: 0.2417 - accuracy: 0.9244 - val_loss: 0.2650 - val_accuracy: 0.9194 - lr: 1.0000e-03 - 361ms/epoch - 8ms/step\n",
            "Epoch 22/25\n",
            "45/45 - 0s - loss: 0.2402 - accuracy: 0.9237 - val_loss: 0.2855 - val_accuracy: 0.9194 - lr: 1.0000e-03 - 372ms/epoch - 8ms/step\n",
            "Epoch 23/25\n",
            "\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 0.2403 - accuracy: 0.9209 - val_loss: 0.2869 - val_accuracy: 0.9194 - lr: 1.0000e-03 - 372ms/epoch - 8ms/step\n",
            "Epoch 24/25\n",
            "45/45 - 0s - loss: 0.2381 - accuracy: 0.9266 - val_loss: 0.2675 - val_accuracy: 0.9178 - lr: 1.0000e-04 - 382ms/epoch - 8ms/step\n",
            "Epoch 25/25\n",
            "45/45 - 0s - loss: 0.2379 - accuracy: 0.9266 - val_loss: 0.2667 - val_accuracy: 0.9178 - lr: 1.0000e-04 - 373ms/epoch - 8ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2667 - accuracy: 0.9178\n",
            "Model: \"model_241\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_242 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_497 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_166 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_498 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "45/45 - 5s - loss: 0.9559 - accuracy: 0.5346 - val_loss: 0.6373 - val_accuracy: 0.5329 - lr: 0.0100 - 5s/epoch - 101ms/step\n",
            "Epoch 2/15\n",
            "45/45 - 0s - loss: 0.5585 - accuracy: 0.5346 - val_loss: 0.5503 - val_accuracy: 0.5329 - lr: 0.0100 - 275ms/epoch - 6ms/step\n",
            "Epoch 3/15\n",
            "45/45 - 0s - loss: 0.5015 - accuracy: 0.5579 - val_loss: 0.5152 - val_accuracy: 0.6151 - lr: 0.0100 - 285ms/epoch - 6ms/step\n",
            "Epoch 4/15\n",
            "45/45 - 0s - loss: 0.4540 - accuracy: 0.7860 - val_loss: 0.4896 - val_accuracy: 0.8816 - lr: 0.0100 - 292ms/epoch - 6ms/step\n",
            "Epoch 5/15\n",
            "45/45 - 0s - loss: 0.4205 - accuracy: 0.8835 - val_loss: 0.4652 - val_accuracy: 0.8766 - lr: 0.0100 - 268ms/epoch - 6ms/step\n",
            "Epoch 6/15\n",
            "45/45 - 0s - loss: 0.4089 - accuracy: 0.8863 - val_loss: 0.4207 - val_accuracy: 0.8832 - lr: 0.0100 - 285ms/epoch - 6ms/step\n",
            "Epoch 7/15\n",
            "45/45 - 0s - loss: 0.3788 - accuracy: 0.8955 - val_loss: 0.4430 - val_accuracy: 0.8799 - lr: 0.0100 - 261ms/epoch - 6ms/step\n",
            "Epoch 8/15\n",
            "45/45 - 0s - loss: 0.3598 - accuracy: 0.8884 - val_loss: 0.4271 - val_accuracy: 0.8816 - lr: 0.0100 - 300ms/epoch - 7ms/step\n",
            "Epoch 9/15\n",
            "45/45 - 0s - loss: 0.3511 - accuracy: 0.8891 - val_loss: 0.3909 - val_accuracy: 0.8882 - lr: 0.0100 - 316ms/epoch - 7ms/step\n",
            "Epoch 10/15\n",
            "45/45 - 0s - loss: 0.3260 - accuracy: 0.8962 - val_loss: 0.3526 - val_accuracy: 0.8865 - lr: 0.0100 - 259ms/epoch - 6ms/step\n",
            "Epoch 11/15\n",
            "45/45 - 0s - loss: 0.3184 - accuracy: 0.9011 - val_loss: 0.3677 - val_accuracy: 0.8865 - lr: 0.0100 - 265ms/epoch - 6ms/step\n",
            "Epoch 12/15\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.3222 - accuracy: 0.8898 - val_loss: 0.3841 - val_accuracy: 0.9013 - lr: 0.0100 - 302ms/epoch - 7ms/step\n",
            "Epoch 13/15\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 0.3218 - accuracy: 0.9004 - val_loss: 0.3868 - val_accuracy: 0.9013 - lr: 1.0000e-03 - 268ms/epoch - 6ms/step\n",
            "Epoch 14/15\n",
            "45/45 - 0s - loss: 0.3037 - accuracy: 0.8976 - val_loss: 0.3892 - val_accuracy: 0.8980 - lr: 1.0000e-04 - 279ms/epoch - 6ms/step\n",
            "Epoch 15/15\n",
            "45/45 - 0s - loss: 0.3005 - accuracy: 0.8990 - val_loss: 0.3892 - val_accuracy: 0.8997 - lr: 1.0000e-04 - 296ms/epoch - 7ms/step\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3892 - accuracy: 0.8997\n",
            "Model: \"model_243\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_244 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_501 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_167 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_502 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "45/45 - 5s - loss: 0.5463 - accuracy: 0.5989 - val_loss: 0.4716 - val_accuracy: 0.8076 - lr: 0.0100 - 5s/epoch - 117ms/step\n",
            "Epoch 2/20\n",
            "45/45 - 0s - loss: 0.4036 - accuracy: 0.8573 - val_loss: 0.3975 - val_accuracy: 0.8898 - lr: 0.0100 - 294ms/epoch - 7ms/step\n",
            "Epoch 3/20\n",
            "45/45 - 0s - loss: 0.3324 - accuracy: 0.9011 - val_loss: 0.3315 - val_accuracy: 0.9030 - lr: 0.0100 - 287ms/epoch - 6ms/step\n",
            "Epoch 4/20\n",
            "45/45 - 0s - loss: 0.2844 - accuracy: 0.9110 - val_loss: 0.3036 - val_accuracy: 0.9079 - lr: 0.0100 - 297ms/epoch - 7ms/step\n",
            "Epoch 5/20\n",
            "45/45 - 0s - loss: 0.2632 - accuracy: 0.9174 - val_loss: 0.3419 - val_accuracy: 0.9046 - lr: 0.0100 - 292ms/epoch - 6ms/step\n",
            "Epoch 6/20\n",
            "45/45 - 0s - loss: 0.2556 - accuracy: 0.9110 - val_loss: 0.2782 - val_accuracy: 0.9194 - lr: 0.0100 - 267ms/epoch - 6ms/step\n",
            "Epoch 7/20\n",
            "45/45 - 0s - loss: 0.2458 - accuracy: 0.9145 - val_loss: 0.2967 - val_accuracy: 0.9128 - lr: 0.0100 - 278ms/epoch - 6ms/step\n",
            "Epoch 8/20\n",
            "45/45 - 0s - loss: 0.2341 - accuracy: 0.9209 - val_loss: 0.2789 - val_accuracy: 0.9079 - lr: 0.0100 - 325ms/epoch - 7ms/step\n",
            "Epoch 9/20\n",
            "45/45 - 0s - loss: 0.2235 - accuracy: 0.9174 - val_loss: 0.2762 - val_accuracy: 0.8980 - lr: 0.0100 - 300ms/epoch - 7ms/step\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.2292 - accuracy: 0.9195 - val_loss: 0.2771 - val_accuracy: 0.9112 - lr: 0.0100 - 264ms/epoch - 6ms/step\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 0.2434 - accuracy: 0.9223 - val_loss: 0.2912 - val_accuracy: 0.9359 - lr: 1.0000e-03 - 294ms/epoch - 7ms/step\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "45/45 - 0s - loss: 0.2265 - accuracy: 0.9266 - val_loss: 0.2908 - val_accuracy: 0.9326 - lr: 1.0000e-04 - 314ms/epoch - 7ms/step\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
            "45/45 - 0s - loss: 0.2258 - accuracy: 0.9266 - val_loss: 0.2907 - val_accuracy: 0.9326 - lr: 1.0000e-05 - 302ms/epoch - 7ms/step\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "45/45 - 0s - loss: 0.2258 - accuracy: 0.9266 - val_loss: 0.2907 - val_accuracy: 0.9326 - lr: 1.0000e-06 - 293ms/epoch - 7ms/step\n",
            "Epoch 15/20\n",
            "45/45 - 0s - loss: 0.2258 - accuracy: 0.9266 - val_loss: 0.2907 - val_accuracy: 0.9326 - lr: 1.0000e-07 - 283ms/epoch - 6ms/step\n",
            "Epoch 16/20\n",
            "45/45 - 0s - loss: 0.2258 - accuracy: 0.9266 - val_loss: 0.2907 - val_accuracy: 0.9326 - lr: 1.0000e-07 - 309ms/epoch - 7ms/step\n",
            "Epoch 17/20\n",
            "45/45 - 0s - loss: 0.2258 - accuracy: 0.9266 - val_loss: 0.2907 - val_accuracy: 0.9326 - lr: 1.0000e-07 - 273ms/epoch - 6ms/step\n",
            "Epoch 18/20\n",
            "45/45 - 0s - loss: 0.2258 - accuracy: 0.9266 - val_loss: 0.2907 - val_accuracy: 0.9326 - lr: 1.0000e-07 - 287ms/epoch - 6ms/step\n",
            "Epoch 19/20\n",
            "45/45 - 0s - loss: 0.2258 - accuracy: 0.9266 - val_loss: 0.2907 - val_accuracy: 0.9326 - lr: 1.0000e-07 - 260ms/epoch - 6ms/step\n",
            "Epoch 20/20\n",
            "45/45 - 0s - loss: 0.2258 - accuracy: 0.9266 - val_loss: 0.2907 - val_accuracy: 0.9326 - lr: 1.0000e-07 - 268ms/epoch - 6ms/step\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2907 - accuracy: 0.9326\n",
            "Model: \"model_245\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_246 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_505 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_168 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_506 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "45/45 - 5s - loss: 0.9441 - accuracy: 0.5233 - val_loss: 0.5736 - val_accuracy: 0.5592 - lr: 0.0100 - 5s/epoch - 105ms/step\n",
            "Epoch 2/15\n",
            "45/45 - 0s - loss: 0.5638 - accuracy: 0.5233 - val_loss: 0.5264 - val_accuracy: 0.5641 - lr: 0.0100 - 298ms/epoch - 7ms/step\n",
            "Epoch 3/15\n",
            "45/45 - 0s - loss: 0.5121 - accuracy: 0.6843 - val_loss: 0.4969 - val_accuracy: 0.8257 - lr: 0.0100 - 256ms/epoch - 6ms/step\n",
            "Epoch 4/15\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.5300 - accuracy: 0.7881 - val_loss: 0.5315 - val_accuracy: 0.8010 - lr: 0.0100 - 318ms/epoch - 7ms/step\n",
            "Epoch 5/15\n",
            "\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 0.5292 - accuracy: 0.7994 - val_loss: 0.5009 - val_accuracy: 0.8026 - lr: 1.0000e-03 - 291ms/epoch - 6ms/step\n",
            "Epoch 6/15\n",
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "45/45 - 0s - loss: 0.5146 - accuracy: 0.8008 - val_loss: 0.4982 - val_accuracy: 0.8026 - lr: 1.0000e-04 - 288ms/epoch - 6ms/step\n",
            "Epoch 7/15\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
            "45/45 - 0s - loss: 0.5132 - accuracy: 0.8023 - val_loss: 0.4979 - val_accuracy: 0.8026 - lr: 1.0000e-05 - 314ms/epoch - 7ms/step\n",
            "Epoch 8/15\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "45/45 - 0s - loss: 0.5131 - accuracy: 0.8023 - val_loss: 0.4979 - val_accuracy: 0.8026 - lr: 1.0000e-06 - 310ms/epoch - 7ms/step\n",
            "Epoch 9/15\n",
            "45/45 - 0s - loss: 0.5131 - accuracy: 0.8023 - val_loss: 0.4979 - val_accuracy: 0.8026 - lr: 1.0000e-07 - 316ms/epoch - 7ms/step\n",
            "Epoch 10/15\n",
            "45/45 - 0s - loss: 0.5131 - accuracy: 0.8023 - val_loss: 0.4979 - val_accuracy: 0.8026 - lr: 1.0000e-07 - 309ms/epoch - 7ms/step\n",
            "Epoch 11/15\n",
            "45/45 - 0s - loss: 0.5131 - accuracy: 0.8023 - val_loss: 0.4979 - val_accuracy: 0.8026 - lr: 1.0000e-07 - 313ms/epoch - 7ms/step\n",
            "Epoch 12/15\n",
            "45/45 - 0s - loss: 0.5131 - accuracy: 0.8023 - val_loss: 0.4979 - val_accuracy: 0.8026 - lr: 1.0000e-07 - 298ms/epoch - 7ms/step\n",
            "Epoch 13/15\n",
            "45/45 - 0s - loss: 0.5131 - accuracy: 0.8023 - val_loss: 0.4979 - val_accuracy: 0.8026 - lr: 1.0000e-07 - 305ms/epoch - 7ms/step\n",
            "Epoch 14/15\n",
            "45/45 - 0s - loss: 0.5131 - accuracy: 0.8023 - val_loss: 0.4979 - val_accuracy: 0.8026 - lr: 1.0000e-07 - 385ms/epoch - 9ms/step\n",
            "Epoch 15/15\n",
            "45/45 - 0s - loss: 0.5131 - accuracy: 0.8023 - val_loss: 0.4979 - val_accuracy: 0.8026 - lr: 1.0000e-07 - 406ms/epoch - 9ms/step\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4979 - accuracy: 0.8026\n",
            "Model: \"model_247\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_248 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_509 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_169 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_510 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "45/45 - 5s - loss: 7.3641 - accuracy: 0.5226 - val_loss: 6.7527 - val_accuracy: 0.5609 - lr: 0.0100 - 5s/epoch - 115ms/step\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 7.3640 - accuracy: 0.5226 - val_loss: 6.7529 - val_accuracy: 0.5609 - lr: 0.0100 - 294ms/epoch - 7ms/step\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 7.3640 - accuracy: 0.5226 - val_loss: 6.7529 - val_accuracy: 0.5609 - lr: 1.0000e-03 - 279ms/epoch - 6ms/step\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "45/45 - 0s - loss: 7.3640 - accuracy: 0.5226 - val_loss: 6.7529 - val_accuracy: 0.5609 - lr: 1.0000e-04 - 279ms/epoch - 6ms/step\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
            "45/45 - 0s - loss: 7.3640 - accuracy: 0.5226 - val_loss: 6.7529 - val_accuracy: 0.5609 - lr: 1.0000e-05 - 293ms/epoch - 7ms/step\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "45/45 - 0s - loss: 7.3640 - accuracy: 0.5226 - val_loss: 6.7529 - val_accuracy: 0.5609 - lr: 1.0000e-06 - 287ms/epoch - 6ms/step\n",
            "Epoch 7/20\n",
            "45/45 - 0s - loss: 7.3640 - accuracy: 0.5226 - val_loss: 6.7529 - val_accuracy: 0.5609 - lr: 1.0000e-07 - 309ms/epoch - 7ms/step\n",
            "Epoch 8/20\n",
            "45/45 - 0s - loss: 7.3640 - accuracy: 0.5226 - val_loss: 6.7529 - val_accuracy: 0.5609 - lr: 1.0000e-07 - 269ms/epoch - 6ms/step\n",
            "Epoch 9/20\n",
            "45/45 - 0s - loss: 7.3640 - accuracy: 0.5226 - val_loss: 6.7529 - val_accuracy: 0.5609 - lr: 1.0000e-07 - 277ms/epoch - 6ms/step\n",
            "Epoch 10/20\n",
            "45/45 - 0s - loss: 7.3640 - accuracy: 0.5226 - val_loss: 6.7529 - val_accuracy: 0.5609 - lr: 1.0000e-07 - 296ms/epoch - 7ms/step\n",
            "Epoch 11/20\n",
            "45/45 - 0s - loss: 7.3640 - accuracy: 0.5226 - val_loss: 6.7529 - val_accuracy: 0.5609 - lr: 1.0000e-07 - 322ms/epoch - 7ms/step\n",
            "Epoch 12/20\n",
            "45/45 - 0s - loss: 7.3640 - accuracy: 0.5226 - val_loss: 6.7529 - val_accuracy: 0.5609 - lr: 1.0000e-07 - 310ms/epoch - 7ms/step\n",
            "Epoch 13/20\n",
            "45/45 - 0s - loss: 7.3640 - accuracy: 0.5226 - val_loss: 6.7529 - val_accuracy: 0.5609 - lr: 1.0000e-07 - 272ms/epoch - 6ms/step\n",
            "Epoch 14/20\n",
            "45/45 - 0s - loss: 7.3640 - accuracy: 0.5226 - val_loss: 6.7529 - val_accuracy: 0.5609 - lr: 1.0000e-07 - 266ms/epoch - 6ms/step\n",
            "Epoch 15/20\n",
            "45/45 - 0s - loss: 7.3640 - accuracy: 0.5226 - val_loss: 6.7529 - val_accuracy: 0.5609 - lr: 1.0000e-07 - 285ms/epoch - 6ms/step\n",
            "Epoch 16/20\n",
            "45/45 - 0s - loss: 7.3640 - accuracy: 0.5226 - val_loss: 6.7529 - val_accuracy: 0.5609 - lr: 1.0000e-07 - 321ms/epoch - 7ms/step\n",
            "Epoch 17/20\n",
            "45/45 - 0s - loss: 7.3640 - accuracy: 0.5226 - val_loss: 6.7529 - val_accuracy: 0.5609 - lr: 1.0000e-07 - 290ms/epoch - 6ms/step\n",
            "Epoch 18/20\n",
            "45/45 - 0s - loss: 7.3640 - accuracy: 0.5226 - val_loss: 6.7529 - val_accuracy: 0.5609 - lr: 1.0000e-07 - 299ms/epoch - 7ms/step\n",
            "Epoch 19/20\n",
            "45/45 - 0s - loss: 7.3640 - accuracy: 0.5226 - val_loss: 6.7529 - val_accuracy: 0.5609 - lr: 1.0000e-07 - 293ms/epoch - 7ms/step\n",
            "Epoch 20/20\n",
            "45/45 - 0s - loss: 7.3640 - accuracy: 0.5226 - val_loss: 6.7529 - val_accuracy: 0.5609 - lr: 1.0000e-07 - 302ms/epoch - 7ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.7529 - accuracy: 0.5609\n",
            "Model: \"model_249\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_250 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_513 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_170 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_514 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "45/45 - 5s - loss: 0.5445 - accuracy: 0.6815 - val_loss: 0.4917 - val_accuracy: 0.8141 - lr: 0.0100 - 5s/epoch - 102ms/step\n",
            "Epoch 2/20\n",
            "45/45 - 0s - loss: 0.4251 - accuracy: 0.8658 - val_loss: 0.4308 - val_accuracy: 0.8684 - lr: 0.0100 - 304ms/epoch - 7ms/step\n",
            "Epoch 3/20\n",
            "45/45 - 0s - loss: 0.3831 - accuracy: 0.8898 - val_loss: 0.4108 - val_accuracy: 0.8783 - lr: 0.0100 - 274ms/epoch - 6ms/step\n",
            "Epoch 4/20\n",
            "45/45 - 0s - loss: 0.3634 - accuracy: 0.8891 - val_loss: 0.3913 - val_accuracy: 0.8849 - lr: 0.0100 - 290ms/epoch - 6ms/step\n",
            "Epoch 5/20\n",
            "45/45 - 0s - loss: 0.3450 - accuracy: 0.8976 - val_loss: 0.3874 - val_accuracy: 0.8832 - lr: 0.0100 - 299ms/epoch - 7ms/step\n",
            "Epoch 6/20\n",
            "45/45 - 0s - loss: 0.3338 - accuracy: 0.9040 - val_loss: 0.3849 - val_accuracy: 0.8816 - lr: 0.0100 - 281ms/epoch - 6ms/step\n",
            "Epoch 7/20\n",
            "45/45 - 0s - loss: 0.3233 - accuracy: 0.9068 - val_loss: 0.3700 - val_accuracy: 0.8750 - lr: 0.0100 - 295ms/epoch - 7ms/step\n",
            "Epoch 8/20\n",
            "45/45 - 0s - loss: 0.3114 - accuracy: 0.9061 - val_loss: 0.3495 - val_accuracy: 0.8865 - lr: 0.0100 - 270ms/epoch - 6ms/step\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.3125 - accuracy: 0.9032 - val_loss: 0.3684 - val_accuracy: 0.8914 - lr: 0.0100 - 301ms/epoch - 7ms/step\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 0.3194 - accuracy: 0.9025 - val_loss: 0.3643 - val_accuracy: 0.8914 - lr: 1.0000e-03 - 302ms/epoch - 7ms/step\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "45/45 - 0s - loss: 0.3162 - accuracy: 0.9047 - val_loss: 0.3638 - val_accuracy: 0.8914 - lr: 1.0000e-04 - 274ms/epoch - 6ms/step\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
            "45/45 - 0s - loss: 0.3160 - accuracy: 0.9047 - val_loss: 0.3637 - val_accuracy: 0.8914 - lr: 1.0000e-05 - 268ms/epoch - 6ms/step\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "45/45 - 0s - loss: 0.3159 - accuracy: 0.9047 - val_loss: 0.3637 - val_accuracy: 0.8914 - lr: 1.0000e-06 - 300ms/epoch - 7ms/step\n",
            "Epoch 14/20\n",
            "45/45 - 0s - loss: 0.3159 - accuracy: 0.9047 - val_loss: 0.3637 - val_accuracy: 0.8914 - lr: 1.0000e-07 - 274ms/epoch - 6ms/step\n",
            "Epoch 15/20\n",
            "45/45 - 0s - loss: 0.3159 - accuracy: 0.9047 - val_loss: 0.3637 - val_accuracy: 0.8914 - lr: 1.0000e-07 - 293ms/epoch - 7ms/step\n",
            "Epoch 16/20\n",
            "45/45 - 0s - loss: 0.3159 - accuracy: 0.9047 - val_loss: 0.3637 - val_accuracy: 0.8914 - lr: 1.0000e-07 - 256ms/epoch - 6ms/step\n",
            "Epoch 17/20\n",
            "45/45 - 0s - loss: 0.3159 - accuracy: 0.9047 - val_loss: 0.3637 - val_accuracy: 0.8914 - lr: 1.0000e-07 - 306ms/epoch - 7ms/step\n",
            "Epoch 18/20\n",
            "45/45 - 0s - loss: 0.3159 - accuracy: 0.9047 - val_loss: 0.3637 - val_accuracy: 0.8914 - lr: 1.0000e-07 - 259ms/epoch - 6ms/step\n",
            "Epoch 19/20\n",
            "45/45 - 0s - loss: 0.3159 - accuracy: 0.9047 - val_loss: 0.3637 - val_accuracy: 0.8914 - lr: 1.0000e-07 - 305ms/epoch - 7ms/step\n",
            "Epoch 20/20\n",
            "45/45 - 0s - loss: 0.3159 - accuracy: 0.9047 - val_loss: 0.3637 - val_accuracy: 0.8914 - lr: 1.0000e-07 - 267ms/epoch - 6ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3637 - accuracy: 0.8914\n",
            "Model: \"model_251\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_252 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_517 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_171 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_518 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "45/45 - 5s - loss: 7.0545 - accuracy: 0.5424 - val_loss: 7.4841 - val_accuracy: 0.5148 - lr: 0.0100 - 5s/epoch - 118ms/step\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 7.0590 - accuracy: 0.5424 - val_loss: 7.4841 - val_accuracy: 0.5148 - lr: 0.0100 - 302ms/epoch - 7ms/step\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 7.0590 - accuracy: 0.5424 - val_loss: 7.4841 - val_accuracy: 0.5148 - lr: 1.0000e-03 - 327ms/epoch - 7ms/step\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "45/45 - 0s - loss: 7.0590 - accuracy: 0.5424 - val_loss: 7.4841 - val_accuracy: 0.5148 - lr: 1.0000e-04 - 306ms/epoch - 7ms/step\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
            "45/45 - 0s - loss: 7.0590 - accuracy: 0.5424 - val_loss: 7.4841 - val_accuracy: 0.5148 - lr: 1.0000e-05 - 302ms/epoch - 7ms/step\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "45/45 - 0s - loss: 7.0590 - accuracy: 0.5424 - val_loss: 7.4841 - val_accuracy: 0.5148 - lr: 1.0000e-06 - 307ms/epoch - 7ms/step\n",
            "Epoch 7/20\n",
            "45/45 - 0s - loss: 7.0590 - accuracy: 0.5424 - val_loss: 7.4841 - val_accuracy: 0.5148 - lr: 1.0000e-07 - 296ms/epoch - 7ms/step\n",
            "Epoch 8/20\n",
            "45/45 - 0s - loss: 7.0590 - accuracy: 0.5424 - val_loss: 7.4841 - val_accuracy: 0.5148 - lr: 1.0000e-07 - 275ms/epoch - 6ms/step\n",
            "Epoch 9/20\n",
            "45/45 - 0s - loss: 7.0590 - accuracy: 0.5424 - val_loss: 7.4841 - val_accuracy: 0.5148 - lr: 1.0000e-07 - 319ms/epoch - 7ms/step\n",
            "Epoch 10/20\n",
            "45/45 - 0s - loss: 7.0590 - accuracy: 0.5424 - val_loss: 7.4841 - val_accuracy: 0.5148 - lr: 1.0000e-07 - 315ms/epoch - 7ms/step\n",
            "Epoch 11/20\n",
            "45/45 - 0s - loss: 7.0590 - accuracy: 0.5424 - val_loss: 7.4841 - val_accuracy: 0.5148 - lr: 1.0000e-07 - 312ms/epoch - 7ms/step\n",
            "Epoch 12/20\n",
            "45/45 - 0s - loss: 7.0590 - accuracy: 0.5424 - val_loss: 7.4841 - val_accuracy: 0.5148 - lr: 1.0000e-07 - 274ms/epoch - 6ms/step\n",
            "Epoch 13/20\n",
            "45/45 - 0s - loss: 7.0590 - accuracy: 0.5424 - val_loss: 7.4841 - val_accuracy: 0.5148 - lr: 1.0000e-07 - 293ms/epoch - 7ms/step\n",
            "Epoch 14/20\n",
            "45/45 - 0s - loss: 7.0590 - accuracy: 0.5424 - val_loss: 7.4841 - val_accuracy: 0.5148 - lr: 1.0000e-07 - 276ms/epoch - 6ms/step\n",
            "Epoch 15/20\n",
            "45/45 - 0s - loss: 7.0590 - accuracy: 0.5424 - val_loss: 7.4841 - val_accuracy: 0.5148 - lr: 1.0000e-07 - 309ms/epoch - 7ms/step\n",
            "Epoch 16/20\n",
            "45/45 - 0s - loss: 7.0590 - accuracy: 0.5424 - val_loss: 7.4841 - val_accuracy: 0.5148 - lr: 1.0000e-07 - 309ms/epoch - 7ms/step\n",
            "Epoch 17/20\n",
            "45/45 - 0s - loss: 7.0590 - accuracy: 0.5424 - val_loss: 7.4841 - val_accuracy: 0.5148 - lr: 1.0000e-07 - 314ms/epoch - 7ms/step\n",
            "Epoch 18/20\n",
            "45/45 - 0s - loss: 7.0590 - accuracy: 0.5424 - val_loss: 7.4841 - val_accuracy: 0.5148 - lr: 1.0000e-07 - 272ms/epoch - 6ms/step\n",
            "Epoch 19/20\n",
            "45/45 - 0s - loss: 7.0590 - accuracy: 0.5424 - val_loss: 7.4841 - val_accuracy: 0.5148 - lr: 1.0000e-07 - 296ms/epoch - 7ms/step\n",
            "Epoch 20/20\n",
            "45/45 - 0s - loss: 7.0590 - accuracy: 0.5424 - val_loss: 7.4841 - val_accuracy: 0.5148 - lr: 1.0000e-07 - 307ms/epoch - 7ms/step\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 7.4841 - accuracy: 0.5148\n",
            "Model: \"model_253\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_254 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_521 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_172 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_522 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "45/45 - 7s - loss: 1.5321 - accuracy: 0.5360 - val_loss: 0.6540 - val_accuracy: 0.5296 - lr: 0.0100 - 7s/epoch - 150ms/step\n",
            "Epoch 2/15\n",
            "45/45 - 0s - loss: 0.6140 - accuracy: 0.5360 - val_loss: 0.5792 - val_accuracy: 0.5296 - lr: 0.0100 - 368ms/epoch - 8ms/step\n",
            "Epoch 3/15\n",
            "45/45 - 0s - loss: 0.5507 - accuracy: 0.5360 - val_loss: 0.5221 - val_accuracy: 0.5329 - lr: 0.0100 - 341ms/epoch - 8ms/step\n",
            "Epoch 4/15\n",
            "45/45 - 0s - loss: 0.5007 - accuracy: 0.6667 - val_loss: 0.4771 - val_accuracy: 0.7549 - lr: 0.0100 - 388ms/epoch - 9ms/step\n",
            "Epoch 5/15\n",
            "45/45 - 0s - loss: 0.4560 - accuracy: 0.8093 - val_loss: 0.4293 - val_accuracy: 0.8602 - lr: 0.0100 - 373ms/epoch - 8ms/step\n",
            "Epoch 6/15\n",
            "45/45 - 0s - loss: 0.4108 - accuracy: 0.8651 - val_loss: 0.3744 - val_accuracy: 0.8882 - lr: 0.0100 - 364ms/epoch - 8ms/step\n",
            "Epoch 7/15\n",
            "45/45 - 0s - loss: 0.3743 - accuracy: 0.8884 - val_loss: 0.3493 - val_accuracy: 0.9128 - lr: 0.0100 - 385ms/epoch - 9ms/step\n",
            "Epoch 8/15\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.3769 - accuracy: 0.8941 - val_loss: 0.3882 - val_accuracy: 0.9079 - lr: 0.0100 - 386ms/epoch - 9ms/step\n",
            "Epoch 9/15\n",
            "\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 0.4052 - accuracy: 0.8849 - val_loss: 0.3844 - val_accuracy: 0.9062 - lr: 1.0000e-03 - 390ms/epoch - 9ms/step\n",
            "Epoch 10/15\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "45/45 - 0s - loss: 0.4031 - accuracy: 0.8849 - val_loss: 0.3841 - val_accuracy: 0.9062 - lr: 1.0000e-04 - 362ms/epoch - 8ms/step\n",
            "Epoch 11/15\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
            "45/45 - 0s - loss: 0.4029 - accuracy: 0.8849 - val_loss: 0.3840 - val_accuracy: 0.9062 - lr: 1.0000e-05 - 377ms/epoch - 8ms/step\n",
            "Epoch 12/15\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "45/45 - 0s - loss: 0.4029 - accuracy: 0.8849 - val_loss: 0.3840 - val_accuracy: 0.9062 - lr: 1.0000e-06 - 401ms/epoch - 9ms/step\n",
            "Epoch 13/15\n",
            "45/45 - 0s - loss: 0.4029 - accuracy: 0.8849 - val_loss: 0.3840 - val_accuracy: 0.9062 - lr: 1.0000e-07 - 381ms/epoch - 8ms/step\n",
            "Epoch 14/15\n",
            "45/45 - 0s - loss: 0.4029 - accuracy: 0.8849 - val_loss: 0.3840 - val_accuracy: 0.9062 - lr: 1.0000e-07 - 376ms/epoch - 8ms/step\n",
            "Epoch 15/15\n",
            "45/45 - 0s - loss: 0.4029 - accuracy: 0.8849 - val_loss: 0.3840 - val_accuracy: 0.9062 - lr: 1.0000e-07 - 390ms/epoch - 9ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3840 - accuracy: 0.9062\n",
            "Model: \"model_255\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_256 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_526 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_173 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_527 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "45/45 - 8s - loss: 0.9203 - accuracy: 0.5339 - val_loss: 0.6473 - val_accuracy: 0.5345 - lr: 0.0100 - 8s/epoch - 167ms/step\n",
            "Epoch 2/25\n",
            "45/45 - 0s - loss: 0.6201 - accuracy: 0.5339 - val_loss: 0.5945 - val_accuracy: 0.5345 - lr: 0.0100 - 387ms/epoch - 9ms/step\n",
            "Epoch 3/25\n",
            "45/45 - 0s - loss: 0.5704 - accuracy: 0.5339 - val_loss: 0.5403 - val_accuracy: 0.5345 - lr: 0.0100 - 374ms/epoch - 8ms/step\n",
            "Epoch 4/25\n",
            "45/45 - 0s - loss: 0.5071 - accuracy: 0.6208 - val_loss: 0.4652 - val_accuracy: 0.7632 - lr: 0.0100 - 381ms/epoch - 8ms/step\n",
            "Epoch 5/25\n",
            "45/45 - 0s - loss: 0.4334 - accuracy: 0.8178 - val_loss: 0.4000 - val_accuracy: 0.8898 - lr: 0.0100 - 385ms/epoch - 9ms/step\n",
            "Epoch 6/25\n",
            "45/45 - 0s - loss: 0.3801 - accuracy: 0.8927 - val_loss: 0.3600 - val_accuracy: 0.9046 - lr: 0.0100 - 369ms/epoch - 8ms/step\n",
            "Epoch 7/25\n",
            "45/45 - 0s - loss: 0.3430 - accuracy: 0.9075 - val_loss: 0.3369 - val_accuracy: 0.9046 - lr: 0.0100 - 389ms/epoch - 9ms/step\n",
            "Epoch 8/25\n",
            "45/45 - 0s - loss: 0.3193 - accuracy: 0.9110 - val_loss: 0.3200 - val_accuracy: 0.9293 - lr: 0.0100 - 384ms/epoch - 9ms/step\n",
            "Epoch 9/25\n",
            "45/45 - 0s - loss: 0.2964 - accuracy: 0.9167 - val_loss: 0.2822 - val_accuracy: 0.9260 - lr: 0.0100 - 406ms/epoch - 9ms/step\n",
            "Epoch 10/25\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.3310 - accuracy: 0.9061 - val_loss: 0.3313 - val_accuracy: 0.9178 - lr: 0.0100 - 384ms/epoch - 9ms/step\n",
            "Epoch 11/25\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 0.2970 - accuracy: 0.9223 - val_loss: 0.3269 - val_accuracy: 0.9260 - lr: 1.0000e-03 - 373ms/epoch - 8ms/step\n",
            "Epoch 12/25\n",
            "45/45 - 0s - loss: 0.2943 - accuracy: 0.9230 - val_loss: 0.3266 - val_accuracy: 0.9260 - lr: 1.0000e-04 - 397ms/epoch - 9ms/step\n",
            "Epoch 13/25\n",
            "45/45 - 0s - loss: 0.2940 - accuracy: 0.9230 - val_loss: 0.3262 - val_accuracy: 0.9260 - lr: 1.0000e-04 - 386ms/epoch - 9ms/step\n",
            "Epoch 14/25\n",
            "45/45 - 0s - loss: 0.2937 - accuracy: 0.9237 - val_loss: 0.3259 - val_accuracy: 0.9260 - lr: 1.0000e-04 - 383ms/epoch - 9ms/step\n",
            "Epoch 15/25\n",
            "45/45 - 0s - loss: 0.2933 - accuracy: 0.9244 - val_loss: 0.3256 - val_accuracy: 0.9260 - lr: 1.0000e-04 - 425ms/epoch - 9ms/step\n",
            "Epoch 16/25\n",
            "45/45 - 0s - loss: 0.2930 - accuracy: 0.9251 - val_loss: 0.3254 - val_accuracy: 0.9260 - lr: 1.0000e-04 - 412ms/epoch - 9ms/step\n",
            "Epoch 17/25\n",
            "45/45 - 0s - loss: 0.2927 - accuracy: 0.9251 - val_loss: 0.3251 - val_accuracy: 0.9260 - lr: 1.0000e-04 - 399ms/epoch - 9ms/step\n",
            "Epoch 18/25\n",
            "45/45 - 0s - loss: 0.2924 - accuracy: 0.9258 - val_loss: 0.3248 - val_accuracy: 0.9260 - lr: 1.0000e-04 - 384ms/epoch - 9ms/step\n",
            "Epoch 19/25\n",
            "45/45 - 0s - loss: 0.2922 - accuracy: 0.9266 - val_loss: 0.3245 - val_accuracy: 0.9260 - lr: 1.0000e-04 - 383ms/epoch - 9ms/step\n",
            "Epoch 20/25\n",
            "45/45 - 0s - loss: 0.2919 - accuracy: 0.9266 - val_loss: 0.3242 - val_accuracy: 0.9260 - lr: 1.0000e-04 - 420ms/epoch - 9ms/step\n",
            "Epoch 21/25\n",
            "45/45 - 0s - loss: 0.2916 - accuracy: 0.9266 - val_loss: 0.3239 - val_accuracy: 0.9243 - lr: 1.0000e-04 - 418ms/epoch - 9ms/step\n",
            "Epoch 22/25\n",
            "45/45 - 0s - loss: 0.2913 - accuracy: 0.9266 - val_loss: 0.3236 - val_accuracy: 0.9276 - lr: 1.0000e-04 - 386ms/epoch - 9ms/step\n",
            "Epoch 23/25\n",
            "45/45 - 0s - loss: 0.2910 - accuracy: 0.9266 - val_loss: 0.3233 - val_accuracy: 0.9276 - lr: 1.0000e-04 - 395ms/epoch - 9ms/step\n",
            "Epoch 24/25\n",
            "45/45 - 0s - loss: 0.2907 - accuracy: 0.9266 - val_loss: 0.3231 - val_accuracy: 0.9276 - lr: 1.0000e-04 - 366ms/epoch - 8ms/step\n",
            "Epoch 25/25\n",
            "45/45 - 0s - loss: 0.2904 - accuracy: 0.9258 - val_loss: 0.3228 - val_accuracy: 0.9276 - lr: 1.0000e-04 - 387ms/epoch - 9ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3228 - accuracy: 0.9276\n",
            "Model: \"model_257\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_258 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_531 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_174 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_532 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "45/45 - 5s - loss: 0.4259 - accuracy: 0.8623 - val_loss: 0.3569 - val_accuracy: 0.8717 - lr: 0.0100 - 5s/epoch - 114ms/step\n",
            "Epoch 2/25\n",
            "45/45 - 0s - loss: 0.3085 - accuracy: 0.8828 - val_loss: 0.6391 - val_accuracy: 0.8421 - lr: 0.0100 - 304ms/epoch - 7ms/step\n",
            "Epoch 3/25\n",
            "\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.3159 - accuracy: 0.8891 - val_loss: 0.3302 - val_accuracy: 0.8684 - lr: 0.0100 - 274ms/epoch - 6ms/step\n",
            "Epoch 4/25\n",
            "45/45 - 0s - loss: 0.2857 - accuracy: 0.8891 - val_loss: 0.3269 - val_accuracy: 0.8684 - lr: 1.0000e-03 - 317ms/epoch - 7ms/step\n",
            "Epoch 5/25\n",
            "\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 0.2896 - accuracy: 0.8955 - val_loss: 0.3277 - val_accuracy: 0.8750 - lr: 1.0000e-03 - 278ms/epoch - 6ms/step\n",
            "Epoch 6/25\n",
            "45/45 - 0s - loss: 0.2803 - accuracy: 0.8948 - val_loss: 0.3278 - val_accuracy: 0.8766 - lr: 1.0000e-04 - 287ms/epoch - 6ms/step\n",
            "Epoch 7/25\n",
            "45/45 - 0s - loss: 0.2800 - accuracy: 0.8955 - val_loss: 0.3280 - val_accuracy: 0.8766 - lr: 1.0000e-04 - 308ms/epoch - 7ms/step\n",
            "Epoch 8/25\n",
            "45/45 - 0s - loss: 0.2797 - accuracy: 0.8955 - val_loss: 0.3281 - val_accuracy: 0.8766 - lr: 1.0000e-04 - 285ms/epoch - 6ms/step\n",
            "Epoch 9/25\n",
            "45/45 - 0s - loss: 0.2794 - accuracy: 0.8955 - val_loss: 0.3280 - val_accuracy: 0.8766 - lr: 1.0000e-04 - 288ms/epoch - 6ms/step\n",
            "Epoch 10/25\n",
            "45/45 - 0s - loss: 0.2792 - accuracy: 0.8955 - val_loss: 0.3279 - val_accuracy: 0.8766 - lr: 1.0000e-04 - 302ms/epoch - 7ms/step\n",
            "Epoch 11/25\n",
            "45/45 - 0s - loss: 0.2789 - accuracy: 0.8962 - val_loss: 0.3278 - val_accuracy: 0.8766 - lr: 1.0000e-04 - 316ms/epoch - 7ms/step\n",
            "Epoch 12/25\n",
            "45/45 - 0s - loss: 0.2786 - accuracy: 0.8962 - val_loss: 0.3277 - val_accuracy: 0.8766 - lr: 1.0000e-04 - 276ms/epoch - 6ms/step\n",
            "Epoch 13/25\n",
            "45/45 - 0s - loss: 0.2785 - accuracy: 0.8962 - val_loss: 0.3275 - val_accuracy: 0.8766 - lr: 1.0000e-04 - 301ms/epoch - 7ms/step\n",
            "Epoch 14/25\n",
            "45/45 - 0s - loss: 0.2782 - accuracy: 0.8969 - val_loss: 0.3273 - val_accuracy: 0.8750 - lr: 1.0000e-04 - 286ms/epoch - 6ms/step\n",
            "Epoch 15/25\n",
            "45/45 - 0s - loss: 0.2780 - accuracy: 0.8962 - val_loss: 0.3272 - val_accuracy: 0.8750 - lr: 1.0000e-04 - 309ms/epoch - 7ms/step\n",
            "Epoch 16/25\n",
            "45/45 - 0s - loss: 0.2778 - accuracy: 0.8955 - val_loss: 0.3270 - val_accuracy: 0.8750 - lr: 1.0000e-04 - 298ms/epoch - 7ms/step\n",
            "Epoch 17/25\n",
            "45/45 - 0s - loss: 0.2776 - accuracy: 0.8983 - val_loss: 0.3269 - val_accuracy: 0.8750 - lr: 1.0000e-04 - 279ms/epoch - 6ms/step\n",
            "Epoch 18/25\n",
            "45/45 - 0s - loss: 0.2772 - accuracy: 0.8976 - val_loss: 0.3268 - val_accuracy: 0.8766 - lr: 1.0000e-04 - 275ms/epoch - 6ms/step\n",
            "Epoch 19/25\n",
            "45/45 - 0s - loss: 0.2770 - accuracy: 0.8976 - val_loss: 0.3266 - val_accuracy: 0.8766 - lr: 1.0000e-04 - 301ms/epoch - 7ms/step\n",
            "Epoch 20/25\n",
            "45/45 - 0s - loss: 0.2768 - accuracy: 0.8962 - val_loss: 0.3265 - val_accuracy: 0.8766 - lr: 1.0000e-04 - 321ms/epoch - 7ms/step\n",
            "Epoch 21/25\n",
            "45/45 - 0s - loss: 0.2767 - accuracy: 0.8955 - val_loss: 0.3263 - val_accuracy: 0.8766 - lr: 1.0000e-04 - 277ms/epoch - 6ms/step\n",
            "Epoch 22/25\n",
            "45/45 - 0s - loss: 0.2765 - accuracy: 0.8962 - val_loss: 0.3262 - val_accuracy: 0.8766 - lr: 1.0000e-04 - 309ms/epoch - 7ms/step\n",
            "Epoch 23/25\n",
            "45/45 - 0s - loss: 0.2763 - accuracy: 0.8969 - val_loss: 0.3260 - val_accuracy: 0.8750 - lr: 1.0000e-04 - 267ms/epoch - 6ms/step\n",
            "Epoch 24/25\n",
            "45/45 - 0s - loss: 0.2761 - accuracy: 0.8962 - val_loss: 0.3259 - val_accuracy: 0.8750 - lr: 1.0000e-04 - 290ms/epoch - 6ms/step\n",
            "Epoch 25/25\n",
            "45/45 - 0s - loss: 0.2760 - accuracy: 0.8969 - val_loss: 0.3258 - val_accuracy: 0.8750 - lr: 1.0000e-04 - 266ms/epoch - 6ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3258 - accuracy: 0.8750\n",
            "Model: \"model_259\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_260 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_535 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_175 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_536 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "45/45 - 7s - loss: 0.7650 - accuracy: 0.5367 - val_loss: 0.6335 - val_accuracy: 0.5280 - lr: 0.0100 - 7s/epoch - 148ms/step\n",
            "Epoch 2/15\n",
            "45/45 - 0s - loss: 0.5951 - accuracy: 0.5367 - val_loss: 0.5663 - val_accuracy: 0.5280 - lr: 0.0100 - 379ms/epoch - 8ms/step\n",
            "Epoch 3/15\n",
            "45/45 - 0s - loss: 0.5427 - accuracy: 0.5388 - val_loss: 0.5150 - val_accuracy: 0.5559 - lr: 0.0100 - 361ms/epoch - 8ms/step\n",
            "Epoch 4/15\n",
            "45/45 - 0s - loss: 0.4958 - accuracy: 0.7260 - val_loss: 0.4651 - val_accuracy: 0.8043 - lr: 0.0100 - 352ms/epoch - 8ms/step\n",
            "Epoch 5/15\n",
            "45/45 - 0s - loss: 0.4501 - accuracy: 0.8340 - val_loss: 0.4168 - val_accuracy: 0.8618 - lr: 0.0100 - 364ms/epoch - 8ms/step\n",
            "Epoch 6/15\n",
            "45/45 - 0s - loss: 0.4096 - accuracy: 0.8863 - val_loss: 0.3801 - val_accuracy: 0.8865 - lr: 0.0100 - 372ms/epoch - 8ms/step\n",
            "Epoch 7/15\n",
            "45/45 - 0s - loss: 0.3830 - accuracy: 0.8898 - val_loss: 0.3551 - val_accuracy: 0.9013 - lr: 0.0100 - 382ms/epoch - 8ms/step\n",
            "Epoch 8/15\n",
            "45/45 - 0s - loss: 0.3692 - accuracy: 0.8912 - val_loss: 0.3353 - val_accuracy: 0.9030 - lr: 0.0100 - 404ms/epoch - 9ms/step\n",
            "Epoch 9/15\n",
            "45/45 - 0s - loss: 0.3520 - accuracy: 0.9025 - val_loss: 0.3194 - val_accuracy: 0.9095 - lr: 0.0100 - 383ms/epoch - 9ms/step\n",
            "Epoch 10/15\n",
            "45/45 - 0s - loss: 0.3378 - accuracy: 0.9047 - val_loss: 0.3060 - val_accuracy: 0.9128 - lr: 0.0100 - 372ms/epoch - 8ms/step\n",
            "Epoch 11/15\n",
            "45/45 - 0s - loss: 0.3257 - accuracy: 0.9096 - val_loss: 0.2937 - val_accuracy: 0.9211 - lr: 0.0100 - 387ms/epoch - 9ms/step\n",
            "Epoch 12/15\n",
            "45/45 - 0s - loss: 0.3138 - accuracy: 0.9138 - val_loss: 0.2835 - val_accuracy: 0.9194 - lr: 0.0100 - 388ms/epoch - 9ms/step\n",
            "Epoch 13/15\n",
            "45/45 - 0s - loss: 0.3029 - accuracy: 0.9145 - val_loss: 0.2709 - val_accuracy: 0.9276 - lr: 0.0100 - 393ms/epoch - 9ms/step\n",
            "Epoch 14/15\n",
            "45/45 - 0s - loss: 0.2921 - accuracy: 0.9195 - val_loss: 0.2604 - val_accuracy: 0.9276 - lr: 0.0100 - 386ms/epoch - 9ms/step\n",
            "Epoch 15/15\n",
            "45/45 - 0s - loss: 0.2824 - accuracy: 0.9153 - val_loss: 0.2514 - val_accuracy: 0.9309 - lr: 0.0100 - 363ms/epoch - 8ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2514 - accuracy: 0.9309\n",
            "Model: \"model_261\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_262 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_540 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_176 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_541 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "45/45 - 5s - loss: 0.7016 - accuracy: 0.6907 - val_loss: 0.5679 - val_accuracy: 0.8635 - lr: 0.0100 - 5s/epoch - 119ms/step\n",
            "Epoch 2/25\n",
            "45/45 - 0s - loss: 0.4669 - accuracy: 0.8905 - val_loss: 0.3760 - val_accuracy: 0.8882 - lr: 0.0100 - 280ms/epoch - 6ms/step\n",
            "Epoch 3/25\n",
            "45/45 - 0s - loss: 0.3603 - accuracy: 0.9047 - val_loss: 0.3569 - val_accuracy: 0.8947 - lr: 0.0100 - 277ms/epoch - 6ms/step\n",
            "Epoch 4/25\n",
            "45/45 - 0s - loss: 0.3291 - accuracy: 0.9082 - val_loss: 0.3234 - val_accuracy: 0.8947 - lr: 0.0100 - 315ms/epoch - 7ms/step\n",
            "Epoch 5/25\n",
            "45/45 - 0s - loss: 0.3073 - accuracy: 0.8990 - val_loss: 0.3293 - val_accuracy: 0.9128 - lr: 0.0100 - 322ms/epoch - 7ms/step\n",
            "Epoch 6/25\n",
            "45/45 - 0s - loss: 0.2834 - accuracy: 0.9047 - val_loss: 0.2931 - val_accuracy: 0.8816 - lr: 0.0100 - 307ms/epoch - 7ms/step\n",
            "Epoch 7/25\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.2932 - accuracy: 0.8983 - val_loss: 0.3660 - val_accuracy: 0.9260 - lr: 0.0100 - 285ms/epoch - 6ms/step\n",
            "Epoch 8/25\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 0.3028 - accuracy: 0.9153 - val_loss: 0.3005 - val_accuracy: 0.8799 - lr: 1.0000e-03 - 322ms/epoch - 7ms/step\n",
            "Epoch 9/25\n",
            "\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "45/45 - 0s - loss: 0.2919 - accuracy: 0.8877 - val_loss: 0.2984 - val_accuracy: 0.8816 - lr: 1.0000e-04 - 319ms/epoch - 7ms/step\n",
            "Epoch 10/25\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
            "45/45 - 0s - loss: 0.2905 - accuracy: 0.8884 - val_loss: 0.2982 - val_accuracy: 0.8816 - lr: 1.0000e-05 - 309ms/epoch - 7ms/step\n",
            "Epoch 11/25\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "45/45 - 0s - loss: 0.2903 - accuracy: 0.8884 - val_loss: 0.2981 - val_accuracy: 0.8816 - lr: 1.0000e-06 - 278ms/epoch - 6ms/step\n",
            "Epoch 12/25\n",
            "45/45 - 0s - loss: 0.2903 - accuracy: 0.8884 - val_loss: 0.2981 - val_accuracy: 0.8816 - lr: 1.0000e-07 - 282ms/epoch - 6ms/step\n",
            "Epoch 13/25\n",
            "45/45 - 0s - loss: 0.2903 - accuracy: 0.8884 - val_loss: 0.2981 - val_accuracy: 0.8816 - lr: 1.0000e-07 - 279ms/epoch - 6ms/step\n",
            "Epoch 14/25\n",
            "45/45 - 0s - loss: 0.2903 - accuracy: 0.8884 - val_loss: 0.2981 - val_accuracy: 0.8816 - lr: 1.0000e-07 - 284ms/epoch - 6ms/step\n",
            "Epoch 15/25\n",
            "45/45 - 0s - loss: 0.2903 - accuracy: 0.8884 - val_loss: 0.2981 - val_accuracy: 0.8816 - lr: 1.0000e-07 - 286ms/epoch - 6ms/step\n",
            "Epoch 16/25\n",
            "45/45 - 0s - loss: 0.2903 - accuracy: 0.8884 - val_loss: 0.2981 - val_accuracy: 0.8816 - lr: 1.0000e-07 - 298ms/epoch - 7ms/step\n",
            "Epoch 17/25\n",
            "45/45 - 0s - loss: 0.2903 - accuracy: 0.8884 - val_loss: 0.2981 - val_accuracy: 0.8816 - lr: 1.0000e-07 - 306ms/epoch - 7ms/step\n",
            "Epoch 18/25\n",
            "45/45 - 0s - loss: 0.2903 - accuracy: 0.8884 - val_loss: 0.2981 - val_accuracy: 0.8816 - lr: 1.0000e-07 - 273ms/epoch - 6ms/step\n",
            "Epoch 19/25\n",
            "45/45 - 0s - loss: 0.2903 - accuracy: 0.8884 - val_loss: 0.2981 - val_accuracy: 0.8816 - lr: 1.0000e-07 - 273ms/epoch - 6ms/step\n",
            "Epoch 20/25\n",
            "45/45 - 0s - loss: 0.2903 - accuracy: 0.8884 - val_loss: 0.2981 - val_accuracy: 0.8816 - lr: 1.0000e-07 - 275ms/epoch - 6ms/step\n",
            "Epoch 21/25\n",
            "45/45 - 0s - loss: 0.2903 - accuracy: 0.8884 - val_loss: 0.2981 - val_accuracy: 0.8816 - lr: 1.0000e-07 - 288ms/epoch - 6ms/step\n",
            "Epoch 22/25\n",
            "45/45 - 0s - loss: 0.2903 - accuracy: 0.8884 - val_loss: 0.2981 - val_accuracy: 0.8816 - lr: 1.0000e-07 - 275ms/epoch - 6ms/step\n",
            "Epoch 23/25\n",
            "45/45 - 0s - loss: 0.2903 - accuracy: 0.8884 - val_loss: 0.2981 - val_accuracy: 0.8816 - lr: 1.0000e-07 - 300ms/epoch - 7ms/step\n",
            "Epoch 24/25\n",
            "45/45 - 0s - loss: 0.2903 - accuracy: 0.8884 - val_loss: 0.2981 - val_accuracy: 0.8816 - lr: 1.0000e-07 - 275ms/epoch - 6ms/step\n",
            "Epoch 25/25\n",
            "45/45 - 0s - loss: 0.2903 - accuracy: 0.8884 - val_loss: 0.2981 - val_accuracy: 0.8816 - lr: 1.0000e-07 - 271ms/epoch - 6ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2981 - accuracy: 0.8816\n",
            "Model: \"model_263\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_264 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_544 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_177 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_545 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "45/45 - 5s - loss: 0.5238 - accuracy: 0.6384 - val_loss: 0.4709 - val_accuracy: 0.8059 - lr: 0.0100 - 5s/epoch - 101ms/step\n",
            "Epoch 2/25\n",
            "45/45 - 0s - loss: 0.4605 - accuracy: 0.8489 - val_loss: 0.4197 - val_accuracy: 0.8766 - lr: 0.0100 - 285ms/epoch - 6ms/step\n",
            "Epoch 3/25\n",
            "45/45 - 0s - loss: 0.4339 - accuracy: 0.8736 - val_loss: 0.3816 - val_accuracy: 0.8750 - lr: 0.0100 - 267ms/epoch - 6ms/step\n",
            "Epoch 4/25\n",
            "45/45 - 0s - loss: 0.4039 - accuracy: 0.8792 - val_loss: 0.3585 - val_accuracy: 0.8783 - lr: 0.0100 - 310ms/epoch - 7ms/step\n",
            "Epoch 5/25\n",
            "45/45 - 0s - loss: 0.3738 - accuracy: 0.8778 - val_loss: 0.3375 - val_accuracy: 0.8766 - lr: 0.0100 - 308ms/epoch - 7ms/step\n",
            "Epoch 6/25\n",
            "45/45 - 0s - loss: 0.3645 - accuracy: 0.8863 - val_loss: 0.3401 - val_accuracy: 0.8799 - lr: 0.0100 - 300ms/epoch - 7ms/step\n",
            "Epoch 7/25\n",
            "45/45 - 0s - loss: 0.3496 - accuracy: 0.8806 - val_loss: 0.3651 - val_accuracy: 0.8898 - lr: 0.0100 - 314ms/epoch - 7ms/step\n",
            "Epoch 8/25\n",
            "45/45 - 0s - loss: 0.3451 - accuracy: 0.8863 - val_loss: 0.2931 - val_accuracy: 0.8832 - lr: 0.0100 - 288ms/epoch - 6ms/step\n",
            "Epoch 9/25\n",
            "45/45 - 0s - loss: 0.3275 - accuracy: 0.8941 - val_loss: 0.3039 - val_accuracy: 0.8931 - lr: 0.0100 - 297ms/epoch - 7ms/step\n",
            "Epoch 10/25\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.3346 - accuracy: 0.8898 - val_loss: 0.3215 - val_accuracy: 0.8947 - lr: 0.0100 - 319ms/epoch - 7ms/step\n",
            "Epoch 11/25\n",
            "45/45 - 0s - loss: 0.3095 - accuracy: 0.8969 - val_loss: 0.3185 - val_accuracy: 0.8980 - lr: 1.0000e-03 - 312ms/epoch - 7ms/step\n",
            "Epoch 12/25\n",
            "45/45 - 0s - loss: 0.3061 - accuracy: 0.8990 - val_loss: 0.2995 - val_accuracy: 0.8980 - lr: 1.0000e-03 - 286ms/epoch - 6ms/step\n",
            "Epoch 13/25\n",
            "45/45 - 0s - loss: 0.3045 - accuracy: 0.8976 - val_loss: 0.3155 - val_accuracy: 0.8964 - lr: 1.0000e-03 - 284ms/epoch - 6ms/step\n",
            "Epoch 14/25\n",
            "45/45 - 0s - loss: 0.3035 - accuracy: 0.8976 - val_loss: 0.2762 - val_accuracy: 0.8964 - lr: 1.0000e-03 - 282ms/epoch - 6ms/step\n",
            "Epoch 15/25\n",
            "45/45 - 0s - loss: 0.3024 - accuracy: 0.8976 - val_loss: 0.2733 - val_accuracy: 0.8980 - lr: 1.0000e-03 - 314ms/epoch - 7ms/step\n",
            "Epoch 16/25\n",
            "45/45 - 0s - loss: 0.3007 - accuracy: 0.8990 - val_loss: 0.2756 - val_accuracy: 0.8997 - lr: 1.0000e-03 - 289ms/epoch - 6ms/step\n",
            "Epoch 17/25\n",
            "45/45 - 0s - loss: 0.2993 - accuracy: 0.9011 - val_loss: 0.2924 - val_accuracy: 0.8997 - lr: 1.0000e-03 - 283ms/epoch - 6ms/step\n",
            "Epoch 18/25\n",
            "45/45 - 0s - loss: 0.2981 - accuracy: 0.9011 - val_loss: 0.2763 - val_accuracy: 0.8997 - lr: 1.0000e-03 - 272ms/epoch - 6ms/step\n",
            "Epoch 19/25\n",
            "45/45 - 0s - loss: 0.2966 - accuracy: 0.9004 - val_loss: 0.2887 - val_accuracy: 0.9013 - lr: 1.0000e-03 - 282ms/epoch - 6ms/step\n",
            "Epoch 20/25\n",
            "45/45 - 0s - loss: 0.2960 - accuracy: 0.9018 - val_loss: 0.2670 - val_accuracy: 0.9013 - lr: 1.0000e-03 - 296ms/epoch - 7ms/step\n",
            "Epoch 21/25\n",
            "45/45 - 0s - loss: 0.2945 - accuracy: 0.9032 - val_loss: 0.2664 - val_accuracy: 0.9013 - lr: 1.0000e-03 - 277ms/epoch - 6ms/step\n",
            "Epoch 22/25\n",
            "45/45 - 0s - loss: 0.2937 - accuracy: 0.9040 - val_loss: 0.2626 - val_accuracy: 0.9013 - lr: 1.0000e-03 - 303ms/epoch - 7ms/step\n",
            "Epoch 23/25\n",
            "45/45 - 0s - loss: 0.2928 - accuracy: 0.9040 - val_loss: 0.2634 - val_accuracy: 0.9030 - lr: 1.0000e-03 - 307ms/epoch - 7ms/step\n",
            "Epoch 24/25\n",
            "45/45 - 0s - loss: 0.2918 - accuracy: 0.9040 - val_loss: 0.2626 - val_accuracy: 0.9013 - lr: 1.0000e-03 - 268ms/epoch - 6ms/step\n",
            "Epoch 25/25\n",
            "45/45 - 0s - loss: 0.2904 - accuracy: 0.9032 - val_loss: 0.2606 - val_accuracy: 0.9030 - lr: 1.0000e-03 - 278ms/epoch - 6ms/step\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2606 - accuracy: 0.9030\n",
            "Model: \"model_265\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_266 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_548 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_178 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_549 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "45/45 - 5s - loss: 0.4858 - accuracy: 0.7782 - val_loss: 0.3731 - val_accuracy: 0.9079 - lr: 0.0100 - 5s/epoch - 118ms/step\n",
            "Epoch 2/25\n",
            "45/45 - 0s - loss: 0.3417 - accuracy: 0.9082 - val_loss: 0.3338 - val_accuracy: 0.9194 - lr: 0.0100 - 315ms/epoch - 7ms/step\n",
            "Epoch 3/25\n",
            "45/45 - 0s - loss: 0.3019 - accuracy: 0.9089 - val_loss: 0.3020 - val_accuracy: 0.9243 - lr: 0.0100 - 274ms/epoch - 6ms/step\n",
            "Epoch 4/25\n",
            "45/45 - 0s - loss: 0.2828 - accuracy: 0.9145 - val_loss: 0.2890 - val_accuracy: 0.9309 - lr: 0.0100 - 274ms/epoch - 6ms/step\n",
            "Epoch 5/25\n",
            "45/45 - 0s - loss: 0.2605 - accuracy: 0.9138 - val_loss: 0.2677 - val_accuracy: 0.9391 - lr: 0.0100 - 277ms/epoch - 6ms/step\n",
            "Epoch 6/25\n",
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.2875 - accuracy: 0.9018 - val_loss: 0.2797 - val_accuracy: 0.9079 - lr: 0.0100 - 317ms/epoch - 7ms/step\n",
            "Epoch 7/25\n",
            "45/45 - 0s - loss: 0.2542 - accuracy: 0.9110 - val_loss: 0.2692 - val_accuracy: 0.9211 - lr: 1.0000e-03 - 311ms/epoch - 7ms/step\n",
            "Epoch 8/25\n",
            "45/45 - 0s - loss: 0.2523 - accuracy: 0.9153 - val_loss: 0.3011 - val_accuracy: 0.8914 - lr: 1.0000e-03 - 271ms/epoch - 6ms/step\n",
            "Epoch 9/25\n",
            "\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 0.2760 - accuracy: 0.8976 - val_loss: 0.2938 - val_accuracy: 0.8931 - lr: 1.0000e-03 - 307ms/epoch - 7ms/step\n",
            "Epoch 10/25\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "45/45 - 0s - loss: 0.2714 - accuracy: 0.8976 - val_loss: 0.2932 - val_accuracy: 0.8931 - lr: 1.0000e-04 - 299ms/epoch - 7ms/step\n",
            "Epoch 11/25\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
            "45/45 - 0s - loss: 0.2710 - accuracy: 0.8969 - val_loss: 0.2931 - val_accuracy: 0.8931 - lr: 1.0000e-05 - 309ms/epoch - 7ms/step\n",
            "Epoch 12/25\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "45/45 - 0s - loss: 0.2710 - accuracy: 0.8969 - val_loss: 0.2931 - val_accuracy: 0.8931 - lr: 1.0000e-06 - 294ms/epoch - 7ms/step\n",
            "Epoch 13/25\n",
            "45/45 - 0s - loss: 0.2710 - accuracy: 0.8969 - val_loss: 0.2931 - val_accuracy: 0.8931 - lr: 1.0000e-07 - 289ms/epoch - 6ms/step\n",
            "Epoch 14/25\n",
            "45/45 - 0s - loss: 0.2710 - accuracy: 0.8969 - val_loss: 0.2931 - val_accuracy: 0.8931 - lr: 1.0000e-07 - 272ms/epoch - 6ms/step\n",
            "Epoch 15/25\n",
            "45/45 - 0s - loss: 0.2710 - accuracy: 0.8969 - val_loss: 0.2931 - val_accuracy: 0.8931 - lr: 1.0000e-07 - 276ms/epoch - 6ms/step\n",
            "Epoch 16/25\n",
            "45/45 - 0s - loss: 0.2710 - accuracy: 0.8969 - val_loss: 0.2931 - val_accuracy: 0.8931 - lr: 1.0000e-07 - 308ms/epoch - 7ms/step\n",
            "Epoch 17/25\n",
            "45/45 - 0s - loss: 0.2710 - accuracy: 0.8969 - val_loss: 0.2931 - val_accuracy: 0.8931 - lr: 1.0000e-07 - 269ms/epoch - 6ms/step\n",
            "Epoch 18/25\n",
            "45/45 - 0s - loss: 0.2710 - accuracy: 0.8969 - val_loss: 0.2931 - val_accuracy: 0.8931 - lr: 1.0000e-07 - 301ms/epoch - 7ms/step\n",
            "Epoch 19/25\n",
            "45/45 - 0s - loss: 0.2710 - accuracy: 0.8969 - val_loss: 0.2931 - val_accuracy: 0.8931 - lr: 1.0000e-07 - 299ms/epoch - 7ms/step\n",
            "Epoch 20/25\n",
            "45/45 - 0s - loss: 0.2710 - accuracy: 0.8969 - val_loss: 0.2931 - val_accuracy: 0.8931 - lr: 1.0000e-07 - 306ms/epoch - 7ms/step\n",
            "Epoch 21/25\n",
            "45/45 - 0s - loss: 0.2710 - accuracy: 0.8969 - val_loss: 0.2931 - val_accuracy: 0.8931 - lr: 1.0000e-07 - 301ms/epoch - 7ms/step\n",
            "Epoch 22/25\n",
            "45/45 - 0s - loss: 0.2710 - accuracy: 0.8969 - val_loss: 0.2931 - val_accuracy: 0.8931 - lr: 1.0000e-07 - 303ms/epoch - 7ms/step\n",
            "Epoch 23/25\n",
            "45/45 - 0s - loss: 0.2710 - accuracy: 0.8969 - val_loss: 0.2931 - val_accuracy: 0.8931 - lr: 1.0000e-07 - 309ms/epoch - 7ms/step\n",
            "Epoch 24/25\n",
            "45/45 - 0s - loss: 0.2710 - accuracy: 0.8969 - val_loss: 0.2931 - val_accuracy: 0.8931 - lr: 1.0000e-07 - 303ms/epoch - 7ms/step\n",
            "Epoch 25/25\n",
            "45/45 - 0s - loss: 0.2710 - accuracy: 0.8969 - val_loss: 0.2931 - val_accuracy: 0.8931 - lr: 1.0000e-07 - 301ms/epoch - 7ms/step\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2931 - accuracy: 0.8931\n",
            "Model: \"model_267\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_268 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_552 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_179 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_553 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "45/45 - 7s - loss: 0.7927 - accuracy: 0.5339 - val_loss: 0.6506 - val_accuracy: 0.5345 - lr: 0.0100 - 7s/epoch - 148ms/step\n",
            "Epoch 2/25\n",
            "45/45 - 0s - loss: 0.6142 - accuracy: 0.5339 - val_loss: 0.5824 - val_accuracy: 0.5345 - lr: 0.0100 - 397ms/epoch - 9ms/step\n",
            "Epoch 3/25\n",
            "45/45 - 0s - loss: 0.5284 - accuracy: 0.5339 - val_loss: 0.4879 - val_accuracy: 0.5362 - lr: 0.0100 - 379ms/epoch - 8ms/step\n",
            "Epoch 4/25\n",
            "45/45 - 0s - loss: 0.4519 - accuracy: 0.6801 - val_loss: 0.4291 - val_accuracy: 0.7911 - lr: 0.0100 - 359ms/epoch - 8ms/step\n",
            "Epoch 5/25\n",
            "45/45 - 0s - loss: 0.4084 - accuracy: 0.8573 - val_loss: 0.3894 - val_accuracy: 0.8832 - lr: 0.0100 - 389ms/epoch - 9ms/step\n",
            "Epoch 6/25\n",
            "45/45 - 0s - loss: 0.3622 - accuracy: 0.9054 - val_loss: 0.3638 - val_accuracy: 0.8947 - lr: 0.0100 - 413ms/epoch - 9ms/step\n",
            "Epoch 7/25\n",
            "45/45 - 0s - loss: 0.3411 - accuracy: 0.9145 - val_loss: 0.3536 - val_accuracy: 0.8980 - lr: 0.0100 - 492ms/epoch - 11ms/step\n",
            "Epoch 8/25\n",
            "45/45 - 1s - loss: 0.3261 - accuracy: 0.9181 - val_loss: 0.3373 - val_accuracy: 0.9161 - lr: 0.0100 - 532ms/epoch - 12ms/step\n",
            "Epoch 9/25\n",
            "45/45 - 1s - loss: 0.2982 - accuracy: 0.9251 - val_loss: 0.3309 - val_accuracy: 0.9128 - lr: 0.0100 - 521ms/epoch - 12ms/step\n",
            "Epoch 10/25\n",
            "45/45 - 1s - loss: 0.2785 - accuracy: 0.9258 - val_loss: 0.3048 - val_accuracy: 0.9095 - lr: 0.0100 - 633ms/epoch - 14ms/step\n",
            "Epoch 11/25\n",
            "45/45 - 0s - loss: 0.2581 - accuracy: 0.9379 - val_loss: 0.2914 - val_accuracy: 0.9079 - lr: 0.0100 - 490ms/epoch - 11ms/step\n",
            "Epoch 12/25\n",
            "45/45 - 0s - loss: 0.2426 - accuracy: 0.9357 - val_loss: 0.2969 - val_accuracy: 0.9145 - lr: 0.0100 - 415ms/epoch - 9ms/step\n",
            "Epoch 13/25\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.2594 - accuracy: 0.9181 - val_loss: 0.2951 - val_accuracy: 0.9046 - lr: 0.0100 - 387ms/epoch - 9ms/step\n",
            "Epoch 14/25\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 0.2582 - accuracy: 0.9131 - val_loss: 0.2936 - val_accuracy: 0.9062 - lr: 1.0000e-03 - 396ms/epoch - 9ms/step\n",
            "Epoch 15/25\n",
            "\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "45/45 - 0s - loss: 0.2558 - accuracy: 0.9174 - val_loss: 0.2934 - val_accuracy: 0.9046 - lr: 1.0000e-04 - 383ms/epoch - 9ms/step\n",
            "Epoch 16/25\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
            "45/45 - 0s - loss: 0.2556 - accuracy: 0.9174 - val_loss: 0.2934 - val_accuracy: 0.9046 - lr: 1.0000e-05 - 381ms/epoch - 8ms/step\n",
            "Epoch 17/25\n",
            "\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "45/45 - 0s - loss: 0.2556 - accuracy: 0.9174 - val_loss: 0.2934 - val_accuracy: 0.9046 - lr: 1.0000e-06 - 410ms/epoch - 9ms/step\n",
            "Epoch 18/25\n",
            "45/45 - 0s - loss: 0.2556 - accuracy: 0.9174 - val_loss: 0.2934 - val_accuracy: 0.9046 - lr: 1.0000e-07 - 392ms/epoch - 9ms/step\n",
            "Epoch 19/25\n",
            "45/45 - 0s - loss: 0.2556 - accuracy: 0.9174 - val_loss: 0.2934 - val_accuracy: 0.9046 - lr: 1.0000e-07 - 380ms/epoch - 8ms/step\n",
            "Epoch 20/25\n",
            "45/45 - 0s - loss: 0.2556 - accuracy: 0.9174 - val_loss: 0.2934 - val_accuracy: 0.9046 - lr: 1.0000e-07 - 368ms/epoch - 8ms/step\n",
            "Epoch 21/25\n",
            "45/45 - 0s - loss: 0.2556 - accuracy: 0.9174 - val_loss: 0.2934 - val_accuracy: 0.9046 - lr: 1.0000e-07 - 363ms/epoch - 8ms/step\n",
            "Epoch 22/25\n",
            "45/45 - 0s - loss: 0.2556 - accuracy: 0.9174 - val_loss: 0.2934 - val_accuracy: 0.9046 - lr: 1.0000e-07 - 387ms/epoch - 9ms/step\n",
            "Epoch 23/25\n",
            "45/45 - 0s - loss: 0.2556 - accuracy: 0.9174 - val_loss: 0.2934 - val_accuracy: 0.9046 - lr: 1.0000e-07 - 373ms/epoch - 8ms/step\n",
            "Epoch 24/25\n",
            "45/45 - 0s - loss: 0.2556 - accuracy: 0.9174 - val_loss: 0.2934 - val_accuracy: 0.9046 - lr: 1.0000e-07 - 391ms/epoch - 9ms/step\n",
            "Epoch 25/25\n",
            "45/45 - 0s - loss: 0.2556 - accuracy: 0.9174 - val_loss: 0.2934 - val_accuracy: 0.9046 - lr: 1.0000e-07 - 401ms/epoch - 9ms/step\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2934 - accuracy: 0.9046\n",
            "Model: \"model_269\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_270 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_557 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_180 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_558 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "45/45 - 5s - loss: 0.4947 - accuracy: 0.7288 - val_loss: 0.4127 - val_accuracy: 0.8799 - lr: 0.0100 - 5s/epoch - 105ms/step\n",
            "Epoch 2/25\n",
            "45/45 - 0s - loss: 0.3672 - accuracy: 0.8849 - val_loss: 0.3463 - val_accuracy: 0.8964 - lr: 0.0100 - 303ms/epoch - 7ms/step\n",
            "Epoch 3/25\n",
            "45/45 - 0s - loss: 0.3247 - accuracy: 0.8969 - val_loss: 0.3085 - val_accuracy: 0.8947 - lr: 0.0100 - 270ms/epoch - 6ms/step\n",
            "Epoch 4/25\n",
            "45/45 - 0s - loss: 0.3024 - accuracy: 0.8976 - val_loss: 0.2898 - val_accuracy: 0.8997 - lr: 0.0100 - 284ms/epoch - 6ms/step\n",
            "Epoch 5/25\n",
            "45/45 - 0s - loss: 0.2774 - accuracy: 0.9032 - val_loss: 0.2736 - val_accuracy: 0.9112 - lr: 0.0100 - 285ms/epoch - 6ms/step\n",
            "Epoch 6/25\n",
            "45/45 - 0s - loss: 0.2573 - accuracy: 0.9082 - val_loss: 0.2508 - val_accuracy: 0.9178 - lr: 0.0100 - 286ms/epoch - 6ms/step\n",
            "Epoch 7/25\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.2594 - accuracy: 0.9054 - val_loss: 0.2759 - val_accuracy: 0.8947 - lr: 0.0100 - 277ms/epoch - 6ms/step\n",
            "Epoch 8/25\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 0.2716 - accuracy: 0.8976 - val_loss: 0.2739 - val_accuracy: 0.8997 - lr: 1.0000e-03 - 314ms/epoch - 7ms/step\n",
            "Epoch 9/25\n",
            "\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "45/45 - 0s - loss: 0.2687 - accuracy: 0.8962 - val_loss: 0.2739 - val_accuracy: 0.9013 - lr: 1.0000e-04 - 308ms/epoch - 7ms/step\n",
            "Epoch 10/25\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
            "45/45 - 0s - loss: 0.2684 - accuracy: 0.8962 - val_loss: 0.2739 - val_accuracy: 0.9013 - lr: 1.0000e-05 - 317ms/epoch - 7ms/step\n",
            "Epoch 11/25\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "45/45 - 0s - loss: 0.2684 - accuracy: 0.8962 - val_loss: 0.2739 - val_accuracy: 0.9013 - lr: 1.0000e-06 - 315ms/epoch - 7ms/step\n",
            "Epoch 12/25\n",
            "45/45 - 0s - loss: 0.2684 - accuracy: 0.8962 - val_loss: 0.2739 - val_accuracy: 0.9013 - lr: 1.0000e-07 - 302ms/epoch - 7ms/step\n",
            "Epoch 13/25\n",
            "45/45 - 0s - loss: 0.2684 - accuracy: 0.8962 - val_loss: 0.2739 - val_accuracy: 0.9013 - lr: 1.0000e-07 - 298ms/epoch - 7ms/step\n",
            "Epoch 14/25\n",
            "45/45 - 0s - loss: 0.2684 - accuracy: 0.8962 - val_loss: 0.2739 - val_accuracy: 0.9013 - lr: 1.0000e-07 - 284ms/epoch - 6ms/step\n",
            "Epoch 15/25\n",
            "45/45 - 0s - loss: 0.2684 - accuracy: 0.8962 - val_loss: 0.2739 - val_accuracy: 0.9013 - lr: 1.0000e-07 - 282ms/epoch - 6ms/step\n",
            "Epoch 16/25\n",
            "45/45 - 0s - loss: 0.2684 - accuracy: 0.8962 - val_loss: 0.2739 - val_accuracy: 0.9013 - lr: 1.0000e-07 - 310ms/epoch - 7ms/step\n",
            "Epoch 17/25\n",
            "45/45 - 0s - loss: 0.2684 - accuracy: 0.8962 - val_loss: 0.2739 - val_accuracy: 0.9013 - lr: 1.0000e-07 - 299ms/epoch - 7ms/step\n",
            "Epoch 18/25\n",
            "45/45 - 0s - loss: 0.2684 - accuracy: 0.8962 - val_loss: 0.2739 - val_accuracy: 0.9013 - lr: 1.0000e-07 - 285ms/epoch - 6ms/step\n",
            "Epoch 19/25\n",
            "45/45 - 0s - loss: 0.2684 - accuracy: 0.8962 - val_loss: 0.2739 - val_accuracy: 0.9013 - lr: 1.0000e-07 - 312ms/epoch - 7ms/step\n",
            "Epoch 20/25\n",
            "45/45 - 0s - loss: 0.2684 - accuracy: 0.8962 - val_loss: 0.2739 - val_accuracy: 0.9013 - lr: 1.0000e-07 - 302ms/epoch - 7ms/step\n",
            "Epoch 21/25\n",
            "45/45 - 0s - loss: 0.2684 - accuracy: 0.8962 - val_loss: 0.2739 - val_accuracy: 0.9013 - lr: 1.0000e-07 - 278ms/epoch - 6ms/step\n",
            "Epoch 22/25\n",
            "45/45 - 0s - loss: 0.2684 - accuracy: 0.8962 - val_loss: 0.2739 - val_accuracy: 0.9013 - lr: 1.0000e-07 - 318ms/epoch - 7ms/step\n",
            "Epoch 23/25\n",
            "45/45 - 0s - loss: 0.2684 - accuracy: 0.8962 - val_loss: 0.2739 - val_accuracy: 0.9013 - lr: 1.0000e-07 - 304ms/epoch - 7ms/step\n",
            "Epoch 24/25\n",
            "45/45 - 0s - loss: 0.2684 - accuracy: 0.8962 - val_loss: 0.2739 - val_accuracy: 0.9013 - lr: 1.0000e-07 - 312ms/epoch - 7ms/step\n",
            "Epoch 25/25\n",
            "45/45 - 0s - loss: 0.2684 - accuracy: 0.8962 - val_loss: 0.2739 - val_accuracy: 0.9013 - lr: 1.0000e-07 - 315ms/epoch - 7ms/step\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2739 - accuracy: 0.9013\n",
            "Model: \"model_271\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_272 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_561 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_181 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_562 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "45/45 - 5s - loss: 7.2441 - accuracy: 0.5304 - val_loss: 7.0529 - val_accuracy: 0.5428 - lr: 0.0100 - 5s/epoch - 114ms/step\n",
            "Epoch 2/15\n",
            "\n",
            "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 7.2441 - accuracy: 0.5304 - val_loss: 7.0529 - val_accuracy: 0.5428 - lr: 0.0100 - 317ms/epoch - 7ms/step\n",
            "Epoch 3/15\n",
            "\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 7.2441 - accuracy: 0.5304 - val_loss: 7.0529 - val_accuracy: 0.5428 - lr: 1.0000e-03 - 299ms/epoch - 7ms/step\n",
            "Epoch 4/15\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "45/45 - 0s - loss: 7.2441 - accuracy: 0.5304 - val_loss: 7.0529 - val_accuracy: 0.5428 - lr: 1.0000e-04 - 283ms/epoch - 6ms/step\n",
            "Epoch 5/15\n",
            "\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
            "45/45 - 0s - loss: 7.2441 - accuracy: 0.5304 - val_loss: 7.0529 - val_accuracy: 0.5428 - lr: 1.0000e-05 - 300ms/epoch - 7ms/step\n",
            "Epoch 6/15\n",
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "45/45 - 0s - loss: 7.2441 - accuracy: 0.5304 - val_loss: 7.0529 - val_accuracy: 0.5428 - lr: 1.0000e-06 - 284ms/epoch - 6ms/step\n",
            "Epoch 7/15\n",
            "45/45 - 0s - loss: 7.2441 - accuracy: 0.5304 - val_loss: 7.0529 - val_accuracy: 0.5428 - lr: 1.0000e-07 - 311ms/epoch - 7ms/step\n",
            "Epoch 8/15\n",
            "45/45 - 0s - loss: 7.2441 - accuracy: 0.5304 - val_loss: 7.0529 - val_accuracy: 0.5428 - lr: 1.0000e-07 - 285ms/epoch - 6ms/step\n",
            "Epoch 9/15\n",
            "45/45 - 0s - loss: 7.2441 - accuracy: 0.5304 - val_loss: 7.0529 - val_accuracy: 0.5428 - lr: 1.0000e-07 - 275ms/epoch - 6ms/step\n",
            "Epoch 10/15\n",
            "45/45 - 0s - loss: 7.2441 - accuracy: 0.5304 - val_loss: 7.0529 - val_accuracy: 0.5428 - lr: 1.0000e-07 - 315ms/epoch - 7ms/step\n",
            "Epoch 11/15\n",
            "45/45 - 0s - loss: 7.2441 - accuracy: 0.5304 - val_loss: 7.0529 - val_accuracy: 0.5428 - lr: 1.0000e-07 - 281ms/epoch - 6ms/step\n",
            "Epoch 12/15\n",
            "45/45 - 0s - loss: 7.2441 - accuracy: 0.5304 - val_loss: 7.0529 - val_accuracy: 0.5428 - lr: 1.0000e-07 - 312ms/epoch - 7ms/step\n",
            "Epoch 13/15\n",
            "45/45 - 0s - loss: 7.2441 - accuracy: 0.5304 - val_loss: 7.0529 - val_accuracy: 0.5428 - lr: 1.0000e-07 - 300ms/epoch - 7ms/step\n",
            "Epoch 14/15\n",
            "45/45 - 0s - loss: 7.2441 - accuracy: 0.5304 - val_loss: 7.0529 - val_accuracy: 0.5428 - lr: 1.0000e-07 - 260ms/epoch - 6ms/step\n",
            "Epoch 15/15\n",
            "45/45 - 0s - loss: 7.2441 - accuracy: 0.5304 - val_loss: 7.0529 - val_accuracy: 0.5428 - lr: 1.0000e-07 - 303ms/epoch - 7ms/step\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.0529 - accuracy: 0.5428\n",
            "Model: \"model_273\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_274 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_565 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_182 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_566 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "45/45 - 7s - loss: 0.6681 - accuracy: 0.5395 - val_loss: 0.5747 - val_accuracy: 0.5214 - lr: 0.0100 - 7s/epoch - 150ms/step\n",
            "Epoch 2/15\n",
            "45/45 - 0s - loss: 0.5224 - accuracy: 0.5395 - val_loss: 0.4988 - val_accuracy: 0.5214 - lr: 0.0100 - 370ms/epoch - 8ms/step\n",
            "Epoch 3/15\n",
            "45/45 - 0s - loss: 0.4636 - accuracy: 0.6709 - val_loss: 0.4494 - val_accuracy: 0.8635 - lr: 0.0100 - 371ms/epoch - 8ms/step\n",
            "Epoch 4/15\n",
            "45/45 - 0s - loss: 0.4234 - accuracy: 0.8842 - val_loss: 0.4120 - val_accuracy: 0.9030 - lr: 0.0100 - 397ms/epoch - 9ms/step\n",
            "Epoch 5/15\n",
            "45/45 - 0s - loss: 0.3891 - accuracy: 0.9018 - val_loss: 0.3857 - val_accuracy: 0.8980 - lr: 0.0100 - 369ms/epoch - 8ms/step\n",
            "Epoch 6/15\n",
            "45/45 - 0s - loss: 0.3639 - accuracy: 0.9040 - val_loss: 0.3617 - val_accuracy: 0.9062 - lr: 0.0100 - 389ms/epoch - 9ms/step\n",
            "Epoch 7/15\n",
            "45/45 - 0s - loss: 0.3501 - accuracy: 0.9025 - val_loss: 0.3447 - val_accuracy: 0.8964 - lr: 0.0100 - 360ms/epoch - 8ms/step\n",
            "Epoch 8/15\n",
            "45/45 - 0s - loss: 0.3320 - accuracy: 0.9004 - val_loss: 0.3246 - val_accuracy: 0.9030 - lr: 0.0100 - 370ms/epoch - 8ms/step\n",
            "Epoch 9/15\n",
            "45/45 - 0s - loss: 0.3184 - accuracy: 0.8997 - val_loss: 0.3555 - val_accuracy: 0.9079 - lr: 0.0100 - 386ms/epoch - 9ms/step\n",
            "Epoch 10/15\n",
            "45/45 - 0s - loss: 0.2958 - accuracy: 0.9124 - val_loss: 0.3144 - val_accuracy: 0.9128 - lr: 0.0100 - 377ms/epoch - 8ms/step\n",
            "Epoch 11/15\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.3195 - accuracy: 0.9061 - val_loss: 0.3137 - val_accuracy: 0.9095 - lr: 0.0100 - 368ms/epoch - 8ms/step\n",
            "Epoch 12/15\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 0.3029 - accuracy: 0.9202 - val_loss: 0.2958 - val_accuracy: 0.9145 - lr: 1.0000e-03 - 373ms/epoch - 8ms/step\n",
            "Epoch 13/15\n",
            "45/45 - 0s - loss: 0.2910 - accuracy: 0.9223 - val_loss: 0.2963 - val_accuracy: 0.9145 - lr: 1.0000e-04 - 393ms/epoch - 9ms/step\n",
            "Epoch 14/15\n",
            "45/45 - 0s - loss: 0.2899 - accuracy: 0.9237 - val_loss: 0.2970 - val_accuracy: 0.9112 - lr: 1.0000e-04 - 391ms/epoch - 9ms/step\n",
            "Epoch 15/15\n",
            "45/45 - 0s - loss: 0.2893 - accuracy: 0.9230 - val_loss: 0.2973 - val_accuracy: 0.9112 - lr: 1.0000e-04 - 365ms/epoch - 8ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2973 - accuracy: 0.9112\n",
            "Model: \"model_275\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_276 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_570 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_183 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_571 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "45/45 - 5s - loss: 0.6109 - accuracy: 0.6674 - val_loss: 0.5391 - val_accuracy: 0.8783 - lr: 0.0100 - 5s/epoch - 120ms/step\n",
            "Epoch 2/25\n",
            "45/45 - 0s - loss: 0.5152 - accuracy: 0.8750 - val_loss: 0.4818 - val_accuracy: 0.8898 - lr: 0.0100 - 287ms/epoch - 6ms/step\n",
            "Epoch 3/25\n",
            "45/45 - 0s - loss: 0.4712 - accuracy: 0.8806 - val_loss: 0.4417 - val_accuracy: 0.8947 - lr: 0.0100 - 319ms/epoch - 7ms/step\n",
            "Epoch 4/25\n",
            "45/45 - 0s - loss: 0.4303 - accuracy: 0.8785 - val_loss: 0.3982 - val_accuracy: 0.8931 - lr: 0.0100 - 297ms/epoch - 7ms/step\n",
            "Epoch 5/25\n",
            "45/45 - 0s - loss: 0.4004 - accuracy: 0.8778 - val_loss: 0.3780 - val_accuracy: 0.8931 - lr: 0.0100 - 275ms/epoch - 6ms/step\n",
            "Epoch 6/25\n",
            "45/45 - 0s - loss: 0.3835 - accuracy: 0.8771 - val_loss: 0.3628 - val_accuracy: 0.8947 - lr: 0.0100 - 301ms/epoch - 7ms/step\n",
            "Epoch 7/25\n",
            "45/45 - 0s - loss: 0.3680 - accuracy: 0.8792 - val_loss: 0.3486 - val_accuracy: 0.8947 - lr: 0.0100 - 289ms/epoch - 6ms/step\n",
            "Epoch 8/25\n",
            "45/45 - 0s - loss: 0.3552 - accuracy: 0.8792 - val_loss: 0.3376 - val_accuracy: 0.8964 - lr: 0.0100 - 282ms/epoch - 6ms/step\n",
            "Epoch 9/25\n",
            "45/45 - 0s - loss: 0.3438 - accuracy: 0.8821 - val_loss: 0.3253 - val_accuracy: 0.8964 - lr: 0.0100 - 314ms/epoch - 7ms/step\n",
            "Epoch 10/25\n",
            "45/45 - 0s - loss: 0.3317 - accuracy: 0.8821 - val_loss: 0.3145 - val_accuracy: 0.8997 - lr: 0.0100 - 311ms/epoch - 7ms/step\n",
            "Epoch 11/25\n",
            "45/45 - 0s - loss: 0.3192 - accuracy: 0.8905 - val_loss: 0.3057 - val_accuracy: 0.8947 - lr: 0.0100 - 314ms/epoch - 7ms/step\n",
            "Epoch 12/25\n",
            "45/45 - 0s - loss: 0.3069 - accuracy: 0.8905 - val_loss: 0.2869 - val_accuracy: 0.9128 - lr: 0.0100 - 268ms/epoch - 6ms/step\n",
            "Epoch 13/25\n",
            "45/45 - 0s - loss: 0.2973 - accuracy: 0.8962 - val_loss: 0.2898 - val_accuracy: 0.9062 - lr: 0.0100 - 277ms/epoch - 6ms/step\n",
            "Epoch 14/25\n",
            "45/45 - 0s - loss: 0.2875 - accuracy: 0.8948 - val_loss: 0.2706 - val_accuracy: 0.9194 - lr: 0.0100 - 330ms/epoch - 7ms/step\n",
            "Epoch 15/25\n",
            "45/45 - 0s - loss: 0.2784 - accuracy: 0.9025 - val_loss: 0.2615 - val_accuracy: 0.9128 - lr: 0.0100 - 291ms/epoch - 6ms/step\n",
            "Epoch 16/25\n",
            "45/45 - 0s - loss: 0.2728 - accuracy: 0.9004 - val_loss: 0.2695 - val_accuracy: 0.8997 - lr: 0.0100 - 302ms/epoch - 7ms/step\n",
            "Epoch 17/25\n",
            "45/45 - 0s - loss: 0.2683 - accuracy: 0.8990 - val_loss: 0.2526 - val_accuracy: 0.9161 - lr: 0.0100 - 307ms/epoch - 7ms/step\n",
            "Epoch 18/25\n",
            "45/45 - 0s - loss: 0.2612 - accuracy: 0.9075 - val_loss: 0.2770 - val_accuracy: 0.9194 - lr: 0.0100 - 306ms/epoch - 7ms/step\n",
            "Epoch 19/25\n",
            "45/45 - 0s - loss: 0.2574 - accuracy: 0.9025 - val_loss: 0.3249 - val_accuracy: 0.8931 - lr: 0.0100 - 285ms/epoch - 6ms/step\n",
            "Epoch 20/25\n",
            "45/45 - 0s - loss: 0.2537 - accuracy: 0.9082 - val_loss: 0.2397 - val_accuracy: 0.9161 - lr: 0.0100 - 307ms/epoch - 7ms/step\n",
            "Epoch 21/25\n",
            "45/45 - 0s - loss: 0.2488 - accuracy: 0.9025 - val_loss: 0.2321 - val_accuracy: 0.9211 - lr: 0.0100 - 277ms/epoch - 6ms/step\n",
            "Epoch 22/25\n",
            "45/45 - 0s - loss: 0.2417 - accuracy: 0.9061 - val_loss: 0.2295 - val_accuracy: 0.9211 - lr: 0.0100 - 289ms/epoch - 6ms/step\n",
            "Epoch 23/25\n",
            "45/45 - 0s - loss: 0.2337 - accuracy: 0.9124 - val_loss: 0.2263 - val_accuracy: 0.9194 - lr: 0.0100 - 297ms/epoch - 7ms/step\n",
            "Epoch 24/25\n",
            "\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.2345 - accuracy: 0.9068 - val_loss: 0.2237 - val_accuracy: 0.9260 - lr: 0.0100 - 270ms/epoch - 6ms/step\n",
            "Epoch 25/25\n",
            "45/45 - 0s - loss: 0.2253 - accuracy: 0.9124 - val_loss: 0.2226 - val_accuracy: 0.9227 - lr: 1.0000e-03 - 319ms/epoch - 7ms/step\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2226 - accuracy: 0.9227\n",
            "Model: \"model_277\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_278 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_574 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_184 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_575 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "45/45 - 7s - loss: 0.7054 - accuracy: 0.5332 - val_loss: 0.6081 - val_accuracy: 0.5362 - lr: 0.0100 - 7s/epoch - 149ms/step\n",
            "Epoch 2/20\n",
            "45/45 - 0s - loss: 0.5696 - accuracy: 0.5332 - val_loss: 0.5313 - val_accuracy: 0.5362 - lr: 0.0100 - 372ms/epoch - 8ms/step\n",
            "Epoch 3/20\n",
            "45/45 - 0s - loss: 0.5007 - accuracy: 0.5664 - val_loss: 0.4574 - val_accuracy: 0.6546 - lr: 0.0100 - 369ms/epoch - 8ms/step\n",
            "Epoch 4/20\n",
            "45/45 - 0s - loss: 0.4348 - accuracy: 0.7782 - val_loss: 0.4200 - val_accuracy: 0.8651 - lr: 0.0100 - 352ms/epoch - 8ms/step\n",
            "Epoch 5/20\n",
            "45/45 - 0s - loss: 0.3977 - accuracy: 0.8969 - val_loss: 0.3706 - val_accuracy: 0.8717 - lr: 0.0100 - 360ms/epoch - 8ms/step\n",
            "Epoch 6/20\n",
            "45/45 - 0s - loss: 0.3590 - accuracy: 0.9209 - val_loss: 0.3373 - val_accuracy: 0.9145 - lr: 0.0100 - 385ms/epoch - 9ms/step\n",
            "Epoch 7/20\n",
            "45/45 - 0s - loss: 0.3302 - accuracy: 0.9258 - val_loss: 0.3096 - val_accuracy: 0.9194 - lr: 0.0100 - 374ms/epoch - 8ms/step\n",
            "Epoch 8/20\n",
            "45/45 - 0s - loss: 0.3112 - accuracy: 0.9223 - val_loss: 0.2832 - val_accuracy: 0.9260 - lr: 0.0100 - 400ms/epoch - 9ms/step\n",
            "Epoch 9/20\n",
            "45/45 - 1s - loss: 0.2881 - accuracy: 0.9308 - val_loss: 0.2616 - val_accuracy: 0.9260 - lr: 0.0100 - 506ms/epoch - 11ms/step\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 1s - loss: 0.3210 - accuracy: 0.8997 - val_loss: 0.2737 - val_accuracy: 0.9326 - lr: 0.0100 - 541ms/epoch - 12ms/step\n",
            "Epoch 11/20\n",
            "45/45 - 1s - loss: 0.2764 - accuracy: 0.9273 - val_loss: 0.2699 - val_accuracy: 0.9309 - lr: 1.0000e-03 - 540ms/epoch - 12ms/step\n",
            "Epoch 12/20\n",
            "45/45 - 1s - loss: 0.2722 - accuracy: 0.9294 - val_loss: 0.2671 - val_accuracy: 0.9359 - lr: 1.0000e-03 - 608ms/epoch - 14ms/step\n",
            "Epoch 13/20\n",
            "45/45 - 0s - loss: 0.2688 - accuracy: 0.9308 - val_loss: 0.2644 - val_accuracy: 0.9375 - lr: 1.0000e-03 - 456ms/epoch - 10ms/step\n",
            "Epoch 14/20\n",
            "45/45 - 0s - loss: 0.2657 - accuracy: 0.9329 - val_loss: 0.2621 - val_accuracy: 0.9342 - lr: 1.0000e-03 - 382ms/epoch - 8ms/step\n",
            "Epoch 15/20\n",
            "45/45 - 0s - loss: 0.2629 - accuracy: 0.9343 - val_loss: 0.2599 - val_accuracy: 0.9375 - lr: 1.0000e-03 - 404ms/epoch - 9ms/step\n",
            "Epoch 16/20\n",
            "45/45 - 0s - loss: 0.2603 - accuracy: 0.9357 - val_loss: 0.2579 - val_accuracy: 0.9359 - lr: 1.0000e-03 - 358ms/epoch - 8ms/step\n",
            "Epoch 17/20\n",
            "45/45 - 0s - loss: 0.2577 - accuracy: 0.9371 - val_loss: 0.2559 - val_accuracy: 0.9359 - lr: 1.0000e-03 - 385ms/epoch - 9ms/step\n",
            "Epoch 18/20\n",
            "45/45 - 0s - loss: 0.2554 - accuracy: 0.9393 - val_loss: 0.2538 - val_accuracy: 0.9375 - lr: 1.0000e-03 - 352ms/epoch - 8ms/step\n",
            "Epoch 19/20\n",
            "45/45 - 0s - loss: 0.2533 - accuracy: 0.9386 - val_loss: 0.2524 - val_accuracy: 0.9359 - lr: 1.0000e-03 - 384ms/epoch - 9ms/step\n",
            "Epoch 20/20\n",
            "45/45 - 0s - loss: 0.2511 - accuracy: 0.9421 - val_loss: 0.2503 - val_accuracy: 0.9359 - lr: 1.0000e-03 - 356ms/epoch - 8ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2503 - accuracy: 0.9359\n",
            "Model: \"model_279\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_280 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_579 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_185 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_580 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "45/45 - 7s - loss: 0.7014 - accuracy: 0.5282 - val_loss: 0.6035 - val_accuracy: 0.5477 - lr: 0.0100 - 7s/epoch - 153ms/step\n",
            "Epoch 2/15\n",
            "45/45 - 0s - loss: 0.5774 - accuracy: 0.5282 - val_loss: 0.5324 - val_accuracy: 0.5477 - lr: 0.0100 - 356ms/epoch - 8ms/step\n",
            "Epoch 3/15\n",
            "45/45 - 0s - loss: 0.5147 - accuracy: 0.5282 - val_loss: 0.4813 - val_accuracy: 0.5477 - lr: 0.0100 - 410ms/epoch - 9ms/step\n",
            "Epoch 4/15\n",
            "45/45 - 0s - loss: 0.4693 - accuracy: 0.6822 - val_loss: 0.4458 - val_accuracy: 0.8618 - lr: 0.0100 - 381ms/epoch - 8ms/step\n",
            "Epoch 5/15\n",
            "45/45 - 0s - loss: 0.4378 - accuracy: 0.8856 - val_loss: 0.4224 - val_accuracy: 0.8865 - lr: 0.0100 - 379ms/epoch - 8ms/step\n",
            "Epoch 6/15\n",
            "45/45 - 0s - loss: 0.4148 - accuracy: 0.8792 - val_loss: 0.4050 - val_accuracy: 0.8882 - lr: 0.0100 - 428ms/epoch - 10ms/step\n",
            "Epoch 7/15\n",
            "45/45 - 0s - loss: 0.3964 - accuracy: 0.8842 - val_loss: 0.3889 - val_accuracy: 0.8849 - lr: 0.0100 - 401ms/epoch - 9ms/step\n",
            "Epoch 8/15\n",
            "45/45 - 0s - loss: 0.3891 - accuracy: 0.8778 - val_loss: 0.3733 - val_accuracy: 0.8914 - lr: 0.0100 - 373ms/epoch - 8ms/step\n",
            "Epoch 9/15\n",
            "45/45 - 0s - loss: 0.3731 - accuracy: 0.8821 - val_loss: 0.3560 - val_accuracy: 0.8914 - lr: 0.0100 - 389ms/epoch - 9ms/step\n",
            "Epoch 10/15\n",
            "45/45 - 0s - loss: 0.3565 - accuracy: 0.8856 - val_loss: 0.3366 - val_accuracy: 0.8931 - lr: 0.0100 - 372ms/epoch - 8ms/step\n",
            "Epoch 11/15\n",
            "45/45 - 0s - loss: 0.3396 - accuracy: 0.8997 - val_loss: 0.3169 - val_accuracy: 0.9013 - lr: 0.0100 - 374ms/epoch - 8ms/step\n",
            "Epoch 12/15\n",
            "45/45 - 0s - loss: 0.3332 - accuracy: 0.9032 - val_loss: 0.3166 - val_accuracy: 0.8882 - lr: 0.0100 - 370ms/epoch - 8ms/step\n",
            "Epoch 13/15\n",
            "45/45 - 0s - loss: 0.3139 - accuracy: 0.9075 - val_loss: 0.2963 - val_accuracy: 0.9030 - lr: 0.0100 - 360ms/epoch - 8ms/step\n",
            "Epoch 14/15\n",
            "45/45 - 0s - loss: 0.3019 - accuracy: 0.9160 - val_loss: 0.2759 - val_accuracy: 0.9161 - lr: 0.0100 - 379ms/epoch - 8ms/step\n",
            "Epoch 15/15\n",
            "45/45 - 0s - loss: 0.2898 - accuracy: 0.9273 - val_loss: 0.2709 - val_accuracy: 0.8997 - lr: 0.0100 - 395ms/epoch - 9ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2709 - accuracy: 0.8997\n",
            "  Evaluated 28 individuals\n",
            "  Min 0.5148026347160339\n",
            "  Max 0.9358552694320679\n",
            "  Avg 0.8627193013827006\n",
            "  Std 0.11211808978372187\n",
            "-- Generation 5 --\n",
            "Model: \"model_281\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_282 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_584 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_186 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_585 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "45/45 - 5s - loss: 0.6236 - accuracy: 0.5381 - val_loss: 0.5166 - val_accuracy: 0.5428 - lr: 0.0100 - 5s/epoch - 118ms/step\n",
            "Epoch 2/25\n",
            "45/45 - 0s - loss: 0.4643 - accuracy: 0.7599 - val_loss: 0.4064 - val_accuracy: 0.8832 - lr: 0.0100 - 293ms/epoch - 7ms/step\n",
            "Epoch 3/25\n",
            "45/45 - 0s - loss: 0.3996 - accuracy: 0.8701 - val_loss: 0.3649 - val_accuracy: 0.8816 - lr: 0.0100 - 283ms/epoch - 6ms/step\n",
            "Epoch 4/25\n",
            "45/45 - 0s - loss: 0.3632 - accuracy: 0.8694 - val_loss: 0.3376 - val_accuracy: 0.8849 - lr: 0.0100 - 306ms/epoch - 7ms/step\n",
            "Epoch 5/25\n",
            "45/45 - 0s - loss: 0.3386 - accuracy: 0.8701 - val_loss: 0.3178 - val_accuracy: 0.8849 - lr: 0.0100 - 282ms/epoch - 6ms/step\n",
            "Epoch 6/25\n",
            "45/45 - 0s - loss: 0.3238 - accuracy: 0.8701 - val_loss: 0.3076 - val_accuracy: 0.8849 - lr: 0.0100 - 309ms/epoch - 7ms/step\n",
            "Epoch 7/25\n",
            "45/45 - 0s - loss: 0.3139 - accuracy: 0.8708 - val_loss: 0.2975 - val_accuracy: 0.8849 - lr: 0.0100 - 308ms/epoch - 7ms/step\n",
            "Epoch 8/25\n",
            "45/45 - 0s - loss: 0.3056 - accuracy: 0.8708 - val_loss: 0.2962 - val_accuracy: 0.8849 - lr: 0.0100 - 309ms/epoch - 7ms/step\n",
            "Epoch 9/25\n",
            "45/45 - 0s - loss: 0.2998 - accuracy: 0.8722 - val_loss: 0.2797 - val_accuracy: 0.8865 - lr: 0.0100 - 281ms/epoch - 6ms/step\n",
            "Epoch 10/25\n",
            "45/45 - 0s - loss: 0.2889 - accuracy: 0.8757 - val_loss: 0.2711 - val_accuracy: 0.8882 - lr: 0.0100 - 304ms/epoch - 7ms/step\n",
            "Epoch 11/25\n",
            "45/45 - 0s - loss: 0.2806 - accuracy: 0.8785 - val_loss: 0.2689 - val_accuracy: 0.8931 - lr: 0.0100 - 291ms/epoch - 6ms/step\n",
            "Epoch 12/25\n",
            "45/45 - 0s - loss: 0.2722 - accuracy: 0.8792 - val_loss: 0.2549 - val_accuracy: 0.9013 - lr: 0.0100 - 272ms/epoch - 6ms/step\n",
            "Epoch 13/25\n",
            "45/45 - 0s - loss: 0.2645 - accuracy: 0.8842 - val_loss: 0.2480 - val_accuracy: 0.8914 - lr: 0.0100 - 316ms/epoch - 7ms/step\n",
            "Epoch 14/25\n",
            "45/45 - 0s - loss: 0.2550 - accuracy: 0.8842 - val_loss: 0.2416 - val_accuracy: 0.9062 - lr: 0.0100 - 326ms/epoch - 7ms/step\n",
            "Epoch 15/25\n",
            "\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.2566 - accuracy: 0.8898 - val_loss: 0.2398 - val_accuracy: 0.9128 - lr: 0.0100 - 296ms/epoch - 7ms/step\n",
            "Epoch 16/25\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 0.2670 - accuracy: 0.8941 - val_loss: 0.2358 - val_accuracy: 0.9145 - lr: 1.0000e-03 - 300ms/epoch - 7ms/step\n",
            "Epoch 17/25\n",
            "\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "45/45 - 0s - loss: 0.2649 - accuracy: 0.8962 - val_loss: 0.2355 - val_accuracy: 0.9145 - lr: 1.0000e-04 - 286ms/epoch - 6ms/step\n",
            "Epoch 18/25\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
            "45/45 - 0s - loss: 0.2647 - accuracy: 0.8962 - val_loss: 0.2355 - val_accuracy: 0.9145 - lr: 1.0000e-05 - 334ms/epoch - 7ms/step\n",
            "Epoch 19/25\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "45/45 - 0s - loss: 0.2647 - accuracy: 0.8962 - val_loss: 0.2355 - val_accuracy: 0.9145 - lr: 1.0000e-06 - 304ms/epoch - 7ms/step\n",
            "Epoch 20/25\n",
            "45/45 - 0s - loss: 0.2647 - accuracy: 0.8962 - val_loss: 0.2355 - val_accuracy: 0.9145 - lr: 1.0000e-07 - 286ms/epoch - 6ms/step\n",
            "Epoch 21/25\n",
            "45/45 - 0s - loss: 0.2647 - accuracy: 0.8962 - val_loss: 0.2355 - val_accuracy: 0.9145 - lr: 1.0000e-07 - 292ms/epoch - 6ms/step\n",
            "Epoch 22/25\n",
            "45/45 - 0s - loss: 0.2647 - accuracy: 0.8962 - val_loss: 0.2355 - val_accuracy: 0.9145 - lr: 1.0000e-07 - 326ms/epoch - 7ms/step\n",
            "Epoch 23/25\n",
            "45/45 - 0s - loss: 0.2647 - accuracy: 0.8962 - val_loss: 0.2355 - val_accuracy: 0.9145 - lr: 1.0000e-07 - 302ms/epoch - 7ms/step\n",
            "Epoch 24/25\n",
            "45/45 - 0s - loss: 0.2647 - accuracy: 0.8962 - val_loss: 0.2355 - val_accuracy: 0.9145 - lr: 1.0000e-07 - 301ms/epoch - 7ms/step\n",
            "Epoch 25/25\n",
            "45/45 - 0s - loss: 0.2647 - accuracy: 0.8962 - val_loss: 0.2355 - val_accuracy: 0.9145 - lr: 1.0000e-07 - 304ms/epoch - 7ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2355 - accuracy: 0.9145\n",
            "Model: \"model_283\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_284 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_588 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_187 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_589 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "45/45 - 7s - loss: 0.7789 - accuracy: 0.5290 - val_loss: 0.5893 - val_accuracy: 0.5461 - lr: 0.0100 - 7s/epoch - 149ms/step\n",
            "Epoch 2/25\n",
            "45/45 - 0s - loss: 0.5509 - accuracy: 0.6356 - val_loss: 0.4870 - val_accuracy: 0.8421 - lr: 0.0100 - 393ms/epoch - 9ms/step\n",
            "Epoch 3/25\n",
            "45/45 - 0s - loss: 0.4776 - accuracy: 0.8482 - val_loss: 0.4289 - val_accuracy: 0.8898 - lr: 0.0100 - 388ms/epoch - 9ms/step\n",
            "Epoch 4/25\n",
            "45/45 - 0s - loss: 0.4248 - accuracy: 0.8757 - val_loss: 0.3856 - val_accuracy: 0.8882 - lr: 0.0100 - 385ms/epoch - 9ms/step\n",
            "Epoch 5/25\n",
            "45/45 - 0s - loss: 0.3917 - accuracy: 0.8884 - val_loss: 0.3558 - val_accuracy: 0.9030 - lr: 0.0100 - 418ms/epoch - 9ms/step\n",
            "Epoch 6/25\n",
            "45/45 - 0s - loss: 0.3676 - accuracy: 0.8919 - val_loss: 0.3384 - val_accuracy: 0.8997 - lr: 0.0100 - 386ms/epoch - 9ms/step\n",
            "Epoch 7/25\n",
            "45/45 - 0s - loss: 0.3451 - accuracy: 0.8990 - val_loss: 0.3220 - val_accuracy: 0.8882 - lr: 0.0100 - 399ms/epoch - 9ms/step\n",
            "Epoch 8/25\n",
            "45/45 - 0s - loss: 0.3301 - accuracy: 0.9011 - val_loss: 0.3040 - val_accuracy: 0.8931 - lr: 0.0100 - 394ms/epoch - 9ms/step\n",
            "Epoch 9/25\n",
            "45/45 - 0s - loss: 0.3213 - accuracy: 0.9025 - val_loss: 0.3105 - val_accuracy: 0.9079 - lr: 0.0100 - 387ms/epoch - 9ms/step\n",
            "Epoch 10/25\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.3328 - accuracy: 0.8785 - val_loss: 0.4152 - val_accuracy: 0.8306 - lr: 0.0100 - 394ms/epoch - 9ms/step\n",
            "Epoch 11/25\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 0.3904 - accuracy: 0.8453 - val_loss: 0.3471 - val_accuracy: 0.8668 - lr: 1.0000e-03 - 386ms/epoch - 9ms/step\n",
            "Epoch 12/25\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "45/45 - 0s - loss: 0.3534 - accuracy: 0.8722 - val_loss: 0.3408 - val_accuracy: 0.8668 - lr: 1.0000e-04 - 383ms/epoch - 9ms/step\n",
            "Epoch 13/25\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
            "45/45 - 0s - loss: 0.3507 - accuracy: 0.8750 - val_loss: 0.3402 - val_accuracy: 0.8684 - lr: 1.0000e-05 - 371ms/epoch - 8ms/step\n",
            "Epoch 14/25\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "45/45 - 0s - loss: 0.3504 - accuracy: 0.8750 - val_loss: 0.3402 - val_accuracy: 0.8684 - lr: 1.0000e-06 - 369ms/epoch - 8ms/step\n",
            "Epoch 15/25\n",
            "45/45 - 0s - loss: 0.3504 - accuracy: 0.8750 - val_loss: 0.3402 - val_accuracy: 0.8684 - lr: 1.0000e-07 - 423ms/epoch - 9ms/step\n",
            "Epoch 16/25\n",
            "45/45 - 0s - loss: 0.3504 - accuracy: 0.8750 - val_loss: 0.3402 - val_accuracy: 0.8684 - lr: 1.0000e-07 - 373ms/epoch - 8ms/step\n",
            "Epoch 17/25\n",
            "45/45 - 0s - loss: 0.3504 - accuracy: 0.8750 - val_loss: 0.3402 - val_accuracy: 0.8684 - lr: 1.0000e-07 - 395ms/epoch - 9ms/step\n",
            "Epoch 18/25\n",
            "45/45 - 0s - loss: 0.3504 - accuracy: 0.8750 - val_loss: 0.3402 - val_accuracy: 0.8684 - lr: 1.0000e-07 - 372ms/epoch - 8ms/step\n",
            "Epoch 19/25\n",
            "45/45 - 0s - loss: 0.3504 - accuracy: 0.8750 - val_loss: 0.3402 - val_accuracy: 0.8684 - lr: 1.0000e-07 - 367ms/epoch - 8ms/step\n",
            "Epoch 20/25\n",
            "45/45 - 0s - loss: 0.3504 - accuracy: 0.8750 - val_loss: 0.3402 - val_accuracy: 0.8684 - lr: 1.0000e-07 - 374ms/epoch - 8ms/step\n",
            "Epoch 21/25\n",
            "45/45 - 0s - loss: 0.3504 - accuracy: 0.8750 - val_loss: 0.3402 - val_accuracy: 0.8684 - lr: 1.0000e-07 - 391ms/epoch - 9ms/step\n",
            "Epoch 22/25\n",
            "45/45 - 0s - loss: 0.3504 - accuracy: 0.8750 - val_loss: 0.3402 - val_accuracy: 0.8684 - lr: 1.0000e-07 - 375ms/epoch - 8ms/step\n",
            "Epoch 23/25\n",
            "45/45 - 0s - loss: 0.3504 - accuracy: 0.8750 - val_loss: 0.3401 - val_accuracy: 0.8684 - lr: 1.0000e-07 - 401ms/epoch - 9ms/step\n",
            "Epoch 24/25\n",
            "45/45 - 0s - loss: 0.3504 - accuracy: 0.8750 - val_loss: 0.3401 - val_accuracy: 0.8684 - lr: 1.0000e-07 - 372ms/epoch - 8ms/step\n",
            "Epoch 25/25\n",
            "45/45 - 0s - loss: 0.3504 - accuracy: 0.8750 - val_loss: 0.3401 - val_accuracy: 0.8684 - lr: 1.0000e-07 - 386ms/epoch - 9ms/step\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3401 - accuracy: 0.8684\n",
            "Model: \"model_285\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_286 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_593 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_188 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_594 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "45/45 - 7s - loss: 0.8841 - accuracy: 0.5410 - val_loss: 0.7740 - val_accuracy: 0.5181 - lr: 0.0100 - 7s/epoch - 152ms/step\n",
            "Epoch 2/20\n",
            "45/45 - 0s - loss: 0.7237 - accuracy: 0.5410 - val_loss: 0.7161 - val_accuracy: 0.5181 - lr: 0.0100 - 428ms/epoch - 10ms/step\n",
            "Epoch 3/20\n",
            "45/45 - 0s - loss: 0.6850 - accuracy: 0.5410 - val_loss: 0.6853 - val_accuracy: 0.5181 - lr: 0.0100 - 388ms/epoch - 9ms/step\n",
            "Epoch 4/20\n",
            "45/45 - 0s - loss: 0.6603 - accuracy: 0.5410 - val_loss: 0.6626 - val_accuracy: 0.5181 - lr: 0.0100 - 416ms/epoch - 9ms/step\n",
            "Epoch 5/20\n",
            "45/45 - 0s - loss: 0.6408 - accuracy: 0.5410 - val_loss: 0.6437 - val_accuracy: 0.5181 - lr: 0.0100 - 368ms/epoch - 8ms/step\n",
            "Epoch 6/20\n",
            "45/45 - 0s - loss: 0.6229 - accuracy: 0.5410 - val_loss: 0.6242 - val_accuracy: 0.5181 - lr: 0.0100 - 396ms/epoch - 9ms/step\n",
            "Epoch 7/20\n",
            "45/45 - 0s - loss: 0.6016 - accuracy: 0.5410 - val_loss: 0.5989 - val_accuracy: 0.5181 - lr: 0.0100 - 389ms/epoch - 9ms/step\n",
            "Epoch 8/20\n",
            "45/45 - 0s - loss: 0.5748 - accuracy: 0.5487 - val_loss: 0.5689 - val_accuracy: 0.6151 - lr: 0.0100 - 401ms/epoch - 9ms/step\n",
            "Epoch 9/20\n",
            "45/45 - 0s - loss: 0.5432 - accuracy: 0.6907 - val_loss: 0.5343 - val_accuracy: 0.7747 - lr: 0.0100 - 405ms/epoch - 9ms/step\n",
            "Epoch 10/20\n",
            "45/45 - 0s - loss: 0.4980 - accuracy: 0.7881 - val_loss: 0.4826 - val_accuracy: 0.8026 - lr: 0.0100 - 409ms/epoch - 9ms/step\n",
            "Epoch 11/20\n",
            "45/45 - 0s - loss: 0.4445 - accuracy: 0.8256 - val_loss: 0.4369 - val_accuracy: 0.8487 - lr: 0.0100 - 380ms/epoch - 8ms/step\n",
            "Epoch 12/20\n",
            "45/45 - 0s - loss: 0.4011 - accuracy: 0.8644 - val_loss: 0.3966 - val_accuracy: 0.8980 - lr: 0.0100 - 405ms/epoch - 9ms/step\n",
            "Epoch 13/20\n",
            "45/45 - 0s - loss: 0.3721 - accuracy: 0.9025 - val_loss: 0.3671 - val_accuracy: 0.9161 - lr: 0.0100 - 386ms/epoch - 9ms/step\n",
            "Epoch 14/20\n",
            "45/45 - 0s - loss: 0.3456 - accuracy: 0.9117 - val_loss: 0.3455 - val_accuracy: 0.9194 - lr: 0.0100 - 391ms/epoch - 9ms/step\n",
            "Epoch 15/20\n",
            "45/45 - 0s - loss: 0.3273 - accuracy: 0.9153 - val_loss: 0.3259 - val_accuracy: 0.9260 - lr: 0.0100 - 372ms/epoch - 8ms/step\n",
            "Epoch 16/20\n",
            "45/45 - 0s - loss: 0.3097 - accuracy: 0.9216 - val_loss: 0.3078 - val_accuracy: 0.9309 - lr: 0.0100 - 388ms/epoch - 9ms/step\n",
            "Epoch 17/20\n",
            "45/45 - 0s - loss: 0.2939 - accuracy: 0.9216 - val_loss: 0.2891 - val_accuracy: 0.9276 - lr: 0.0100 - 389ms/epoch - 9ms/step\n",
            "Epoch 18/20\n",
            "45/45 - 0s - loss: 0.2784 - accuracy: 0.9216 - val_loss: 0.2775 - val_accuracy: 0.9145 - lr: 0.0100 - 395ms/epoch - 9ms/step\n",
            "Epoch 19/20\n",
            "45/45 - 0s - loss: 0.2625 - accuracy: 0.9223 - val_loss: 0.2566 - val_accuracy: 0.9145 - lr: 0.0100 - 400ms/epoch - 9ms/step\n",
            "Epoch 20/20\n",
            "45/45 - 0s - loss: 0.2439 - accuracy: 0.9230 - val_loss: 0.2419 - val_accuracy: 0.9276 - lr: 0.0100 - 420ms/epoch - 9ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2419 - accuracy: 0.9276\n",
            "Model: \"model_287\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_288 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_598 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_189 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_599 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "45/45 - 8s - loss: 1.1771 - accuracy: 0.5424 - val_loss: 0.6424 - val_accuracy: 0.5148 - lr: 0.0100 - 8s/epoch - 183ms/step\n",
            "Epoch 2/15\n",
            "45/45 - 0s - loss: 0.5841 - accuracy: 0.5424 - val_loss: 0.5551 - val_accuracy: 0.5148 - lr: 0.0100 - 377ms/epoch - 8ms/step\n",
            "Epoch 3/15\n",
            "45/45 - 0s - loss: 0.5119 - accuracy: 0.5734 - val_loss: 0.4829 - val_accuracy: 0.6990 - lr: 0.0100 - 383ms/epoch - 9ms/step\n",
            "Epoch 4/15\n",
            "45/45 - 0s - loss: 0.4482 - accuracy: 0.7698 - val_loss: 0.4267 - val_accuracy: 0.8257 - lr: 0.0100 - 377ms/epoch - 8ms/step\n",
            "Epoch 5/15\n",
            "45/45 - 0s - loss: 0.4039 - accuracy: 0.8694 - val_loss: 0.3871 - val_accuracy: 0.9079 - lr: 0.0100 - 379ms/epoch - 8ms/step\n",
            "Epoch 6/15\n",
            "45/45 - 0s - loss: 0.3704 - accuracy: 0.8934 - val_loss: 0.3533 - val_accuracy: 0.9375 - lr: 0.0100 - 407ms/epoch - 9ms/step\n",
            "Epoch 7/15\n",
            "45/45 - 0s - loss: 0.3435 - accuracy: 0.9068 - val_loss: 0.3317 - val_accuracy: 0.9227 - lr: 0.0100 - 405ms/epoch - 9ms/step\n",
            "Epoch 8/15\n",
            "45/45 - 0s - loss: 0.3217 - accuracy: 0.9160 - val_loss: 0.3060 - val_accuracy: 0.9391 - lr: 0.0100 - 386ms/epoch - 9ms/step\n",
            "Epoch 9/15\n",
            "45/45 - 0s - loss: 0.3040 - accuracy: 0.9167 - val_loss: 0.2880 - val_accuracy: 0.9391 - lr: 0.0100 - 363ms/epoch - 8ms/step\n",
            "Epoch 10/15\n",
            "45/45 - 0s - loss: 0.2865 - accuracy: 0.9209 - val_loss: 0.2695 - val_accuracy: 0.9605 - lr: 0.0100 - 374ms/epoch - 8ms/step\n",
            "Epoch 11/15\n",
            "45/45 - 0s - loss: 0.2729 - accuracy: 0.9251 - val_loss: 0.2611 - val_accuracy: 0.9556 - lr: 0.0100 - 384ms/epoch - 9ms/step\n",
            "Epoch 12/15\n",
            "45/45 - 0s - loss: 0.2669 - accuracy: 0.9280 - val_loss: 0.2411 - val_accuracy: 0.9572 - lr: 0.0100 - 387ms/epoch - 9ms/step\n",
            "Epoch 13/15\n",
            "45/45 - 0s - loss: 0.2617 - accuracy: 0.9308 - val_loss: 0.2586 - val_accuracy: 0.9490 - lr: 0.0100 - 373ms/epoch - 8ms/step\n",
            "Epoch 14/15\n",
            "45/45 - 0s - loss: 0.2607 - accuracy: 0.9230 - val_loss: 0.2235 - val_accuracy: 0.9539 - lr: 0.0100 - 381ms/epoch - 8ms/step\n",
            "Epoch 15/15\n",
            "\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.3115 - accuracy: 0.8729 - val_loss: 0.2706 - val_accuracy: 0.9211 - lr: 0.0100 - 406ms/epoch - 9ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2706 - accuracy: 0.9211\n",
            "Model: \"model_289\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_290 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_603 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_190 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_604 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "45/45 - 5s - loss: 0.5068 - accuracy: 0.7754 - val_loss: 0.3375 - val_accuracy: 0.8717 - lr: 0.0100 - 5s/epoch - 101ms/step\n",
            "Epoch 2/15\n",
            "45/45 - 0s - loss: 0.3442 - accuracy: 0.8799 - val_loss: 0.3218 - val_accuracy: 0.8750 - lr: 0.0100 - 276ms/epoch - 6ms/step\n",
            "Epoch 3/15\n",
            "45/45 - 0s - loss: 0.3256 - accuracy: 0.8764 - val_loss: 0.3121 - val_accuracy: 0.8750 - lr: 0.0100 - 263ms/epoch - 6ms/step\n",
            "Epoch 4/15\n",
            "45/45 - 0s - loss: 0.3146 - accuracy: 0.8785 - val_loss: 0.2938 - val_accuracy: 0.8799 - lr: 0.0100 - 279ms/epoch - 6ms/step\n",
            "Epoch 5/15\n",
            "45/45 - 0s - loss: 0.3096 - accuracy: 0.8821 - val_loss: 0.2919 - val_accuracy: 0.8766 - lr: 0.0100 - 289ms/epoch - 6ms/step\n",
            "Epoch 6/15\n",
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.3116 - accuracy: 0.8835 - val_loss: 0.2894 - val_accuracy: 0.8816 - lr: 0.0100 - 304ms/epoch - 7ms/step\n",
            "Epoch 7/15\n",
            "45/45 - 0s - loss: 0.3050 - accuracy: 0.8835 - val_loss: 0.2869 - val_accuracy: 0.8816 - lr: 1.0000e-03 - 262ms/epoch - 6ms/step\n",
            "Epoch 8/15\n",
            "45/45 - 0s - loss: 0.3001 - accuracy: 0.8821 - val_loss: 0.3204 - val_accuracy: 0.8766 - lr: 1.0000e-03 - 303ms/epoch - 7ms/step\n",
            "Epoch 9/15\n",
            "\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 0.3257 - accuracy: 0.8764 - val_loss: 0.3172 - val_accuracy: 0.8766 - lr: 1.0000e-03 - 288ms/epoch - 6ms/step\n",
            "Epoch 10/15\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "45/45 - 0s - loss: 0.3240 - accuracy: 0.8757 - val_loss: 0.3169 - val_accuracy: 0.8766 - lr: 1.0000e-04 - 323ms/epoch - 7ms/step\n",
            "Epoch 11/15\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
            "45/45 - 0s - loss: 0.3238 - accuracy: 0.8757 - val_loss: 0.3169 - val_accuracy: 0.8766 - lr: 1.0000e-05 - 308ms/epoch - 7ms/step\n",
            "Epoch 12/15\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "45/45 - 0s - loss: 0.3238 - accuracy: 0.8757 - val_loss: 0.3169 - val_accuracy: 0.8766 - lr: 1.0000e-06 - 279ms/epoch - 6ms/step\n",
            "Epoch 13/15\n",
            "45/45 - 0s - loss: 0.3238 - accuracy: 0.8757 - val_loss: 0.3169 - val_accuracy: 0.8766 - lr: 1.0000e-07 - 267ms/epoch - 6ms/step\n",
            "Epoch 14/15\n",
            "45/45 - 0s - loss: 0.3238 - accuracy: 0.8757 - val_loss: 0.3169 - val_accuracy: 0.8766 - lr: 1.0000e-07 - 268ms/epoch - 6ms/step\n",
            "Epoch 15/15\n",
            "45/45 - 0s - loss: 0.3238 - accuracy: 0.8757 - val_loss: 0.3169 - val_accuracy: 0.8766 - lr: 1.0000e-07 - 274ms/epoch - 6ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3169 - accuracy: 0.8766\n",
            "Model: \"model_291\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_292 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_607 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_191 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_608 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "45/45 - 5s - loss: 0.7167 - accuracy: 0.5106 - val_loss: 0.5660 - val_accuracy: 0.5888 - lr: 0.0100 - 5s/epoch - 104ms/step\n",
            "Epoch 2/20\n",
            "45/45 - 0s - loss: 0.5815 - accuracy: 0.5148 - val_loss: 0.5269 - val_accuracy: 0.6201 - lr: 0.0100 - 285ms/epoch - 6ms/step\n",
            "Epoch 3/20\n",
            "45/45 - 0s - loss: 0.5438 - accuracy: 0.8107 - val_loss: 0.4967 - val_accuracy: 0.8651 - lr: 0.0100 - 281ms/epoch - 6ms/step\n",
            "Epoch 4/20\n",
            "45/45 - 0s - loss: 0.5099 - accuracy: 0.8701 - val_loss: 0.4567 - val_accuracy: 0.8849 - lr: 0.0100 - 276ms/epoch - 6ms/step\n",
            "Epoch 5/20\n",
            "45/45 - 0s - loss: 0.4578 - accuracy: 0.8842 - val_loss: 0.3989 - val_accuracy: 0.8898 - lr: 0.0100 - 304ms/epoch - 7ms/step\n",
            "Epoch 6/20\n",
            "45/45 - 0s - loss: 0.4234 - accuracy: 0.8856 - val_loss: 0.3712 - val_accuracy: 0.8849 - lr: 0.0100 - 308ms/epoch - 7ms/step\n",
            "Epoch 7/20\n",
            "45/45 - 0s - loss: 0.3951 - accuracy: 0.8884 - val_loss: 0.3457 - val_accuracy: 0.8849 - lr: 0.0100 - 295ms/epoch - 7ms/step\n",
            "Epoch 8/20\n",
            "45/45 - 0s - loss: 0.3746 - accuracy: 0.8877 - val_loss: 0.3315 - val_accuracy: 0.8832 - lr: 0.0100 - 278ms/epoch - 6ms/step\n",
            "Epoch 9/20\n",
            "45/45 - 0s - loss: 0.3574 - accuracy: 0.8898 - val_loss: 0.3247 - val_accuracy: 0.8865 - lr: 0.0100 - 274ms/epoch - 6ms/step\n",
            "Epoch 10/20\n",
            "45/45 - 0s - loss: 0.3433 - accuracy: 0.8891 - val_loss: 0.3123 - val_accuracy: 0.8898 - lr: 0.0100 - 272ms/epoch - 6ms/step\n",
            "Epoch 11/20\n",
            "45/45 - 0s - loss: 0.3316 - accuracy: 0.8912 - val_loss: 0.3073 - val_accuracy: 0.8898 - lr: 0.0100 - 279ms/epoch - 6ms/step\n",
            "Epoch 12/20\n",
            "45/45 - 0s - loss: 0.3198 - accuracy: 0.8898 - val_loss: 0.2974 - val_accuracy: 0.8931 - lr: 0.0100 - 296ms/epoch - 7ms/step\n",
            "Epoch 13/20\n",
            "45/45 - 0s - loss: 0.3182 - accuracy: 0.8919 - val_loss: 0.2907 - val_accuracy: 0.8931 - lr: 0.0100 - 273ms/epoch - 6ms/step\n",
            "Epoch 14/20\n",
            "45/45 - 0s - loss: 0.3075 - accuracy: 0.8976 - val_loss: 0.2789 - val_accuracy: 0.8931 - lr: 0.0100 - 284ms/epoch - 6ms/step\n",
            "Epoch 15/20\n",
            "45/45 - 0s - loss: 0.2838 - accuracy: 0.8997 - val_loss: 0.2816 - val_accuracy: 0.8980 - lr: 0.0100 - 280ms/epoch - 6ms/step\n",
            "Epoch 16/20\n",
            "45/45 - 0s - loss: 0.2792 - accuracy: 0.9032 - val_loss: 0.2645 - val_accuracy: 0.8997 - lr: 0.0100 - 294ms/epoch - 7ms/step\n",
            "Epoch 17/20\n",
            "\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.2849 - accuracy: 0.9018 - val_loss: 0.2892 - val_accuracy: 0.8947 - lr: 0.0100 - 274ms/epoch - 6ms/step\n",
            "Epoch 18/20\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 0.2923 - accuracy: 0.8941 - val_loss: 0.2817 - val_accuracy: 0.8914 - lr: 1.0000e-03 - 323ms/epoch - 7ms/step\n",
            "Epoch 19/20\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "45/45 - 0s - loss: 0.2870 - accuracy: 0.8927 - val_loss: 0.2810 - val_accuracy: 0.8914 - lr: 1.0000e-04 - 270ms/epoch - 6ms/step\n",
            "Epoch 20/20\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
            "45/45 - 0s - loss: 0.2865 - accuracy: 0.8927 - val_loss: 0.2809 - val_accuracy: 0.8914 - lr: 1.0000e-05 - 269ms/epoch - 6ms/step\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2809 - accuracy: 0.8914\n",
            "Model: \"model_293\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_294 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_611 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_192 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_612 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "45/45 - 7s - loss: 0.8399 - accuracy: 0.5346 - val_loss: 0.6714 - val_accuracy: 0.5329 - lr: 0.0100 - 7s/epoch - 161ms/step\n",
            "Epoch 2/20\n",
            "45/45 - 0s - loss: 0.6425 - accuracy: 0.5346 - val_loss: 0.5981 - val_accuracy: 0.5329 - lr: 0.0100 - 379ms/epoch - 8ms/step\n",
            "Epoch 3/20\n",
            "45/45 - 0s - loss: 0.5844 - accuracy: 0.5346 - val_loss: 0.5407 - val_accuracy: 0.5329 - lr: 0.0100 - 372ms/epoch - 8ms/step\n",
            "Epoch 4/20\n",
            "45/45 - 0s - loss: 0.5316 - accuracy: 0.6794 - val_loss: 0.4802 - val_accuracy: 0.8257 - lr: 0.0100 - 383ms/epoch - 9ms/step\n",
            "Epoch 5/20\n",
            "45/45 - 0s - loss: 0.4842 - accuracy: 0.8143 - val_loss: 0.4275 - val_accuracy: 0.8717 - lr: 0.0100 - 382ms/epoch - 8ms/step\n",
            "Epoch 6/20\n",
            "45/45 - 0s - loss: 0.4446 - accuracy: 0.8658 - val_loss: 0.3958 - val_accuracy: 0.8947 - lr: 0.0100 - 381ms/epoch - 8ms/step\n",
            "Epoch 7/20\n",
            "45/45 - 0s - loss: 0.4201 - accuracy: 0.8849 - val_loss: 0.3722 - val_accuracy: 0.8997 - lr: 0.0100 - 378ms/epoch - 8ms/step\n",
            "Epoch 8/20\n",
            "45/45 - 0s - loss: 0.4022 - accuracy: 0.8912 - val_loss: 0.3541 - val_accuracy: 0.8980 - lr: 0.0100 - 402ms/epoch - 9ms/step\n",
            "Epoch 9/20\n",
            "45/45 - 0s - loss: 0.3863 - accuracy: 0.8856 - val_loss: 0.3372 - val_accuracy: 0.9112 - lr: 0.0100 - 372ms/epoch - 8ms/step\n",
            "Epoch 10/20\n",
            "45/45 - 0s - loss: 0.3720 - accuracy: 0.8969 - val_loss: 0.3168 - val_accuracy: 0.9095 - lr: 0.0100 - 406ms/epoch - 9ms/step\n",
            "Epoch 11/20\n",
            "45/45 - 0s - loss: 0.3540 - accuracy: 0.8962 - val_loss: 0.3059 - val_accuracy: 0.9095 - lr: 0.0100 - 369ms/epoch - 8ms/step\n",
            "Epoch 12/20\n",
            "45/45 - 0s - loss: 0.3464 - accuracy: 0.8948 - val_loss: 0.3107 - val_accuracy: 0.9079 - lr: 0.0100 - 396ms/epoch - 9ms/step\n",
            "Epoch 13/20\n",
            "45/45 - 0s - loss: 0.3334 - accuracy: 0.8877 - val_loss: 0.3039 - val_accuracy: 0.8799 - lr: 0.0100 - 390ms/epoch - 9ms/step\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.3381 - accuracy: 0.8637 - val_loss: 0.2787 - val_accuracy: 0.9013 - lr: 0.0100 - 377ms/epoch - 8ms/step\n",
            "Epoch 15/20\n",
            "45/45 - 0s - loss: 0.3229 - accuracy: 0.8877 - val_loss: 0.2767 - val_accuracy: 0.9062 - lr: 1.0000e-03 - 399ms/epoch - 9ms/step\n",
            "Epoch 16/20\n",
            "45/45 - 0s - loss: 0.3207 - accuracy: 0.8877 - val_loss: 0.2742 - val_accuracy: 0.9079 - lr: 1.0000e-03 - 370ms/epoch - 8ms/step\n",
            "Epoch 17/20\n",
            "45/45 - 0s - loss: 0.3185 - accuracy: 0.8884 - val_loss: 0.2715 - val_accuracy: 0.9112 - lr: 1.0000e-03 - 381ms/epoch - 8ms/step\n",
            "Epoch 18/20\n",
            "45/45 - 0s - loss: 0.3166 - accuracy: 0.8898 - val_loss: 0.2693 - val_accuracy: 0.9145 - lr: 1.0000e-03 - 376ms/epoch - 8ms/step\n",
            "Epoch 19/20\n",
            "45/45 - 0s - loss: 0.3150 - accuracy: 0.8912 - val_loss: 0.2678 - val_accuracy: 0.9128 - lr: 1.0000e-03 - 399ms/epoch - 9ms/step\n",
            "Epoch 20/20\n",
            "45/45 - 0s - loss: 0.3135 - accuracy: 0.8934 - val_loss: 0.2665 - val_accuracy: 0.9128 - lr: 1.0000e-03 - 359ms/epoch - 8ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2665 - accuracy: 0.9128\n",
            "Model: \"model_295\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_296 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_616 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_193 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_617 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "45/45 - 7s - loss: 0.9341 - accuracy: 0.5318 - val_loss: 0.6720 - val_accuracy: 0.5395 - lr: 0.0100 - 7s/epoch - 146ms/step\n",
            "Epoch 2/25\n",
            "45/45 - 0s - loss: 0.6311 - accuracy: 0.5318 - val_loss: 0.5992 - val_accuracy: 0.5395 - lr: 0.0100 - 367ms/epoch - 8ms/step\n",
            "Epoch 3/25\n",
            "45/45 - 0s - loss: 0.5638 - accuracy: 0.5318 - val_loss: 0.5371 - val_accuracy: 0.5395 - lr: 0.0100 - 375ms/epoch - 8ms/step\n",
            "Epoch 4/25\n",
            "45/45 - 0s - loss: 0.4960 - accuracy: 0.6031 - val_loss: 0.4693 - val_accuracy: 0.7171 - lr: 0.0100 - 379ms/epoch - 8ms/step\n",
            "Epoch 5/25\n",
            "45/45 - 0s - loss: 0.4317 - accuracy: 0.8143 - val_loss: 0.4192 - val_accuracy: 0.8668 - lr: 0.0100 - 397ms/epoch - 9ms/step\n",
            "Epoch 6/25\n",
            "45/45 - 0s - loss: 0.3971 - accuracy: 0.8934 - val_loss: 0.4350 - val_accuracy: 0.8783 - lr: 0.0100 - 387ms/epoch - 9ms/step\n",
            "Epoch 7/25\n",
            "45/45 - 0s - loss: 0.3804 - accuracy: 0.9082 - val_loss: 0.4023 - val_accuracy: 0.8882 - lr: 0.0100 - 399ms/epoch - 9ms/step\n",
            "Epoch 8/25\n",
            "45/45 - 0s - loss: 0.3548 - accuracy: 0.9117 - val_loss: 0.3693 - val_accuracy: 0.9112 - lr: 0.0100 - 374ms/epoch - 8ms/step\n",
            "Epoch 9/25\n",
            "45/45 - 0s - loss: 0.3361 - accuracy: 0.9167 - val_loss: 0.3512 - val_accuracy: 0.9095 - lr: 0.0100 - 366ms/epoch - 8ms/step\n",
            "Epoch 10/25\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.3660 - accuracy: 0.8651 - val_loss: 0.6584 - val_accuracy: 0.4753 - lr: 0.0100 - 403ms/epoch - 9ms/step\n",
            "Epoch 11/25\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 0.6305 - accuracy: 0.4986 - val_loss: 0.6464 - val_accuracy: 0.4819 - lr: 1.0000e-03 - 377ms/epoch - 8ms/step\n",
            "Epoch 12/25\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "45/45 - 0s - loss: 0.6238 - accuracy: 0.5042 - val_loss: 0.6452 - val_accuracy: 0.4836 - lr: 1.0000e-04 - 378ms/epoch - 8ms/step\n",
            "Epoch 13/25\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
            "45/45 - 0s - loss: 0.6232 - accuracy: 0.5042 - val_loss: 0.6451 - val_accuracy: 0.4836 - lr: 1.0000e-05 - 407ms/epoch - 9ms/step\n",
            "Epoch 14/25\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "45/45 - 0s - loss: 0.6231 - accuracy: 0.5042 - val_loss: 0.6451 - val_accuracy: 0.4836 - lr: 1.0000e-06 - 370ms/epoch - 8ms/step\n",
            "Epoch 15/25\n",
            "45/45 - 0s - loss: 0.6231 - accuracy: 0.5042 - val_loss: 0.6451 - val_accuracy: 0.4836 - lr: 1.0000e-07 - 380ms/epoch - 8ms/step\n",
            "Epoch 16/25\n",
            "45/45 - 0s - loss: 0.6231 - accuracy: 0.5042 - val_loss: 0.6451 - val_accuracy: 0.4836 - lr: 1.0000e-07 - 374ms/epoch - 8ms/step\n",
            "Epoch 17/25\n",
            "45/45 - 0s - loss: 0.6231 - accuracy: 0.5042 - val_loss: 0.6451 - val_accuracy: 0.4836 - lr: 1.0000e-07 - 366ms/epoch - 8ms/step\n",
            "Epoch 18/25\n",
            "45/45 - 0s - loss: 0.6231 - accuracy: 0.5042 - val_loss: 0.6451 - val_accuracy: 0.4836 - lr: 1.0000e-07 - 392ms/epoch - 9ms/step\n",
            "Epoch 19/25\n",
            "45/45 - 0s - loss: 0.6231 - accuracy: 0.5042 - val_loss: 0.6451 - val_accuracy: 0.4836 - lr: 1.0000e-07 - 379ms/epoch - 8ms/step\n",
            "Epoch 20/25\n",
            "45/45 - 0s - loss: 0.6231 - accuracy: 0.5042 - val_loss: 0.6451 - val_accuracy: 0.4836 - lr: 1.0000e-07 - 376ms/epoch - 8ms/step\n",
            "Epoch 21/25\n",
            "45/45 - 0s - loss: 0.6231 - accuracy: 0.5042 - val_loss: 0.6451 - val_accuracy: 0.4836 - lr: 1.0000e-07 - 377ms/epoch - 8ms/step\n",
            "Epoch 22/25\n",
            "45/45 - 0s - loss: 0.6231 - accuracy: 0.5042 - val_loss: 0.6451 - val_accuracy: 0.4836 - lr: 1.0000e-07 - 368ms/epoch - 8ms/step\n",
            "Epoch 23/25\n",
            "45/45 - 0s - loss: 0.6231 - accuracy: 0.5042 - val_loss: 0.6451 - val_accuracy: 0.4836 - lr: 1.0000e-07 - 389ms/epoch - 9ms/step\n",
            "Epoch 24/25\n",
            "45/45 - 0s - loss: 0.6231 - accuracy: 0.5042 - val_loss: 0.6451 - val_accuracy: 0.4836 - lr: 1.0000e-07 - 402ms/epoch - 9ms/step\n",
            "Epoch 25/25\n",
            "45/45 - 0s - loss: 0.6231 - accuracy: 0.5042 - val_loss: 0.6451 - val_accuracy: 0.4836 - lr: 1.0000e-07 - 368ms/epoch - 8ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.6451 - accuracy: 0.4836\n",
            "Model: \"model_297\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_298 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_621 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_194 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_622 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "45/45 - 5s - loss: 0.7160 - accuracy: 0.5410 - val_loss: 0.5035 - val_accuracy: 0.5296 - lr: 0.0100 - 5s/epoch - 106ms/step\n",
            "Epoch 2/25\n",
            "45/45 - 0s - loss: 0.4914 - accuracy: 0.6949 - val_loss: 0.4516 - val_accuracy: 0.8569 - lr: 0.0100 - 292ms/epoch - 6ms/step\n",
            "Epoch 3/25\n",
            "45/45 - 0s - loss: 0.4750 - accuracy: 0.8446 - val_loss: 0.5225 - val_accuracy: 0.8865 - lr: 0.0100 - 360ms/epoch - 8ms/step\n",
            "Epoch 4/25\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.4847 - accuracy: 0.8729 - val_loss: 0.4405 - val_accuracy: 0.8914 - lr: 0.0100 - 398ms/epoch - 9ms/step\n",
            "Epoch 5/25\n",
            "45/45 - 0s - loss: 0.4432 - accuracy: 0.8764 - val_loss: 0.4326 - val_accuracy: 0.8898 - lr: 1.0000e-03 - 396ms/epoch - 9ms/step\n",
            "Epoch 6/25\n",
            "45/45 - 0s - loss: 0.4355 - accuracy: 0.8778 - val_loss: 0.4245 - val_accuracy: 0.8898 - lr: 1.0000e-03 - 409ms/epoch - 9ms/step\n",
            "Epoch 7/25\n",
            "45/45 - 0s - loss: 0.4273 - accuracy: 0.8778 - val_loss: 0.4166 - val_accuracy: 0.8882 - lr: 1.0000e-03 - 421ms/epoch - 9ms/step\n",
            "Epoch 8/25\n",
            "45/45 - 0s - loss: 0.4195 - accuracy: 0.8778 - val_loss: 0.4084 - val_accuracy: 0.8898 - lr: 1.0000e-03 - 434ms/epoch - 10ms/step\n",
            "Epoch 9/25\n",
            "45/45 - 0s - loss: 0.4115 - accuracy: 0.8785 - val_loss: 0.4006 - val_accuracy: 0.8882 - lr: 1.0000e-03 - 357ms/epoch - 8ms/step\n",
            "Epoch 10/25\n",
            "45/45 - 0s - loss: 0.4043 - accuracy: 0.8785 - val_loss: 0.3937 - val_accuracy: 0.8865 - lr: 1.0000e-03 - 300ms/epoch - 7ms/step\n",
            "Epoch 11/25\n",
            "45/45 - 0s - loss: 0.3979 - accuracy: 0.8785 - val_loss: 0.3877 - val_accuracy: 0.8882 - lr: 1.0000e-03 - 312ms/epoch - 7ms/step\n",
            "Epoch 12/25\n",
            "45/45 - 0s - loss: 0.3924 - accuracy: 0.8778 - val_loss: 0.3824 - val_accuracy: 0.8882 - lr: 1.0000e-03 - 308ms/epoch - 7ms/step\n",
            "Epoch 13/25\n",
            "45/45 - 0s - loss: 0.3875 - accuracy: 0.8785 - val_loss: 0.3778 - val_accuracy: 0.8882 - lr: 1.0000e-03 - 299ms/epoch - 7ms/step\n",
            "Epoch 14/25\n",
            "45/45 - 0s - loss: 0.3835 - accuracy: 0.8778 - val_loss: 0.3740 - val_accuracy: 0.8882 - lr: 1.0000e-03 - 285ms/epoch - 6ms/step\n",
            "Epoch 15/25\n",
            "45/45 - 0s - loss: 0.3801 - accuracy: 0.8785 - val_loss: 0.3706 - val_accuracy: 0.8882 - lr: 1.0000e-03 - 283ms/epoch - 6ms/step\n",
            "Epoch 16/25\n",
            "45/45 - 0s - loss: 0.3773 - accuracy: 0.8785 - val_loss: 0.3682 - val_accuracy: 0.8882 - lr: 1.0000e-03 - 277ms/epoch - 6ms/step\n",
            "Epoch 17/25\n",
            "45/45 - 0s - loss: 0.3746 - accuracy: 0.8785 - val_loss: 0.3655 - val_accuracy: 0.8882 - lr: 1.0000e-03 - 294ms/epoch - 7ms/step\n",
            "Epoch 18/25\n",
            "45/45 - 0s - loss: 0.3719 - accuracy: 0.8778 - val_loss: 0.3626 - val_accuracy: 0.8882 - lr: 1.0000e-03 - 284ms/epoch - 6ms/step\n",
            "Epoch 19/25\n",
            "45/45 - 0s - loss: 0.3697 - accuracy: 0.8771 - val_loss: 0.3603 - val_accuracy: 0.8882 - lr: 1.0000e-03 - 287ms/epoch - 6ms/step\n",
            "Epoch 20/25\n",
            "45/45 - 0s - loss: 0.3672 - accuracy: 0.8785 - val_loss: 0.3585 - val_accuracy: 0.8882 - lr: 1.0000e-03 - 280ms/epoch - 6ms/step\n",
            "Epoch 21/25\n",
            "45/45 - 0s - loss: 0.3645 - accuracy: 0.8778 - val_loss: 0.3558 - val_accuracy: 0.8882 - lr: 1.0000e-03 - 314ms/epoch - 7ms/step\n",
            "Epoch 22/25\n",
            "45/45 - 0s - loss: 0.3619 - accuracy: 0.8771 - val_loss: 0.3534 - val_accuracy: 0.8882 - lr: 1.0000e-03 - 293ms/epoch - 7ms/step\n",
            "Epoch 23/25\n",
            "45/45 - 0s - loss: 0.3599 - accuracy: 0.8785 - val_loss: 0.3517 - val_accuracy: 0.8898 - lr: 1.0000e-03 - 278ms/epoch - 6ms/step\n",
            "Epoch 24/25\n",
            "45/45 - 0s - loss: 0.3575 - accuracy: 0.8764 - val_loss: 0.3495 - val_accuracy: 0.8898 - lr: 1.0000e-03 - 316ms/epoch - 7ms/step\n",
            "Epoch 25/25\n",
            "45/45 - 0s - loss: 0.3552 - accuracy: 0.8771 - val_loss: 0.3475 - val_accuracy: 0.8882 - lr: 1.0000e-03 - 292ms/epoch - 6ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3475 - accuracy: 0.8882\n",
            "Model: \"model_299\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_300 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_625 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_195 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_626 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "45/45 - 5s - loss: 0.5270 - accuracy: 0.7973 - val_loss: 0.3920 - val_accuracy: 0.8783 - lr: 0.0100 - 5s/epoch - 102ms/step\n",
            "Epoch 2/25\n",
            "45/45 - 0s - loss: 0.3595 - accuracy: 0.8764 - val_loss: 0.4020 - val_accuracy: 0.8734 - lr: 0.0100 - 267ms/epoch - 6ms/step\n",
            "Epoch 3/25\n",
            "45/45 - 0s - loss: 0.3407 - accuracy: 0.8828 - val_loss: 0.3661 - val_accuracy: 0.8783 - lr: 0.0100 - 311ms/epoch - 7ms/step\n",
            "Epoch 4/25\n",
            "45/45 - 0s - loss: 0.3268 - accuracy: 0.8842 - val_loss: 0.3519 - val_accuracy: 0.8799 - lr: 0.0100 - 295ms/epoch - 7ms/step\n",
            "Epoch 5/25\n",
            "45/45 - 0s - loss: 0.3192 - accuracy: 0.8828 - val_loss: 0.3588 - val_accuracy: 0.8816 - lr: 0.0100 - 287ms/epoch - 6ms/step\n",
            "Epoch 6/25\n",
            "45/45 - 0s - loss: 0.3070 - accuracy: 0.8835 - val_loss: 0.3650 - val_accuracy: 0.8766 - lr: 0.0100 - 310ms/epoch - 7ms/step\n",
            "Epoch 7/25\n",
            "45/45 - 0s - loss: 0.3020 - accuracy: 0.8806 - val_loss: 0.3434 - val_accuracy: 0.8832 - lr: 0.0100 - 307ms/epoch - 7ms/step\n",
            "Epoch 8/25\n",
            "45/45 - 0s - loss: 0.2892 - accuracy: 0.8849 - val_loss: 0.3441 - val_accuracy: 0.8750 - lr: 0.0100 - 318ms/epoch - 7ms/step\n",
            "Epoch 9/25\n",
            "45/45 - 0s - loss: 0.2837 - accuracy: 0.8835 - val_loss: 0.3414 - val_accuracy: 0.8849 - lr: 0.0100 - 331ms/epoch - 7ms/step\n",
            "Epoch 10/25\n",
            "45/45 - 0s - loss: 0.2757 - accuracy: 0.8905 - val_loss: 0.2978 - val_accuracy: 0.8882 - lr: 0.0100 - 312ms/epoch - 7ms/step\n",
            "Epoch 11/25\n",
            "45/45 - 0s - loss: 0.2682 - accuracy: 0.8919 - val_loss: 0.2949 - val_accuracy: 0.8947 - lr: 0.0100 - 285ms/epoch - 6ms/step\n",
            "Epoch 12/25\n",
            "45/45 - 0s - loss: 0.2542 - accuracy: 0.8997 - val_loss: 0.2502 - val_accuracy: 0.8964 - lr: 0.0100 - 275ms/epoch - 6ms/step\n",
            "Epoch 13/25\n",
            "45/45 - 0s - loss: 0.2439 - accuracy: 0.9032 - val_loss: 0.2459 - val_accuracy: 0.9046 - lr: 0.0100 - 282ms/epoch - 6ms/step\n",
            "Epoch 14/25\n",
            "45/45 - 0s - loss: 0.2381 - accuracy: 0.9096 - val_loss: 0.2448 - val_accuracy: 0.9046 - lr: 0.0100 - 306ms/epoch - 7ms/step\n",
            "Epoch 15/25\n",
            "45/45 - 0s - loss: 0.2298 - accuracy: 0.9117 - val_loss: 0.2539 - val_accuracy: 0.9161 - lr: 0.0100 - 301ms/epoch - 7ms/step\n",
            "Epoch 16/25\n",
            "45/45 - 0s - loss: 0.2271 - accuracy: 0.9167 - val_loss: 0.2462 - val_accuracy: 0.9194 - lr: 0.0100 - 276ms/epoch - 6ms/step\n",
            "Epoch 17/25\n",
            "45/45 - 0s - loss: 0.2208 - accuracy: 0.9230 - val_loss: 0.2470 - val_accuracy: 0.9145 - lr: 0.0100 - 276ms/epoch - 6ms/step\n",
            "Epoch 18/25\n",
            "45/45 - 0s - loss: 0.2181 - accuracy: 0.9167 - val_loss: 0.2414 - val_accuracy: 0.9128 - lr: 0.0100 - 309ms/epoch - 7ms/step\n",
            "Epoch 19/25\n",
            "45/45 - 0s - loss: 0.2061 - accuracy: 0.9266 - val_loss: 0.2265 - val_accuracy: 0.9243 - lr: 0.0100 - 274ms/epoch - 6ms/step\n",
            "Epoch 20/25\n",
            "45/45 - 0s - loss: 0.2032 - accuracy: 0.9273 - val_loss: 0.2932 - val_accuracy: 0.9062 - lr: 0.0100 - 307ms/epoch - 7ms/step\n",
            "Epoch 21/25\n",
            "45/45 - 0s - loss: 0.2008 - accuracy: 0.9237 - val_loss: 0.2118 - val_accuracy: 0.9227 - lr: 0.0100 - 328ms/epoch - 7ms/step\n",
            "Epoch 22/25\n",
            "45/45 - 0s - loss: 0.1980 - accuracy: 0.9294 - val_loss: 0.2134 - val_accuracy: 0.9408 - lr: 0.0100 - 273ms/epoch - 6ms/step\n",
            "Epoch 23/25\n",
            "45/45 - 0s - loss: 0.1928 - accuracy: 0.9308 - val_loss: 0.2208 - val_accuracy: 0.9309 - lr: 0.0100 - 271ms/epoch - 6ms/step\n",
            "Epoch 24/25\n",
            "\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.2073 - accuracy: 0.9294 - val_loss: 0.2158 - val_accuracy: 0.9276 - lr: 0.0100 - 304ms/epoch - 7ms/step\n",
            "Epoch 25/25\n",
            "45/45 - 0s - loss: 0.1781 - accuracy: 0.9428 - val_loss: 0.1941 - val_accuracy: 0.9342 - lr: 1.0000e-03 - 309ms/epoch - 7ms/step\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1941 - accuracy: 0.9342\n",
            "Model: \"model_301\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_302 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_629 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_196 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_630 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "45/45 - 5s - loss: 0.5796 - accuracy: 0.5833 - val_loss: 0.5015 - val_accuracy: 0.6579 - lr: 0.0100 - 5s/epoch - 107ms/step\n",
            "Epoch 2/15\n",
            "45/45 - 0s - loss: 0.4383 - accuracy: 0.7959 - val_loss: 0.4239 - val_accuracy: 0.8618 - lr: 0.0100 - 305ms/epoch - 7ms/step\n",
            "Epoch 3/15\n",
            "45/45 - 0s - loss: 0.4052 - accuracy: 0.8651 - val_loss: 0.3835 - val_accuracy: 0.8816 - lr: 0.0100 - 271ms/epoch - 6ms/step\n",
            "Epoch 4/15\n",
            "45/45 - 0s - loss: 0.3719 - accuracy: 0.8743 - val_loss: 0.3765 - val_accuracy: 0.8766 - lr: 0.0100 - 283ms/epoch - 6ms/step\n",
            "Epoch 5/15\n",
            "45/45 - 0s - loss: 0.3527 - accuracy: 0.8814 - val_loss: 0.3257 - val_accuracy: 0.8931 - lr: 0.0100 - 283ms/epoch - 6ms/step\n",
            "Epoch 6/15\n",
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.3947 - accuracy: 0.8891 - val_loss: 0.3389 - val_accuracy: 0.8997 - lr: 0.0100 - 291ms/epoch - 6ms/step\n",
            "Epoch 7/15\n",
            "45/45 - 0s - loss: 0.3444 - accuracy: 0.8941 - val_loss: 0.3220 - val_accuracy: 0.8931 - lr: 1.0000e-03 - 275ms/epoch - 6ms/step\n",
            "Epoch 8/15\n",
            "45/45 - 0s - loss: 0.3270 - accuracy: 0.8941 - val_loss: 0.3119 - val_accuracy: 0.8898 - lr: 1.0000e-03 - 306ms/epoch - 7ms/step\n",
            "Epoch 9/15\n",
            "45/45 - 0s - loss: 0.3146 - accuracy: 0.8976 - val_loss: 0.3032 - val_accuracy: 0.8947 - lr: 1.0000e-03 - 290ms/epoch - 6ms/step\n",
            "Epoch 10/15\n",
            "45/45 - 0s - loss: 0.3065 - accuracy: 0.8983 - val_loss: 0.2966 - val_accuracy: 0.8947 - lr: 1.0000e-03 - 271ms/epoch - 6ms/step\n",
            "Epoch 11/15\n",
            "45/45 - 0s - loss: 0.3013 - accuracy: 0.8990 - val_loss: 0.2911 - val_accuracy: 0.8997 - lr: 1.0000e-03 - 283ms/epoch - 6ms/step\n",
            "Epoch 12/15\n",
            "45/45 - 0s - loss: 0.2986 - accuracy: 0.9018 - val_loss: 0.2880 - val_accuracy: 0.8997 - lr: 1.0000e-03 - 288ms/epoch - 6ms/step\n",
            "Epoch 13/15\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 0.3000 - accuracy: 0.9018 - val_loss: 0.2888 - val_accuracy: 0.9030 - lr: 1.0000e-03 - 287ms/epoch - 6ms/step\n",
            "Epoch 14/15\n",
            "45/45 - 0s - loss: 0.2966 - accuracy: 0.9025 - val_loss: 0.2884 - val_accuracy: 0.9030 - lr: 1.0000e-04 - 302ms/epoch - 7ms/step\n",
            "Epoch 15/15\n",
            "45/45 - 0s - loss: 0.2961 - accuracy: 0.9025 - val_loss: 0.2879 - val_accuracy: 0.9030 - lr: 1.0000e-04 - 306ms/epoch - 7ms/step\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2879 - accuracy: 0.9030\n",
            "Model: \"model_303\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_304 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_633 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_197 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_634 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "45/45 - 7s - loss: 0.7845 - accuracy: 0.5480 - val_loss: 0.6532 - val_accuracy: 0.5016 - lr: 0.0100 - 7s/epoch - 164ms/step\n",
            "Epoch 2/25\n",
            "45/45 - 0s - loss: 0.6173 - accuracy: 0.5494 - val_loss: 0.6081 - val_accuracy: 0.5132 - lr: 0.0100 - 385ms/epoch - 9ms/step\n",
            "Epoch 3/25\n",
            "45/45 - 0s - loss: 0.5671 - accuracy: 0.5847 - val_loss: 0.5611 - val_accuracy: 0.6234 - lr: 0.0100 - 368ms/epoch - 8ms/step\n",
            "Epoch 4/25\n",
            "45/45 - 0s - loss: 0.5207 - accuracy: 0.7295 - val_loss: 0.5166 - val_accuracy: 0.7467 - lr: 0.0100 - 368ms/epoch - 8ms/step\n",
            "Epoch 5/25\n",
            "45/45 - 0s - loss: 0.4682 - accuracy: 0.7910 - val_loss: 0.4668 - val_accuracy: 0.8010 - lr: 0.0100 - 390ms/epoch - 9ms/step\n",
            "Epoch 6/25\n",
            "45/45 - 0s - loss: 0.4228 - accuracy: 0.8503 - val_loss: 0.4251 - val_accuracy: 0.8553 - lr: 0.0100 - 419ms/epoch - 9ms/step\n",
            "Epoch 7/25\n",
            "45/45 - 0s - loss: 0.3847 - accuracy: 0.8821 - val_loss: 0.3875 - val_accuracy: 0.8947 - lr: 0.0100 - 389ms/epoch - 9ms/step\n",
            "Epoch 8/25\n",
            "45/45 - 0s - loss: 0.3535 - accuracy: 0.8962 - val_loss: 0.3845 - val_accuracy: 0.8882 - lr: 0.0100 - 394ms/epoch - 9ms/step\n",
            "Epoch 9/25\n",
            "45/45 - 0s - loss: 0.3278 - accuracy: 0.9025 - val_loss: 0.3620 - val_accuracy: 0.9013 - lr: 0.0100 - 371ms/epoch - 8ms/step\n",
            "Epoch 10/25\n",
            "45/45 - 0s - loss: 0.3070 - accuracy: 0.9124 - val_loss: 0.3267 - val_accuracy: 0.9145 - lr: 0.0100 - 365ms/epoch - 8ms/step\n",
            "Epoch 11/25\n",
            "45/45 - 0s - loss: 0.2858 - accuracy: 0.9160 - val_loss: 0.3208 - val_accuracy: 0.9128 - lr: 0.0100 - 389ms/epoch - 9ms/step\n",
            "Epoch 12/25\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.2868 - accuracy: 0.9160 - val_loss: 0.3042 - val_accuracy: 0.9161 - lr: 0.0100 - 372ms/epoch - 8ms/step\n",
            "Epoch 13/25\n",
            "45/45 - 0s - loss: 0.2674 - accuracy: 0.9258 - val_loss: 0.3026 - val_accuracy: 0.9178 - lr: 1.0000e-03 - 387ms/epoch - 9ms/step\n",
            "Epoch 14/25\n",
            "45/45 - 0s - loss: 0.2663 - accuracy: 0.9266 - val_loss: 0.3009 - val_accuracy: 0.9178 - lr: 1.0000e-03 - 389ms/epoch - 9ms/step\n",
            "Epoch 15/25\n",
            "45/45 - 0s - loss: 0.2631 - accuracy: 0.9266 - val_loss: 0.3045 - val_accuracy: 0.9112 - lr: 1.0000e-03 - 358ms/epoch - 8ms/step\n",
            "Epoch 16/25\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 0.2864 - accuracy: 0.9188 - val_loss: 0.2976 - val_accuracy: 0.9161 - lr: 1.0000e-03 - 407ms/epoch - 9ms/step\n",
            "Epoch 17/25\n",
            "\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "45/45 - 0s - loss: 0.2797 - accuracy: 0.9209 - val_loss: 0.2971 - val_accuracy: 0.9178 - lr: 1.0000e-04 - 380ms/epoch - 8ms/step\n",
            "Epoch 18/25\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
            "45/45 - 0s - loss: 0.2792 - accuracy: 0.9223 - val_loss: 0.2971 - val_accuracy: 0.9178 - lr: 1.0000e-05 - 375ms/epoch - 8ms/step\n",
            "Epoch 19/25\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "45/45 - 0s - loss: 0.2791 - accuracy: 0.9223 - val_loss: 0.2971 - val_accuracy: 0.9178 - lr: 1.0000e-06 - 384ms/epoch - 9ms/step\n",
            "Epoch 20/25\n",
            "45/45 - 0s - loss: 0.2791 - accuracy: 0.9223 - val_loss: 0.2971 - val_accuracy: 0.9178 - lr: 1.0000e-07 - 372ms/epoch - 8ms/step\n",
            "Epoch 21/25\n",
            "45/45 - 0s - loss: 0.2791 - accuracy: 0.9223 - val_loss: 0.2971 - val_accuracy: 0.9178 - lr: 1.0000e-07 - 389ms/epoch - 9ms/step\n",
            "Epoch 22/25\n",
            "45/45 - 0s - loss: 0.2791 - accuracy: 0.9223 - val_loss: 0.2971 - val_accuracy: 0.9178 - lr: 1.0000e-07 - 380ms/epoch - 8ms/step\n",
            "Epoch 23/25\n",
            "45/45 - 0s - loss: 0.2791 - accuracy: 0.9223 - val_loss: 0.2971 - val_accuracy: 0.9178 - lr: 1.0000e-07 - 365ms/epoch - 8ms/step\n",
            "Epoch 24/25\n",
            "45/45 - 0s - loss: 0.2791 - accuracy: 0.9223 - val_loss: 0.2971 - val_accuracy: 0.9178 - lr: 1.0000e-07 - 374ms/epoch - 8ms/step\n",
            "Epoch 25/25\n",
            "45/45 - 0s - loss: 0.2791 - accuracy: 0.9223 - val_loss: 0.2971 - val_accuracy: 0.9178 - lr: 1.0000e-07 - 377ms/epoch - 8ms/step\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2971 - accuracy: 0.9178\n",
            "Model: \"model_305\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_306 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_638 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_198 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_639 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "45/45 - 7s - loss: 0.7124 - accuracy: 0.5353 - val_loss: 0.5610 - val_accuracy: 0.5312 - lr: 0.0100 - 7s/epoch - 147ms/step\n",
            "Epoch 2/20\n",
            "45/45 - 0s - loss: 0.5168 - accuracy: 0.5403 - val_loss: 0.4884 - val_accuracy: 0.6036 - lr: 0.0100 - 391ms/epoch - 9ms/step\n",
            "Epoch 3/20\n",
            "45/45 - 0s - loss: 0.4513 - accuracy: 0.7712 - val_loss: 0.4696 - val_accuracy: 0.8684 - lr: 0.0100 - 369ms/epoch - 8ms/step\n",
            "Epoch 4/20\n",
            "45/45 - 0s - loss: 0.4060 - accuracy: 0.8870 - val_loss: 0.4164 - val_accuracy: 0.8849 - lr: 0.0100 - 402ms/epoch - 9ms/step\n",
            "Epoch 5/20\n",
            "45/45 - 0s - loss: 0.3765 - accuracy: 0.8877 - val_loss: 0.4068 - val_accuracy: 0.8947 - lr: 0.0100 - 390ms/epoch - 9ms/step\n",
            "Epoch 6/20\n",
            "45/45 - 0s - loss: 0.3541 - accuracy: 0.8905 - val_loss: 0.3747 - val_accuracy: 0.8947 - lr: 0.0100 - 384ms/epoch - 9ms/step\n",
            "Epoch 7/20\n",
            "45/45 - 0s - loss: 0.3358 - accuracy: 0.8870 - val_loss: 0.3514 - val_accuracy: 0.9013 - lr: 0.0100 - 378ms/epoch - 8ms/step\n",
            "Epoch 8/20\n",
            "45/45 - 0s - loss: 0.3218 - accuracy: 0.8927 - val_loss: 0.3548 - val_accuracy: 0.8997 - lr: 0.0100 - 400ms/epoch - 9ms/step\n",
            "Epoch 9/20\n",
            "45/45 - 0s - loss: 0.3082 - accuracy: 0.8983 - val_loss: 0.3431 - val_accuracy: 0.9030 - lr: 0.0100 - 399ms/epoch - 9ms/step\n",
            "Epoch 10/20\n",
            "45/45 - 0s - loss: 0.2950 - accuracy: 0.9061 - val_loss: 0.3168 - val_accuracy: 0.9062 - lr: 0.0100 - 395ms/epoch - 9ms/step\n",
            "Epoch 11/20\n",
            "45/45 - 0s - loss: 0.2886 - accuracy: 0.9032 - val_loss: 0.3235 - val_accuracy: 0.9161 - lr: 0.0100 - 393ms/epoch - 9ms/step\n",
            "Epoch 12/20\n",
            "45/45 - 0s - loss: 0.2722 - accuracy: 0.9124 - val_loss: 0.3001 - val_accuracy: 0.9112 - lr: 0.0100 - 368ms/epoch - 8ms/step\n",
            "Epoch 13/20\n",
            "45/45 - 0s - loss: 0.2669 - accuracy: 0.9103 - val_loss: 0.3012 - val_accuracy: 0.9178 - lr: 0.0100 - 361ms/epoch - 8ms/step\n",
            "Epoch 14/20\n",
            "45/45 - 0s - loss: 0.2556 - accuracy: 0.9110 - val_loss: 0.2920 - val_accuracy: 0.9243 - lr: 0.0100 - 371ms/epoch - 8ms/step\n",
            "Epoch 15/20\n",
            "45/45 - 0s - loss: 0.2475 - accuracy: 0.9145 - val_loss: 0.2619 - val_accuracy: 0.9326 - lr: 0.0100 - 372ms/epoch - 8ms/step\n",
            "Epoch 16/20\n",
            "45/45 - 0s - loss: 0.2402 - accuracy: 0.9089 - val_loss: 0.2836 - val_accuracy: 0.9276 - lr: 0.0100 - 398ms/epoch - 9ms/step\n",
            "Epoch 17/20\n",
            "45/45 - 0s - loss: 0.2323 - accuracy: 0.9153 - val_loss: 0.2844 - val_accuracy: 0.9112 - lr: 0.0100 - 364ms/epoch - 8ms/step\n",
            "Epoch 18/20\n",
            "45/45 - 0s - loss: 0.2258 - accuracy: 0.9174 - val_loss: 0.2726 - val_accuracy: 0.9243 - lr: 0.0100 - 361ms/epoch - 8ms/step\n",
            "Epoch 19/20\n",
            "45/45 - 0s - loss: 0.2231 - accuracy: 0.9230 - val_loss: 0.2804 - val_accuracy: 0.9128 - lr: 0.0100 - 395ms/epoch - 9ms/step\n",
            "Epoch 20/20\n",
            "45/45 - 0s - loss: 0.2129 - accuracy: 0.9294 - val_loss: 0.2528 - val_accuracy: 0.9326 - lr: 0.0100 - 386ms/epoch - 9ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2528 - accuracy: 0.9326\n",
            "Model: \"model_307\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_308 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_643 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_199 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_644 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "45/45 - 5s - loss: 0.6706 - accuracy: 0.6758 - val_loss: 0.4427 - val_accuracy: 0.7961 - lr: 0.0100 - 5s/epoch - 103ms/step\n",
            "Epoch 2/25\n",
            "45/45 - 0s - loss: 0.3899 - accuracy: 0.8573 - val_loss: 0.3557 - val_accuracy: 0.8799 - lr: 0.0100 - 297ms/epoch - 7ms/step\n",
            "Epoch 3/25\n",
            "45/45 - 0s - loss: 0.3407 - accuracy: 0.8898 - val_loss: 0.3007 - val_accuracy: 0.9079 - lr: 0.0100 - 279ms/epoch - 6ms/step\n",
            "Epoch 4/25\n",
            "45/45 - 0s - loss: 0.3076 - accuracy: 0.8997 - val_loss: 0.2975 - val_accuracy: 0.9030 - lr: 0.0100 - 310ms/epoch - 7ms/step\n",
            "Epoch 5/25\n",
            "45/45 - 0s - loss: 0.2879 - accuracy: 0.9075 - val_loss: 0.2911 - val_accuracy: 0.9095 - lr: 0.0100 - 275ms/epoch - 6ms/step\n",
            "Epoch 6/25\n",
            "45/45 - 0s - loss: 0.2795 - accuracy: 0.9174 - val_loss: 0.2648 - val_accuracy: 0.9260 - lr: 0.0100 - 278ms/epoch - 6ms/step\n",
            "Epoch 7/25\n",
            "45/45 - 0s - loss: 0.2456 - accuracy: 0.9167 - val_loss: 0.2685 - val_accuracy: 0.9309 - lr: 0.0100 - 286ms/epoch - 6ms/step\n",
            "Epoch 8/25\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.2736 - accuracy: 0.8905 - val_loss: 0.3468 - val_accuracy: 0.8914 - lr: 0.0100 - 289ms/epoch - 6ms/step\n",
            "Epoch 9/25\n",
            "\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 0.3152 - accuracy: 0.8877 - val_loss: 0.3444 - val_accuracy: 0.8882 - lr: 1.0000e-03 - 293ms/epoch - 7ms/step\n",
            "Epoch 10/25\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "45/45 - 0s - loss: 0.3129 - accuracy: 0.8863 - val_loss: 0.3440 - val_accuracy: 0.8882 - lr: 1.0000e-04 - 297ms/epoch - 7ms/step\n",
            "Epoch 11/25\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
            "45/45 - 0s - loss: 0.3127 - accuracy: 0.8863 - val_loss: 0.3440 - val_accuracy: 0.8882 - lr: 1.0000e-05 - 282ms/epoch - 6ms/step\n",
            "Epoch 12/25\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "45/45 - 0s - loss: 0.3127 - accuracy: 0.8863 - val_loss: 0.3440 - val_accuracy: 0.8882 - lr: 1.0000e-06 - 301ms/epoch - 7ms/step\n",
            "Epoch 13/25\n",
            "45/45 - 0s - loss: 0.3127 - accuracy: 0.8863 - val_loss: 0.3440 - val_accuracy: 0.8882 - lr: 1.0000e-07 - 279ms/epoch - 6ms/step\n",
            "Epoch 14/25\n",
            "45/45 - 0s - loss: 0.3127 - accuracy: 0.8863 - val_loss: 0.3440 - val_accuracy: 0.8882 - lr: 1.0000e-07 - 333ms/epoch - 7ms/step\n",
            "Epoch 15/25\n",
            "45/45 - 0s - loss: 0.3127 - accuracy: 0.8863 - val_loss: 0.3440 - val_accuracy: 0.8882 - lr: 1.0000e-07 - 278ms/epoch - 6ms/step\n",
            "Epoch 16/25\n",
            "45/45 - 0s - loss: 0.3127 - accuracy: 0.8863 - val_loss: 0.3440 - val_accuracy: 0.8882 - lr: 1.0000e-07 - 278ms/epoch - 6ms/step\n",
            "Epoch 17/25\n",
            "45/45 - 0s - loss: 0.3127 - accuracy: 0.8863 - val_loss: 0.3440 - val_accuracy: 0.8882 - lr: 1.0000e-07 - 410ms/epoch - 9ms/step\n",
            "Epoch 18/25\n",
            "45/45 - 0s - loss: 0.3127 - accuracy: 0.8863 - val_loss: 0.3440 - val_accuracy: 0.8882 - lr: 1.0000e-07 - 401ms/epoch - 9ms/step\n",
            "Epoch 19/25\n",
            "45/45 - 0s - loss: 0.3127 - accuracy: 0.8863 - val_loss: 0.3440 - val_accuracy: 0.8882 - lr: 1.0000e-07 - 394ms/epoch - 9ms/step\n",
            "Epoch 20/25\n",
            "45/45 - 0s - loss: 0.3127 - accuracy: 0.8863 - val_loss: 0.3440 - val_accuracy: 0.8882 - lr: 1.0000e-07 - 403ms/epoch - 9ms/step\n",
            "Epoch 21/25\n",
            "45/45 - 0s - loss: 0.3127 - accuracy: 0.8863 - val_loss: 0.3440 - val_accuracy: 0.8882 - lr: 1.0000e-07 - 419ms/epoch - 9ms/step\n",
            "Epoch 22/25\n",
            "45/45 - 0s - loss: 0.3127 - accuracy: 0.8863 - val_loss: 0.3440 - val_accuracy: 0.8882 - lr: 1.0000e-07 - 378ms/epoch - 8ms/step\n",
            "Epoch 23/25\n",
            "45/45 - 0s - loss: 0.3127 - accuracy: 0.8863 - val_loss: 0.3440 - val_accuracy: 0.8882 - lr: 1.0000e-07 - 290ms/epoch - 6ms/step\n",
            "Epoch 24/25\n",
            "45/45 - 0s - loss: 0.3127 - accuracy: 0.8863 - val_loss: 0.3440 - val_accuracy: 0.8882 - lr: 1.0000e-07 - 320ms/epoch - 7ms/step\n",
            "Epoch 25/25\n",
            "45/45 - 0s - loss: 0.3127 - accuracy: 0.8863 - val_loss: 0.3440 - val_accuracy: 0.8882 - lr: 1.0000e-07 - 272ms/epoch - 6ms/step\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3440 - accuracy: 0.8882\n",
            "Model: \"model_309\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_310 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_647 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_200 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_648 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "45/45 - 5s - loss: 0.5742 - accuracy: 0.7987 - val_loss: 0.4016 - val_accuracy: 0.8635 - lr: 0.0100 - 5s/epoch - 102ms/step\n",
            "Epoch 2/20\n",
            "45/45 - 0s - loss: 0.3888 - accuracy: 0.8898 - val_loss: 0.4096 - val_accuracy: 0.8553 - lr: 0.0100 - 321ms/epoch - 7ms/step\n",
            "Epoch 3/20\n",
            "45/45 - 0s - loss: 0.3792 - accuracy: 0.8658 - val_loss: 0.3481 - val_accuracy: 0.8734 - lr: 0.0100 - 291ms/epoch - 6ms/step\n",
            "Epoch 4/20\n",
            "45/45 - 0s - loss: 0.3264 - accuracy: 0.9004 - val_loss: 0.2951 - val_accuracy: 0.9013 - lr: 0.0100 - 281ms/epoch - 6ms/step\n",
            "Epoch 5/20\n",
            "45/45 - 0s - loss: 0.3013 - accuracy: 0.9075 - val_loss: 0.2744 - val_accuracy: 0.9095 - lr: 0.0100 - 293ms/epoch - 7ms/step\n",
            "Epoch 6/20\n",
            "45/45 - 0s - loss: 0.2842 - accuracy: 0.9138 - val_loss: 0.2596 - val_accuracy: 0.9178 - lr: 0.0100 - 287ms/epoch - 6ms/step\n",
            "Epoch 7/20\n",
            "45/45 - 0s - loss: 0.2681 - accuracy: 0.9209 - val_loss: 0.2778 - val_accuracy: 0.9178 - lr: 0.0100 - 295ms/epoch - 7ms/step\n",
            "Epoch 8/20\n",
            "45/45 - 0s - loss: 0.2543 - accuracy: 0.9237 - val_loss: 0.2407 - val_accuracy: 0.9194 - lr: 0.0100 - 289ms/epoch - 6ms/step\n",
            "Epoch 9/20\n",
            "45/45 - 0s - loss: 0.2413 - accuracy: 0.9266 - val_loss: 0.2350 - val_accuracy: 0.9227 - lr: 0.0100 - 316ms/epoch - 7ms/step\n",
            "Epoch 10/20\n",
            "45/45 - 0s - loss: 0.2361 - accuracy: 0.9287 - val_loss: 0.2504 - val_accuracy: 0.9194 - lr: 0.0100 - 289ms/epoch - 6ms/step\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.2433 - accuracy: 0.9336 - val_loss: 0.2492 - val_accuracy: 0.9128 - lr: 0.0100 - 327ms/epoch - 7ms/step\n",
            "Epoch 12/20\n",
            "45/45 - 0s - loss: 0.2221 - accuracy: 0.9280 - val_loss: 0.2376 - val_accuracy: 0.9227 - lr: 1.0000e-03 - 284ms/epoch - 6ms/step\n",
            "Epoch 13/20\n",
            "45/45 - 0s - loss: 0.2191 - accuracy: 0.9357 - val_loss: 0.2367 - val_accuracy: 0.9276 - lr: 1.0000e-03 - 262ms/epoch - 6ms/step\n",
            "Epoch 14/20\n",
            "45/45 - 0s - loss: 0.2175 - accuracy: 0.9364 - val_loss: 0.2374 - val_accuracy: 0.9260 - lr: 1.0000e-03 - 304ms/epoch - 7ms/step\n",
            "Epoch 15/20\n",
            "45/45 - 0s - loss: 0.2165 - accuracy: 0.9343 - val_loss: 0.2360 - val_accuracy: 0.9260 - lr: 1.0000e-03 - 273ms/epoch - 6ms/step\n",
            "Epoch 16/20\n",
            "45/45 - 0s - loss: 0.2157 - accuracy: 0.9322 - val_loss: 0.2348 - val_accuracy: 0.9293 - lr: 1.0000e-03 - 279ms/epoch - 6ms/step\n",
            "Epoch 17/20\n",
            "45/45 - 0s - loss: 0.2143 - accuracy: 0.9364 - val_loss: 0.2337 - val_accuracy: 0.9276 - lr: 1.0000e-03 - 287ms/epoch - 6ms/step\n",
            "Epoch 18/20\n",
            "45/45 - 0s - loss: 0.2134 - accuracy: 0.9336 - val_loss: 0.2332 - val_accuracy: 0.9276 - lr: 1.0000e-03 - 297ms/epoch - 7ms/step\n",
            "Epoch 19/20\n",
            "45/45 - 0s - loss: 0.2128 - accuracy: 0.9357 - val_loss: 0.2324 - val_accuracy: 0.9276 - lr: 1.0000e-03 - 301ms/epoch - 7ms/step\n",
            "Epoch 20/20\n",
            "45/45 - 0s - loss: 0.2119 - accuracy: 0.9350 - val_loss: 0.2320 - val_accuracy: 0.9326 - lr: 1.0000e-03 - 267ms/epoch - 6ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2320 - accuracy: 0.9326\n",
            "Model: \"model_311\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_312 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_651 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_201 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_652 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "45/45 - 7s - loss: 0.6779 - accuracy: 0.5346 - val_loss: 0.5496 - val_accuracy: 0.5329 - lr: 0.0100 - 7s/epoch - 152ms/step\n",
            "Epoch 2/20\n",
            "45/45 - 0s - loss: 0.4878 - accuracy: 0.6476 - val_loss: 0.4448 - val_accuracy: 0.8257 - lr: 0.0100 - 364ms/epoch - 8ms/step\n",
            "Epoch 3/20\n",
            "45/45 - 0s - loss: 0.3987 - accuracy: 0.8623 - val_loss: 0.3728 - val_accuracy: 0.8914 - lr: 0.0100 - 372ms/epoch - 8ms/step\n",
            "Epoch 4/20\n",
            "45/45 - 0s - loss: 0.3425 - accuracy: 0.9047 - val_loss: 0.3408 - val_accuracy: 0.9178 - lr: 0.0100 - 391ms/epoch - 9ms/step\n",
            "Epoch 5/20\n",
            "45/45 - 0s - loss: 0.3002 - accuracy: 0.9209 - val_loss: 0.3276 - val_accuracy: 0.9161 - lr: 0.0100 - 402ms/epoch - 9ms/step\n",
            "Epoch 6/20\n",
            "45/45 - 0s - loss: 0.2814 - accuracy: 0.9287 - val_loss: 0.3100 - val_accuracy: 0.9211 - lr: 0.0100 - 373ms/epoch - 8ms/step\n",
            "Epoch 7/20\n",
            "45/45 - 0s - loss: 0.2528 - accuracy: 0.9273 - val_loss: 0.2553 - val_accuracy: 0.9342 - lr: 0.0100 - 367ms/epoch - 8ms/step\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.2606 - accuracy: 0.9223 - val_loss: 0.2548 - val_accuracy: 0.9326 - lr: 0.0100 - 373ms/epoch - 8ms/step\n",
            "Epoch 9/20\n",
            "45/45 - 0s - loss: 0.2490 - accuracy: 0.9216 - val_loss: 0.2860 - val_accuracy: 0.8997 - lr: 1.0000e-03 - 373ms/epoch - 8ms/step\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 0.2662 - accuracy: 0.9061 - val_loss: 0.2607 - val_accuracy: 0.9227 - lr: 1.0000e-03 - 382ms/epoch - 8ms/step\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "45/45 - 0s - loss: 0.2535 - accuracy: 0.9174 - val_loss: 0.2594 - val_accuracy: 0.9260 - lr: 1.0000e-04 - 390ms/epoch - 9ms/step\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
            "45/45 - 0s - loss: 0.2526 - accuracy: 0.9188 - val_loss: 0.2592 - val_accuracy: 0.9260 - lr: 1.0000e-05 - 421ms/epoch - 9ms/step\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "45/45 - 0s - loss: 0.2525 - accuracy: 0.9188 - val_loss: 0.2592 - val_accuracy: 0.9260 - lr: 1.0000e-06 - 381ms/epoch - 8ms/step\n",
            "Epoch 14/20\n",
            "45/45 - 0s - loss: 0.2525 - accuracy: 0.9188 - val_loss: 0.2592 - val_accuracy: 0.9260 - lr: 1.0000e-07 - 414ms/epoch - 9ms/step\n",
            "Epoch 15/20\n",
            "45/45 - 0s - loss: 0.2525 - accuracy: 0.9188 - val_loss: 0.2592 - val_accuracy: 0.9260 - lr: 1.0000e-07 - 380ms/epoch - 8ms/step\n",
            "Epoch 16/20\n",
            "45/45 - 0s - loss: 0.2525 - accuracy: 0.9188 - val_loss: 0.2592 - val_accuracy: 0.9260 - lr: 1.0000e-07 - 404ms/epoch - 9ms/step\n",
            "Epoch 17/20\n",
            "45/45 - 0s - loss: 0.2525 - accuracy: 0.9188 - val_loss: 0.2592 - val_accuracy: 0.9260 - lr: 1.0000e-07 - 389ms/epoch - 9ms/step\n",
            "Epoch 18/20\n",
            "45/45 - 0s - loss: 0.2525 - accuracy: 0.9188 - val_loss: 0.2592 - val_accuracy: 0.9260 - lr: 1.0000e-07 - 392ms/epoch - 9ms/step\n",
            "Epoch 19/20\n",
            "45/45 - 0s - loss: 0.2525 - accuracy: 0.9188 - val_loss: 0.2592 - val_accuracy: 0.9260 - lr: 1.0000e-07 - 370ms/epoch - 8ms/step\n",
            "Epoch 20/20\n",
            "45/45 - 0s - loss: 0.2525 - accuracy: 0.9188 - val_loss: 0.2592 - val_accuracy: 0.9260 - lr: 1.0000e-07 - 383ms/epoch - 9ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2592 - accuracy: 0.9260\n",
            "Model: \"model_313\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_314 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_656 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_202 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_657 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "45/45 - 5s - loss: 2.3355 - accuracy: 0.5219 - val_loss: 0.5157 - val_accuracy: 0.5625 - lr: 0.0100 - 5s/epoch - 118ms/step\n",
            "Epoch 2/25\n",
            "45/45 - 0s - loss: 0.5140 - accuracy: 0.6709 - val_loss: 0.4259 - val_accuracy: 0.8832 - lr: 0.0100 - 310ms/epoch - 7ms/step\n",
            "Epoch 3/25\n",
            "45/45 - 0s - loss: 0.4431 - accuracy: 0.8694 - val_loss: 0.7001 - val_accuracy: 0.4441 - lr: 0.0100 - 299ms/epoch - 7ms/step\n",
            "Epoch 4/25\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.6295 - accuracy: 0.6384 - val_loss: 0.5789 - val_accuracy: 0.7336 - lr: 0.0100 - 310ms/epoch - 7ms/step\n",
            "Epoch 5/25\n",
            "\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 0.5656 - accuracy: 0.7782 - val_loss: 0.5701 - val_accuracy: 0.7484 - lr: 1.0000e-03 - 321ms/epoch - 7ms/step\n",
            "Epoch 6/25\n",
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "45/45 - 0s - loss: 0.5607 - accuracy: 0.7832 - val_loss: 0.5691 - val_accuracy: 0.7500 - lr: 1.0000e-04 - 325ms/epoch - 7ms/step\n",
            "Epoch 7/25\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
            "45/45 - 0s - loss: 0.5602 - accuracy: 0.7832 - val_loss: 0.5690 - val_accuracy: 0.7500 - lr: 1.0000e-05 - 337ms/epoch - 7ms/step\n",
            "Epoch 8/25\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "45/45 - 0s - loss: 0.5601 - accuracy: 0.7832 - val_loss: 0.5690 - val_accuracy: 0.7500 - lr: 1.0000e-06 - 287ms/epoch - 6ms/step\n",
            "Epoch 9/25\n",
            "45/45 - 0s - loss: 0.5601 - accuracy: 0.7832 - val_loss: 0.5690 - val_accuracy: 0.7500 - lr: 1.0000e-07 - 325ms/epoch - 7ms/step\n",
            "Epoch 10/25\n",
            "45/45 - 0s - loss: 0.5601 - accuracy: 0.7832 - val_loss: 0.5690 - val_accuracy: 0.7500 - lr: 1.0000e-07 - 324ms/epoch - 7ms/step\n",
            "Epoch 11/25\n",
            "45/45 - 0s - loss: 0.5601 - accuracy: 0.7832 - val_loss: 0.5690 - val_accuracy: 0.7500 - lr: 1.0000e-07 - 310ms/epoch - 7ms/step\n",
            "Epoch 12/25\n",
            "45/45 - 0s - loss: 0.5601 - accuracy: 0.7832 - val_loss: 0.5690 - val_accuracy: 0.7500 - lr: 1.0000e-07 - 288ms/epoch - 6ms/step\n",
            "Epoch 13/25\n",
            "45/45 - 0s - loss: 0.5601 - accuracy: 0.7832 - val_loss: 0.5690 - val_accuracy: 0.7500 - lr: 1.0000e-07 - 295ms/epoch - 7ms/step\n",
            "Epoch 14/25\n",
            "45/45 - 0s - loss: 0.5601 - accuracy: 0.7832 - val_loss: 0.5690 - val_accuracy: 0.7500 - lr: 1.0000e-07 - 300ms/epoch - 7ms/step\n",
            "Epoch 15/25\n",
            "45/45 - 0s - loss: 0.5601 - accuracy: 0.7832 - val_loss: 0.5690 - val_accuracy: 0.7500 - lr: 1.0000e-07 - 343ms/epoch - 8ms/step\n",
            "Epoch 16/25\n",
            "45/45 - 0s - loss: 0.5601 - accuracy: 0.7832 - val_loss: 0.5690 - val_accuracy: 0.7500 - lr: 1.0000e-07 - 318ms/epoch - 7ms/step\n",
            "Epoch 17/25\n",
            "45/45 - 0s - loss: 0.5601 - accuracy: 0.7832 - val_loss: 0.5690 - val_accuracy: 0.7500 - lr: 1.0000e-07 - 333ms/epoch - 7ms/step\n",
            "Epoch 18/25\n",
            "45/45 - 0s - loss: 0.5601 - accuracy: 0.7832 - val_loss: 0.5690 - val_accuracy: 0.7500 - lr: 1.0000e-07 - 338ms/epoch - 8ms/step\n",
            "Epoch 19/25\n",
            "45/45 - 0s - loss: 0.5601 - accuracy: 0.7832 - val_loss: 0.5690 - val_accuracy: 0.7500 - lr: 1.0000e-07 - 300ms/epoch - 7ms/step\n",
            "Epoch 20/25\n",
            "45/45 - 0s - loss: 0.5601 - accuracy: 0.7832 - val_loss: 0.5690 - val_accuracy: 0.7500 - lr: 1.0000e-07 - 294ms/epoch - 7ms/step\n",
            "Epoch 21/25\n",
            "45/45 - 0s - loss: 0.5601 - accuracy: 0.7832 - val_loss: 0.5690 - val_accuracy: 0.7500 - lr: 1.0000e-07 - 315ms/epoch - 7ms/step\n",
            "Epoch 22/25\n",
            "45/45 - 0s - loss: 0.5601 - accuracy: 0.7832 - val_loss: 0.5690 - val_accuracy: 0.7500 - lr: 1.0000e-07 - 329ms/epoch - 7ms/step\n",
            "Epoch 23/25\n",
            "45/45 - 0s - loss: 0.5601 - accuracy: 0.7832 - val_loss: 0.5690 - val_accuracy: 0.7500 - lr: 1.0000e-07 - 315ms/epoch - 7ms/step\n",
            "Epoch 24/25\n",
            "45/45 - 0s - loss: 0.5601 - accuracy: 0.7832 - val_loss: 0.5690 - val_accuracy: 0.7500 - lr: 1.0000e-07 - 321ms/epoch - 7ms/step\n",
            "Epoch 25/25\n",
            "45/45 - 0s - loss: 0.5601 - accuracy: 0.7832 - val_loss: 0.5690 - val_accuracy: 0.7500 - lr: 1.0000e-07 - 291ms/epoch - 6ms/step\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.5690 - accuracy: 0.7500\n",
            "Model: \"model_315\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_316 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_660 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_204 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_661 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "45/45 - 3s - loss: 0.4597 - accuracy: 0.7853 - val_loss: 0.3658 - val_accuracy: 0.8734 - lr: 0.0100 - 3s/epoch - 59ms/step\n",
            "Epoch 2/20\n",
            "45/45 - 0s - loss: 0.3774 - accuracy: 0.8757 - val_loss: 0.3424 - val_accuracy: 0.8717 - lr: 0.0100 - 205ms/epoch - 5ms/step\n",
            "Epoch 3/20\n",
            "45/45 - 0s - loss: 0.3618 - accuracy: 0.8750 - val_loss: 0.3351 - val_accuracy: 0.8717 - lr: 0.0100 - 194ms/epoch - 4ms/step\n",
            "Epoch 4/20\n",
            "45/45 - 0s - loss: 0.3546 - accuracy: 0.8750 - val_loss: 0.3246 - val_accuracy: 0.8717 - lr: 0.0100 - 237ms/epoch - 5ms/step\n",
            "Epoch 5/20\n",
            "45/45 - 0s - loss: 0.3484 - accuracy: 0.8757 - val_loss: 0.3201 - val_accuracy: 0.8717 - lr: 0.0100 - 246ms/epoch - 5ms/step\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.3515 - accuracy: 0.8757 - val_loss: 0.3153 - val_accuracy: 0.8717 - lr: 0.0100 - 196ms/epoch - 4ms/step\n",
            "Epoch 7/20\n",
            "45/45 - 0s - loss: 0.3407 - accuracy: 0.8757 - val_loss: 0.3153 - val_accuracy: 0.8717 - lr: 1.0000e-03 - 231ms/epoch - 5ms/step\n",
            "Epoch 8/20\n",
            "45/45 - 0s - loss: 0.3398 - accuracy: 0.8757 - val_loss: 0.3151 - val_accuracy: 0.8717 - lr: 1.0000e-03 - 225ms/epoch - 5ms/step\n",
            "Epoch 9/20\n",
            "45/45 - 0s - loss: 0.3396 - accuracy: 0.8757 - val_loss: 0.3149 - val_accuracy: 0.8717 - lr: 1.0000e-03 - 188ms/epoch - 4ms/step\n",
            "Epoch 10/20\n",
            "45/45 - 0s - loss: 0.3390 - accuracy: 0.8757 - val_loss: 0.3146 - val_accuracy: 0.8717 - lr: 1.0000e-03 - 201ms/epoch - 4ms/step\n",
            "Epoch 11/20\n",
            "45/45 - 0s - loss: 0.3386 - accuracy: 0.8757 - val_loss: 0.3144 - val_accuracy: 0.8717 - lr: 1.0000e-03 - 198ms/epoch - 4ms/step\n",
            "Epoch 12/20\n",
            "45/45 - 0s - loss: 0.3380 - accuracy: 0.8757 - val_loss: 0.3139 - val_accuracy: 0.8717 - lr: 1.0000e-03 - 229ms/epoch - 5ms/step\n",
            "Epoch 13/20\n",
            "45/45 - 0s - loss: 0.3378 - accuracy: 0.8757 - val_loss: 0.3137 - val_accuracy: 0.8717 - lr: 1.0000e-03 - 186ms/epoch - 4ms/step\n",
            "Epoch 14/20\n",
            "45/45 - 0s - loss: 0.3372 - accuracy: 0.8757 - val_loss: 0.3132 - val_accuracy: 0.8717 - lr: 1.0000e-03 - 180ms/epoch - 4ms/step\n",
            "Epoch 15/20\n",
            "45/45 - 0s - loss: 0.3366 - accuracy: 0.8757 - val_loss: 0.3127 - val_accuracy: 0.8717 - lr: 1.0000e-03 - 226ms/epoch - 5ms/step\n",
            "Epoch 16/20\n",
            "45/45 - 0s - loss: 0.3362 - accuracy: 0.8757 - val_loss: 0.3123 - val_accuracy: 0.8717 - lr: 1.0000e-03 - 226ms/epoch - 5ms/step\n",
            "Epoch 17/20\n",
            "45/45 - 0s - loss: 0.3358 - accuracy: 0.8757 - val_loss: 0.3120 - val_accuracy: 0.8717 - lr: 1.0000e-03 - 181ms/epoch - 4ms/step\n",
            "Epoch 18/20\n",
            "45/45 - 0s - loss: 0.3351 - accuracy: 0.8757 - val_loss: 0.3118 - val_accuracy: 0.8717 - lr: 1.0000e-03 - 223ms/epoch - 5ms/step\n",
            "Epoch 19/20\n",
            "45/45 - 0s - loss: 0.3347 - accuracy: 0.8757 - val_loss: 0.3111 - val_accuracy: 0.8717 - lr: 1.0000e-03 - 206ms/epoch - 5ms/step\n",
            "Epoch 20/20\n",
            "45/45 - 0s - loss: 0.3341 - accuracy: 0.8757 - val_loss: 0.3105 - val_accuracy: 0.8717 - lr: 1.0000e-03 - 226ms/epoch - 5ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3105 - accuracy: 0.8717\n",
            "Model: \"model_317\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_318 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_663 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_206 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_664 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "45/45 - 5s - loss: 0.9240 - accuracy: 0.5325 - val_loss: 0.6499 - val_accuracy: 0.5378 - lr: 0.0100 - 5s/epoch - 120ms/step\n",
            "Epoch 2/20\n",
            "45/45 - 0s - loss: 0.5979 - accuracy: 0.5325 - val_loss: 0.5303 - val_accuracy: 0.5378 - lr: 0.0100 - 279ms/epoch - 6ms/step\n",
            "Epoch 3/20\n",
            "45/45 - 0s - loss: 0.5260 - accuracy: 0.5346 - val_loss: 0.4929 - val_accuracy: 0.5592 - lr: 0.0100 - 306ms/epoch - 7ms/step\n",
            "Epoch 4/20\n",
            "45/45 - 0s - loss: 0.4726 - accuracy: 0.7578 - val_loss: 0.4422 - val_accuracy: 0.8553 - lr: 0.0100 - 281ms/epoch - 6ms/step\n",
            "Epoch 5/20\n",
            "45/45 - 0s - loss: 0.4564 - accuracy: 0.8785 - val_loss: 0.4368 - val_accuracy: 0.8586 - lr: 0.0100 - 314ms/epoch - 7ms/step\n",
            "Epoch 6/20\n",
            "45/45 - 0s - loss: 0.4357 - accuracy: 0.8785 - val_loss: 0.4190 - val_accuracy: 0.8684 - lr: 0.0100 - 287ms/epoch - 6ms/step\n",
            "Epoch 7/20\n",
            "45/45 - 0s - loss: 0.4203 - accuracy: 0.8842 - val_loss: 0.4053 - val_accuracy: 0.8734 - lr: 0.0100 - 322ms/epoch - 7ms/step\n",
            "Epoch 8/20\n",
            "45/45 - 0s - loss: 0.4061 - accuracy: 0.8849 - val_loss: 0.3929 - val_accuracy: 0.8766 - lr: 0.0100 - 278ms/epoch - 6ms/step\n",
            "Epoch 9/20\n",
            "45/45 - 0s - loss: 0.3944 - accuracy: 0.8856 - val_loss: 0.3824 - val_accuracy: 0.8750 - lr: 0.0100 - 286ms/epoch - 6ms/step\n",
            "Epoch 10/20\n",
            "45/45 - 0s - loss: 0.3846 - accuracy: 0.8863 - val_loss: 0.3738 - val_accuracy: 0.8750 - lr: 0.0100 - 282ms/epoch - 6ms/step\n",
            "Epoch 11/20\n",
            "45/45 - 0s - loss: 0.3759 - accuracy: 0.8891 - val_loss: 0.3690 - val_accuracy: 0.8717 - lr: 0.0100 - 314ms/epoch - 7ms/step\n",
            "Epoch 12/20\n",
            "45/45 - 0s - loss: 0.3699 - accuracy: 0.8870 - val_loss: 0.3589 - val_accuracy: 0.8717 - lr: 0.0100 - 309ms/epoch - 7ms/step\n",
            "Epoch 13/20\n",
            "45/45 - 0s - loss: 0.3627 - accuracy: 0.8863 - val_loss: 0.3530 - val_accuracy: 0.8734 - lr: 0.0100 - 319ms/epoch - 7ms/step\n",
            "Epoch 14/20\n",
            "45/45 - 0s - loss: 0.3572 - accuracy: 0.8863 - val_loss: 0.3461 - val_accuracy: 0.8734 - lr: 0.0100 - 290ms/epoch - 6ms/step\n",
            "Epoch 15/20\n",
            "45/45 - 0s - loss: 0.3507 - accuracy: 0.8870 - val_loss: 0.3420 - val_accuracy: 0.8734 - lr: 0.0100 - 282ms/epoch - 6ms/step\n",
            "Epoch 16/20\n",
            "45/45 - 0s - loss: 0.3461 - accuracy: 0.8870 - val_loss: 0.3390 - val_accuracy: 0.8734 - lr: 0.0100 - 319ms/epoch - 7ms/step\n",
            "Epoch 17/20\n",
            "45/45 - 0s - loss: 0.3403 - accuracy: 0.8842 - val_loss: 0.3314 - val_accuracy: 0.8750 - lr: 0.0100 - 286ms/epoch - 6ms/step\n",
            "Epoch 18/20\n",
            "45/45 - 0s - loss: 0.3333 - accuracy: 0.8877 - val_loss: 0.3269 - val_accuracy: 0.8750 - lr: 0.0100 - 272ms/epoch - 6ms/step\n",
            "Epoch 19/20\n",
            "45/45 - 0s - loss: 0.3288 - accuracy: 0.8884 - val_loss: 0.3202 - val_accuracy: 0.8783 - lr: 0.0100 - 305ms/epoch - 7ms/step\n",
            "Epoch 20/20\n",
            "45/45 - 0s - loss: 0.3250 - accuracy: 0.8891 - val_loss: 0.3180 - val_accuracy: 0.8816 - lr: 0.0100 - 331ms/epoch - 7ms/step\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3180 - accuracy: 0.8816\n",
            "Model: \"model_319\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_320 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_667 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_207 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_668 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "45/45 - 5s - loss: 0.7501 - accuracy: 0.5339 - val_loss: 0.5279 - val_accuracy: 0.5428 - lr: 0.0100 - 5s/epoch - 106ms/step\n",
            "Epoch 2/25\n",
            "45/45 - 0s - loss: 0.5005 - accuracy: 0.6427 - val_loss: 0.4387 - val_accuracy: 0.8405 - lr: 0.0100 - 298ms/epoch - 7ms/step\n",
            "Epoch 3/25\n",
            "45/45 - 0s - loss: 0.4324 - accuracy: 0.8573 - val_loss: 0.3902 - val_accuracy: 0.8914 - lr: 0.0100 - 321ms/epoch - 7ms/step\n",
            "Epoch 4/25\n",
            "45/45 - 0s - loss: 0.3931 - accuracy: 0.8814 - val_loss: 0.4006 - val_accuracy: 0.8947 - lr: 0.0100 - 309ms/epoch - 7ms/step\n",
            "Epoch 5/25\n",
            "45/45 - 0s - loss: 0.3782 - accuracy: 0.8806 - val_loss: 0.3389 - val_accuracy: 0.8947 - lr: 0.0100 - 297ms/epoch - 7ms/step\n",
            "Epoch 6/25\n",
            "45/45 - 0s - loss: 0.3573 - accuracy: 0.8799 - val_loss: 0.3648 - val_accuracy: 0.8816 - lr: 0.0100 - 308ms/epoch - 7ms/step\n",
            "Epoch 7/25\n",
            "45/45 - 0s - loss: 0.3570 - accuracy: 0.8785 - val_loss: 0.3377 - val_accuracy: 0.8865 - lr: 0.0100 - 324ms/epoch - 7ms/step\n",
            "Epoch 8/25\n",
            "45/45 - 0s - loss: 0.3438 - accuracy: 0.8835 - val_loss: 0.3665 - val_accuracy: 0.8931 - lr: 0.0100 - 279ms/epoch - 6ms/step\n",
            "Epoch 9/25\n",
            "45/45 - 0s - loss: 0.3341 - accuracy: 0.8828 - val_loss: 0.3583 - val_accuracy: 0.8931 - lr: 0.0100 - 317ms/epoch - 7ms/step\n",
            "Epoch 10/25\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.3362 - accuracy: 0.8835 - val_loss: 0.3484 - val_accuracy: 0.8997 - lr: 0.0100 - 304ms/epoch - 7ms/step\n",
            "Epoch 11/25\n",
            "45/45 - 0s - loss: 0.3289 - accuracy: 0.8891 - val_loss: 0.3487 - val_accuracy: 0.8964 - lr: 1.0000e-03 - 339ms/epoch - 8ms/step\n",
            "Epoch 12/25\n",
            "45/45 - 0s - loss: 0.3279 - accuracy: 0.8891 - val_loss: 0.3484 - val_accuracy: 0.8964 - lr: 1.0000e-03 - 312ms/epoch - 7ms/step\n",
            "Epoch 13/25\n",
            "45/45 - 0s - loss: 0.3271 - accuracy: 0.8905 - val_loss: 0.3478 - val_accuracy: 0.8964 - lr: 1.0000e-03 - 285ms/epoch - 6ms/step\n",
            "Epoch 14/25\n",
            "45/45 - 0s - loss: 0.3262 - accuracy: 0.8919 - val_loss: 0.3471 - val_accuracy: 0.8964 - lr: 1.0000e-03 - 311ms/epoch - 7ms/step\n",
            "Epoch 15/25\n",
            "45/45 - 0s - loss: 0.3255 - accuracy: 0.8941 - val_loss: 0.3462 - val_accuracy: 0.8980 - lr: 1.0000e-03 - 275ms/epoch - 6ms/step\n",
            "Epoch 16/25\n",
            "45/45 - 0s - loss: 0.3245 - accuracy: 0.8955 - val_loss: 0.3455 - val_accuracy: 0.8997 - lr: 1.0000e-03 - 301ms/epoch - 7ms/step\n",
            "Epoch 17/25\n",
            "45/45 - 0s - loss: 0.3237 - accuracy: 0.8955 - val_loss: 0.3452 - val_accuracy: 0.8980 - lr: 1.0000e-03 - 282ms/epoch - 6ms/step\n",
            "Epoch 18/25\n",
            "45/45 - 0s - loss: 0.3229 - accuracy: 0.8955 - val_loss: 0.3438 - val_accuracy: 0.8997 - lr: 1.0000e-03 - 278ms/epoch - 6ms/step\n",
            "Epoch 19/25\n",
            "45/45 - 0s - loss: 0.3224 - accuracy: 0.8969 - val_loss: 0.3435 - val_accuracy: 0.9013 - lr: 1.0000e-03 - 307ms/epoch - 7ms/step\n",
            "Epoch 20/25\n",
            "45/45 - 0s - loss: 0.3213 - accuracy: 0.8983 - val_loss: 0.3426 - val_accuracy: 0.9013 - lr: 1.0000e-03 - 297ms/epoch - 7ms/step\n",
            "Epoch 21/25\n",
            "45/45 - 0s - loss: 0.3208 - accuracy: 0.9004 - val_loss: 0.3421 - val_accuracy: 0.9013 - lr: 1.0000e-03 - 265ms/epoch - 6ms/step\n",
            "Epoch 22/25\n",
            "45/45 - 0s - loss: 0.3200 - accuracy: 0.9018 - val_loss: 0.3419 - val_accuracy: 0.9013 - lr: 1.0000e-03 - 297ms/epoch - 7ms/step\n",
            "Epoch 23/25\n",
            "45/45 - 0s - loss: 0.3193 - accuracy: 0.9032 - val_loss: 0.3413 - val_accuracy: 0.9046 - lr: 1.0000e-03 - 281ms/epoch - 6ms/step\n",
            "Epoch 24/25\n",
            "45/45 - 0s - loss: 0.3186 - accuracy: 0.9025 - val_loss: 0.3403 - val_accuracy: 0.9046 - lr: 1.0000e-03 - 296ms/epoch - 7ms/step\n",
            "Epoch 25/25\n",
            "45/45 - 0s - loss: 0.3178 - accuracy: 0.9040 - val_loss: 0.3396 - val_accuracy: 0.9046 - lr: 1.0000e-03 - 272ms/epoch - 6ms/step\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3396 - accuracy: 0.9046\n",
            "Model: \"model_321\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_322 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_671 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_208 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_672 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "45/45 - 6s - loss: 7.1412 - accuracy: 0.5360 - val_loss: 7.1436 - val_accuracy: 0.5296 - lr: 0.0100 - 6s/epoch - 124ms/step\n",
            "Epoch 2/20\n",
            "45/45 - 0s - loss: 1.4860 - accuracy: 0.6144 - val_loss: 0.4939 - val_accuracy: 0.7418 - lr: 0.0100 - 310ms/epoch - 7ms/step\n",
            "Epoch 3/20\n",
            "45/45 - 0s - loss: 0.4055 - accuracy: 0.8362 - val_loss: 0.5072 - val_accuracy: 0.8322 - lr: 0.0100 - 310ms/epoch - 7ms/step\n",
            "Epoch 4/20\n",
            "45/45 - 0s - loss: 0.3714 - accuracy: 0.8870 - val_loss: 0.3873 - val_accuracy: 0.8865 - lr: 0.0100 - 287ms/epoch - 6ms/step\n",
            "Epoch 5/20\n",
            "45/45 - 0s - loss: 0.3274 - accuracy: 0.9047 - val_loss: 0.3767 - val_accuracy: 0.8931 - lr: 0.0100 - 279ms/epoch - 6ms/step\n",
            "Epoch 6/20\n",
            "45/45 - 0s - loss: 0.3054 - accuracy: 0.9089 - val_loss: 0.3694 - val_accuracy: 0.8980 - lr: 0.0100 - 304ms/epoch - 7ms/step\n",
            "Epoch 7/20\n",
            "45/45 - 0s - loss: 0.2852 - accuracy: 0.9138 - val_loss: 0.3505 - val_accuracy: 0.9013 - lr: 0.0100 - 283ms/epoch - 6ms/step\n",
            "Epoch 8/20\n",
            "45/45 - 0s - loss: 0.2623 - accuracy: 0.9167 - val_loss: 0.3132 - val_accuracy: 0.9013 - lr: 0.0100 - 278ms/epoch - 6ms/step\n",
            "Epoch 9/20\n",
            "45/45 - 0s - loss: 0.2484 - accuracy: 0.9202 - val_loss: 0.3609 - val_accuracy: 0.8947 - lr: 0.0100 - 279ms/epoch - 6ms/step\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.2596 - accuracy: 0.9216 - val_loss: 0.3161 - val_accuracy: 0.8964 - lr: 0.0100 - 289ms/epoch - 6ms/step\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 0.2496 - accuracy: 0.9237 - val_loss: 0.3153 - val_accuracy: 0.8964 - lr: 1.0000e-03 - 289ms/epoch - 6ms/step\n",
            "Epoch 12/20\n",
            "45/45 - 0s - loss: 0.2471 - accuracy: 0.9223 - val_loss: 0.3152 - val_accuracy: 0.8964 - lr: 1.0000e-04 - 305ms/epoch - 7ms/step\n",
            "Epoch 13/20\n",
            "45/45 - 0s - loss: 0.2469 - accuracy: 0.9223 - val_loss: 0.3151 - val_accuracy: 0.8964 - lr: 1.0000e-04 - 307ms/epoch - 7ms/step\n",
            "Epoch 14/20\n",
            "45/45 - 0s - loss: 0.2467 - accuracy: 0.9223 - val_loss: 0.3150 - val_accuracy: 0.8964 - lr: 1.0000e-04 - 303ms/epoch - 7ms/step\n",
            "Epoch 15/20\n",
            "45/45 - 0s - loss: 0.2465 - accuracy: 0.9223 - val_loss: 0.3148 - val_accuracy: 0.8964 - lr: 1.0000e-04 - 291ms/epoch - 6ms/step\n",
            "Epoch 16/20\n",
            "45/45 - 0s - loss: 0.2463 - accuracy: 0.9223 - val_loss: 0.3147 - val_accuracy: 0.8947 - lr: 1.0000e-04 - 272ms/epoch - 6ms/step\n",
            "Epoch 17/20\n",
            "45/45 - 0s - loss: 0.2461 - accuracy: 0.9223 - val_loss: 0.3146 - val_accuracy: 0.8947 - lr: 1.0000e-04 - 300ms/epoch - 7ms/step\n",
            "Epoch 18/20\n",
            "45/45 - 0s - loss: 0.2459 - accuracy: 0.9223 - val_loss: 0.3145 - val_accuracy: 0.8947 - lr: 1.0000e-04 - 312ms/epoch - 7ms/step\n",
            "Epoch 19/20\n",
            "45/45 - 0s - loss: 0.2457 - accuracy: 0.9223 - val_loss: 0.3144 - val_accuracy: 0.8947 - lr: 1.0000e-04 - 279ms/epoch - 6ms/step\n",
            "Epoch 20/20\n",
            "45/45 - 0s - loss: 0.2456 - accuracy: 0.9223 - val_loss: 0.3142 - val_accuracy: 0.8947 - lr: 1.0000e-04 - 282ms/epoch - 6ms/step\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3142 - accuracy: 0.8947\n",
            "Model: \"model_323\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_324 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_675 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_209 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_676 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "45/45 - 5s - loss: 0.4763 - accuracy: 0.8411 - val_loss: 0.3644 - val_accuracy: 0.9030 - lr: 0.0100 - 5s/epoch - 105ms/step\n",
            "Epoch 2/25\n",
            "45/45 - 0s - loss: 0.3738 - accuracy: 0.8785 - val_loss: 0.2973 - val_accuracy: 0.9062 - lr: 0.0100 - 319ms/epoch - 7ms/step\n",
            "Epoch 3/25\n",
            "45/45 - 0s - loss: 0.3536 - accuracy: 0.8757 - val_loss: 0.3513 - val_accuracy: 0.8618 - lr: 0.0100 - 304ms/epoch - 7ms/step\n",
            "Epoch 4/25\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.3548 - accuracy: 0.8821 - val_loss: 0.2882 - val_accuracy: 0.8898 - lr: 0.0100 - 301ms/epoch - 7ms/step\n",
            "Epoch 5/25\n",
            "45/45 - 0s - loss: 0.3281 - accuracy: 0.8898 - val_loss: 0.2861 - val_accuracy: 0.8898 - lr: 1.0000e-03 - 319ms/epoch - 7ms/step\n",
            "Epoch 6/25\n",
            "45/45 - 0s - loss: 0.3230 - accuracy: 0.8905 - val_loss: 0.2826 - val_accuracy: 0.8898 - lr: 1.0000e-03 - 303ms/epoch - 7ms/step\n",
            "Epoch 7/25\n",
            "45/45 - 0s - loss: 0.3196 - accuracy: 0.8891 - val_loss: 0.2809 - val_accuracy: 0.8931 - lr: 1.0000e-03 - 328ms/epoch - 7ms/step\n",
            "Epoch 8/25\n",
            "45/45 - 0s - loss: 0.3167 - accuracy: 0.8898 - val_loss: 0.2783 - val_accuracy: 0.8931 - lr: 1.0000e-03 - 319ms/epoch - 7ms/step\n",
            "Epoch 9/25\n",
            "45/45 - 0s - loss: 0.3145 - accuracy: 0.8884 - val_loss: 0.2780 - val_accuracy: 0.8931 - lr: 1.0000e-03 - 279ms/epoch - 6ms/step\n",
            "Epoch 10/25\n",
            "45/45 - 0s - loss: 0.3122 - accuracy: 0.8884 - val_loss: 0.2764 - val_accuracy: 0.8914 - lr: 1.0000e-03 - 335ms/epoch - 7ms/step\n",
            "Epoch 11/25\n",
            "45/45 - 0s - loss: 0.3097 - accuracy: 0.8877 - val_loss: 0.2968 - val_accuracy: 0.8914 - lr: 1.0000e-03 - 315ms/epoch - 7ms/step\n",
            "Epoch 12/25\n",
            "45/45 - 0s - loss: 0.3071 - accuracy: 0.8870 - val_loss: 0.2963 - val_accuracy: 0.8914 - lr: 1.0000e-03 - 289ms/epoch - 6ms/step\n",
            "Epoch 13/25\n",
            "45/45 - 0s - loss: 0.3050 - accuracy: 0.8877 - val_loss: 0.2958 - val_accuracy: 0.8931 - lr: 1.0000e-03 - 312ms/epoch - 7ms/step\n",
            "Epoch 14/25\n",
            "45/45 - 0s - loss: 0.3030 - accuracy: 0.8863 - val_loss: 0.2655 - val_accuracy: 0.8947 - lr: 1.0000e-03 - 316ms/epoch - 7ms/step\n",
            "Epoch 15/25\n",
            "45/45 - 0s - loss: 0.3014 - accuracy: 0.8863 - val_loss: 0.2648 - val_accuracy: 0.8931 - lr: 1.0000e-03 - 290ms/epoch - 6ms/step\n",
            "Epoch 16/25\n",
            "45/45 - 0s - loss: 0.2998 - accuracy: 0.8856 - val_loss: 0.2675 - val_accuracy: 0.8914 - lr: 1.0000e-03 - 314ms/epoch - 7ms/step\n",
            "Epoch 17/25\n",
            "45/45 - 0s - loss: 0.2973 - accuracy: 0.8856 - val_loss: 0.2970 - val_accuracy: 0.8914 - lr: 1.0000e-03 - 293ms/epoch - 7ms/step\n",
            "Epoch 18/25\n",
            "45/45 - 0s - loss: 0.2956 - accuracy: 0.8898 - val_loss: 0.2900 - val_accuracy: 0.8914 - lr: 1.0000e-03 - 344ms/epoch - 8ms/step\n",
            "Epoch 19/25\n",
            "45/45 - 0s - loss: 0.2946 - accuracy: 0.8884 - val_loss: 0.2946 - val_accuracy: 0.8914 - lr: 1.0000e-03 - 295ms/epoch - 7ms/step\n",
            "Epoch 20/25\n",
            "45/45 - 0s - loss: 0.2938 - accuracy: 0.8877 - val_loss: 0.3273 - val_accuracy: 0.8914 - lr: 1.0000e-03 - 340ms/epoch - 8ms/step\n",
            "Epoch 21/25\n",
            "45/45 - 0s - loss: 0.2923 - accuracy: 0.8877 - val_loss: 0.3268 - val_accuracy: 0.8914 - lr: 1.0000e-03 - 336ms/epoch - 7ms/step\n",
            "Epoch 22/25\n",
            "45/45 - 0s - loss: 0.2914 - accuracy: 0.8891 - val_loss: 0.3249 - val_accuracy: 0.8914 - lr: 1.0000e-03 - 311ms/epoch - 7ms/step\n",
            "Epoch 23/25\n",
            "45/45 - 0s - loss: 0.2904 - accuracy: 0.8898 - val_loss: 0.3241 - val_accuracy: 0.8931 - lr: 1.0000e-03 - 280ms/epoch - 6ms/step\n",
            "Epoch 24/25\n",
            "45/45 - 0s - loss: 0.2890 - accuracy: 0.8919 - val_loss: 0.3244 - val_accuracy: 0.8947 - lr: 1.0000e-03 - 311ms/epoch - 7ms/step\n",
            "Epoch 25/25\n",
            "45/45 - 0s - loss: 0.2883 - accuracy: 0.8927 - val_loss: 0.3203 - val_accuracy: 0.8964 - lr: 1.0000e-03 - 292ms/epoch - 6ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3203 - accuracy: 0.8964\n",
            "Model: \"model_325\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_326 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_679 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_210 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_680 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "45/45 - 5s - loss: 0.7367 - accuracy: 0.5544 - val_loss: 0.6006 - val_accuracy: 0.4868 - lr: 0.0100 - 5s/epoch - 119ms/step\n",
            "Epoch 2/25\n",
            "45/45 - 0s - loss: 0.4781 - accuracy: 0.6109 - val_loss: 0.4824 - val_accuracy: 0.6842 - lr: 0.0100 - 266ms/epoch - 6ms/step\n",
            "Epoch 3/25\n",
            "45/45 - 0s - loss: 0.4280 - accuracy: 0.8552 - val_loss: 0.5289 - val_accuracy: 0.8766 - lr: 0.0100 - 299ms/epoch - 7ms/step\n",
            "Epoch 4/25\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.4770 - accuracy: 0.8729 - val_loss: 0.4619 - val_accuracy: 0.8734 - lr: 0.0100 - 309ms/epoch - 7ms/step\n",
            "Epoch 5/25\n",
            "\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 0.4442 - accuracy: 0.8686 - val_loss: 0.4563 - val_accuracy: 0.8766 - lr: 1.0000e-03 - 324ms/epoch - 7ms/step\n",
            "Epoch 6/25\n",
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "45/45 - 0s - loss: 0.4403 - accuracy: 0.8715 - val_loss: 0.4560 - val_accuracy: 0.8766 - lr: 1.0000e-04 - 291ms/epoch - 6ms/step\n",
            "Epoch 7/25\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
            "45/45 - 0s - loss: 0.4401 - accuracy: 0.8715 - val_loss: 0.4560 - val_accuracy: 0.8766 - lr: 1.0000e-05 - 294ms/epoch - 7ms/step\n",
            "Epoch 8/25\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "45/45 - 0s - loss: 0.4401 - accuracy: 0.8715 - val_loss: 0.4560 - val_accuracy: 0.8766 - lr: 1.0000e-06 - 325ms/epoch - 7ms/step\n",
            "Epoch 9/25\n",
            "45/45 - 0s - loss: 0.4401 - accuracy: 0.8715 - val_loss: 0.4560 - val_accuracy: 0.8766 - lr: 1.0000e-07 - 286ms/epoch - 6ms/step\n",
            "Epoch 10/25\n",
            "45/45 - 0s - loss: 0.4401 - accuracy: 0.8715 - val_loss: 0.4560 - val_accuracy: 0.8766 - lr: 1.0000e-07 - 274ms/epoch - 6ms/step\n",
            "Epoch 11/25\n",
            "45/45 - 0s - loss: 0.4401 - accuracy: 0.8715 - val_loss: 0.4560 - val_accuracy: 0.8766 - lr: 1.0000e-07 - 279ms/epoch - 6ms/step\n",
            "Epoch 12/25\n",
            "45/45 - 0s - loss: 0.4401 - accuracy: 0.8715 - val_loss: 0.4560 - val_accuracy: 0.8766 - lr: 1.0000e-07 - 316ms/epoch - 7ms/step\n",
            "Epoch 13/25\n",
            "45/45 - 0s - loss: 0.4401 - accuracy: 0.8715 - val_loss: 0.4560 - val_accuracy: 0.8766 - lr: 1.0000e-07 - 275ms/epoch - 6ms/step\n",
            "Epoch 14/25\n",
            "45/45 - 0s - loss: 0.4401 - accuracy: 0.8715 - val_loss: 0.4560 - val_accuracy: 0.8766 - lr: 1.0000e-07 - 275ms/epoch - 6ms/step\n",
            "Epoch 15/25\n",
            "45/45 - 0s - loss: 0.4401 - accuracy: 0.8715 - val_loss: 0.4560 - val_accuracy: 0.8766 - lr: 1.0000e-07 - 307ms/epoch - 7ms/step\n",
            "Epoch 16/25\n",
            "45/45 - 0s - loss: 0.4401 - accuracy: 0.8715 - val_loss: 0.4560 - val_accuracy: 0.8766 - lr: 1.0000e-07 - 299ms/epoch - 7ms/step\n",
            "Epoch 17/25\n",
            "45/45 - 0s - loss: 0.4401 - accuracy: 0.8715 - val_loss: 0.4560 - val_accuracy: 0.8766 - lr: 1.0000e-07 - 291ms/epoch - 6ms/step\n",
            "Epoch 18/25\n",
            "45/45 - 0s - loss: 0.4401 - accuracy: 0.8715 - val_loss: 0.4560 - val_accuracy: 0.8766 - lr: 1.0000e-07 - 281ms/epoch - 6ms/step\n",
            "Epoch 19/25\n",
            "45/45 - 0s - loss: 0.4401 - accuracy: 0.8715 - val_loss: 0.4560 - val_accuracy: 0.8766 - lr: 1.0000e-07 - 296ms/epoch - 7ms/step\n",
            "Epoch 20/25\n",
            "45/45 - 0s - loss: 0.4401 - accuracy: 0.8715 - val_loss: 0.4560 - val_accuracy: 0.8766 - lr: 1.0000e-07 - 304ms/epoch - 7ms/step\n",
            "Epoch 21/25\n",
            "45/45 - 0s - loss: 0.4401 - accuracy: 0.8715 - val_loss: 0.4560 - val_accuracy: 0.8766 - lr: 1.0000e-07 - 264ms/epoch - 6ms/step\n",
            "Epoch 22/25\n",
            "45/45 - 0s - loss: 0.4401 - accuracy: 0.8715 - val_loss: 0.4560 - val_accuracy: 0.8766 - lr: 1.0000e-07 - 284ms/epoch - 6ms/step\n",
            "Epoch 23/25\n",
            "45/45 - 0s - loss: 0.4401 - accuracy: 0.8715 - val_loss: 0.4560 - val_accuracy: 0.8766 - lr: 1.0000e-07 - 287ms/epoch - 6ms/step\n",
            "Epoch 24/25\n",
            "45/45 - 0s - loss: 0.4401 - accuracy: 0.8715 - val_loss: 0.4560 - val_accuracy: 0.8766 - lr: 1.0000e-07 - 309ms/epoch - 7ms/step\n",
            "Epoch 25/25\n",
            "45/45 - 0s - loss: 0.4401 - accuracy: 0.8715 - val_loss: 0.4560 - val_accuracy: 0.8766 - lr: 1.0000e-07 - 316ms/epoch - 7ms/step\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4560 - accuracy: 0.8766\n",
            "Model: \"model_327\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_328 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_683 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_211 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_684 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "45/45 - 5s - loss: 0.5000 - accuracy: 0.7592 - val_loss: 0.4685 - val_accuracy: 0.8553 - lr: 0.0100 - 5s/epoch - 102ms/step\n",
            "Epoch 2/20\n",
            "45/45 - 0s - loss: 0.3991 - accuracy: 0.8842 - val_loss: 0.4338 - val_accuracy: 0.8651 - lr: 0.0100 - 301ms/epoch - 7ms/step\n",
            "Epoch 3/20\n",
            "45/45 - 0s - loss: 0.3720 - accuracy: 0.8884 - val_loss: 0.4120 - val_accuracy: 0.8668 - lr: 0.0100 - 298ms/epoch - 7ms/step\n",
            "Epoch 4/20\n",
            "45/45 - 0s - loss: 0.3511 - accuracy: 0.8905 - val_loss: 0.3943 - val_accuracy: 0.8684 - lr: 0.0100 - 284ms/epoch - 6ms/step\n",
            "Epoch 5/20\n",
            "45/45 - 0s - loss: 0.3344 - accuracy: 0.8891 - val_loss: 0.3808 - val_accuracy: 0.8684 - lr: 0.0100 - 310ms/epoch - 7ms/step\n",
            "Epoch 6/20\n",
            "45/45 - 0s - loss: 0.3204 - accuracy: 0.8962 - val_loss: 0.3703 - val_accuracy: 0.8651 - lr: 0.0100 - 294ms/epoch - 7ms/step\n",
            "Epoch 7/20\n",
            "45/45 - 0s - loss: 0.3078 - accuracy: 0.8997 - val_loss: 0.3577 - val_accuracy: 0.8651 - lr: 0.0100 - 300ms/epoch - 7ms/step\n",
            "Epoch 8/20\n",
            "45/45 - 0s - loss: 0.2947 - accuracy: 0.9032 - val_loss: 0.3448 - val_accuracy: 0.8651 - lr: 0.0100 - 286ms/epoch - 6ms/step\n",
            "Epoch 9/20\n",
            "45/45 - 0s - loss: 0.2832 - accuracy: 0.9032 - val_loss: 0.3349 - val_accuracy: 0.8783 - lr: 0.0100 - 292ms/epoch - 6ms/step\n",
            "Epoch 10/20\n",
            "45/45 - 0s - loss: 0.2763 - accuracy: 0.9054 - val_loss: 0.3447 - val_accuracy: 0.8865 - lr: 0.0100 - 268ms/epoch - 6ms/step\n",
            "Epoch 11/20\n",
            "45/45 - 0s - loss: 0.2674 - accuracy: 0.9047 - val_loss: 0.3354 - val_accuracy: 0.8898 - lr: 0.0100 - 301ms/epoch - 7ms/step\n",
            "Epoch 12/20\n",
            "45/45 - 0s - loss: 0.2638 - accuracy: 0.9089 - val_loss: 0.3534 - val_accuracy: 0.8849 - lr: 0.0100 - 304ms/epoch - 7ms/step\n",
            "Epoch 13/20\n",
            "45/45 - 0s - loss: 0.2558 - accuracy: 0.9117 - val_loss: 0.3447 - val_accuracy: 0.8865 - lr: 0.0100 - 311ms/epoch - 7ms/step\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.2662 - accuracy: 0.9061 - val_loss: 0.3388 - val_accuracy: 0.8865 - lr: 0.0100 - 302ms/epoch - 7ms/step\n",
            "Epoch 15/20\n",
            "\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 0.2563 - accuracy: 0.9075 - val_loss: 0.3338 - val_accuracy: 0.8832 - lr: 1.0000e-03 - 313ms/epoch - 7ms/step\n",
            "Epoch 16/20\n",
            "45/45 - 0s - loss: 0.2553 - accuracy: 0.9089 - val_loss: 0.3338 - val_accuracy: 0.8832 - lr: 1.0000e-04 - 314ms/epoch - 7ms/step\n",
            "Epoch 17/20\n",
            "45/45 - 0s - loss: 0.2552 - accuracy: 0.9089 - val_loss: 0.3339 - val_accuracy: 0.8832 - lr: 1.0000e-04 - 276ms/epoch - 6ms/step\n",
            "Epoch 18/20\n",
            "45/45 - 0s - loss: 0.2551 - accuracy: 0.9089 - val_loss: 0.3339 - val_accuracy: 0.8832 - lr: 1.0000e-04 - 315ms/epoch - 7ms/step\n",
            "Epoch 19/20\n",
            "45/45 - 0s - loss: 0.2550 - accuracy: 0.9089 - val_loss: 0.3341 - val_accuracy: 0.8832 - lr: 1.0000e-04 - 293ms/epoch - 7ms/step\n",
            "Epoch 20/20\n",
            "45/45 - 0s - loss: 0.2549 - accuracy: 0.9089 - val_loss: 0.3342 - val_accuracy: 0.8832 - lr: 1.0000e-04 - 284ms/epoch - 6ms/step\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3342 - accuracy: 0.8832\n",
            "Model: \"model_329\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_330 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_687 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_212 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_688 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "45/45 - 5s - loss: 0.5542 - accuracy: 0.6568 - val_loss: 0.4193 - val_accuracy: 0.8586 - lr: 0.0100 - 5s/epoch - 117ms/step\n",
            "Epoch 2/15\n",
            "45/45 - 0s - loss: 0.3846 - accuracy: 0.8715 - val_loss: 0.3873 - val_accuracy: 0.8832 - lr: 0.0100 - 314ms/epoch - 7ms/step\n",
            "Epoch 3/15\n",
            "45/45 - 0s - loss: 0.3363 - accuracy: 0.8955 - val_loss: 0.3477 - val_accuracy: 0.8947 - lr: 0.0100 - 300ms/epoch - 7ms/step\n",
            "Epoch 4/15\n",
            "45/45 - 0s - loss: 0.3138 - accuracy: 0.9089 - val_loss: 0.3304 - val_accuracy: 0.9013 - lr: 0.0100 - 303ms/epoch - 7ms/step\n",
            "Epoch 5/15\n",
            "45/45 - 0s - loss: 0.2897 - accuracy: 0.9082 - val_loss: 0.3136 - val_accuracy: 0.9030 - lr: 0.0100 - 273ms/epoch - 6ms/step\n",
            "Epoch 6/15\n",
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.3135 - accuracy: 0.8814 - val_loss: 0.3666 - val_accuracy: 0.8931 - lr: 0.0100 - 278ms/epoch - 6ms/step\n",
            "Epoch 7/15\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 0.3009 - accuracy: 0.8884 - val_loss: 0.3617 - val_accuracy: 0.8964 - lr: 1.0000e-03 - 314ms/epoch - 7ms/step\n",
            "Epoch 8/15\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "45/45 - 0s - loss: 0.2984 - accuracy: 0.8912 - val_loss: 0.3613 - val_accuracy: 0.8964 - lr: 1.0000e-04 - 318ms/epoch - 7ms/step\n",
            "Epoch 9/15\n",
            "\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
            "45/45 - 0s - loss: 0.2981 - accuracy: 0.8919 - val_loss: 0.3612 - val_accuracy: 0.8964 - lr: 1.0000e-05 - 301ms/epoch - 7ms/step\n",
            "Epoch 10/15\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "45/45 - 0s - loss: 0.2981 - accuracy: 0.8919 - val_loss: 0.3612 - val_accuracy: 0.8964 - lr: 1.0000e-06 - 312ms/epoch - 7ms/step\n",
            "Epoch 11/15\n",
            "45/45 - 0s - loss: 0.2981 - accuracy: 0.8919 - val_loss: 0.3612 - val_accuracy: 0.8964 - lr: 1.0000e-07 - 296ms/epoch - 7ms/step\n",
            "Epoch 12/15\n",
            "45/45 - 0s - loss: 0.2981 - accuracy: 0.8919 - val_loss: 0.3612 - val_accuracy: 0.8964 - lr: 1.0000e-07 - 316ms/epoch - 7ms/step\n",
            "Epoch 13/15\n",
            "45/45 - 0s - loss: 0.2981 - accuracy: 0.8919 - val_loss: 0.3612 - val_accuracy: 0.8964 - lr: 1.0000e-07 - 270ms/epoch - 6ms/step\n",
            "Epoch 14/15\n",
            "45/45 - 0s - loss: 0.2981 - accuracy: 0.8919 - val_loss: 0.3612 - val_accuracy: 0.8964 - lr: 1.0000e-07 - 298ms/epoch - 7ms/step\n",
            "Epoch 15/15\n",
            "45/45 - 0s - loss: 0.2981 - accuracy: 0.8919 - val_loss: 0.3612 - val_accuracy: 0.8964 - lr: 1.0000e-07 - 271ms/epoch - 6ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3612 - accuracy: 0.8964\n",
            "Model: \"model_331\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_332 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_691 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_213 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_692 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "45/45 - 5s - loss: 1.2857 - accuracy: 0.5388 - val_loss: 0.5988 - val_accuracy: 0.5230 - lr: 0.0100 - 5s/epoch - 105ms/step\n",
            "Epoch 2/15\n",
            "45/45 - 0s - loss: 0.5272 - accuracy: 0.5395 - val_loss: 0.4802 - val_accuracy: 0.5280 - lr: 0.0100 - 317ms/epoch - 7ms/step\n",
            "Epoch 3/15\n",
            "45/45 - 0s - loss: 0.4658 - accuracy: 0.7881 - val_loss: 0.4243 - val_accuracy: 0.8849 - lr: 0.0100 - 303ms/epoch - 7ms/step\n",
            "Epoch 4/15\n",
            "45/45 - 0s - loss: 0.4281 - accuracy: 0.8750 - val_loss: 0.4004 - val_accuracy: 0.8799 - lr: 0.0100 - 264ms/epoch - 6ms/step\n",
            "Epoch 5/15\n",
            "45/45 - 0s - loss: 0.4032 - accuracy: 0.8729 - val_loss: 0.3803 - val_accuracy: 0.8783 - lr: 0.0100 - 294ms/epoch - 7ms/step\n",
            "Epoch 6/15\n",
            "45/45 - 0s - loss: 0.3878 - accuracy: 0.8729 - val_loss: 0.3673 - val_accuracy: 0.8783 - lr: 0.0100 - 266ms/epoch - 6ms/step\n",
            "Epoch 7/15\n",
            "45/45 - 0s - loss: 0.3763 - accuracy: 0.8729 - val_loss: 0.3542 - val_accuracy: 0.8783 - lr: 0.0100 - 280ms/epoch - 6ms/step\n",
            "Epoch 8/15\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.3787 - accuracy: 0.8729 - val_loss: 0.3493 - val_accuracy: 0.8783 - lr: 0.0100 - 276ms/epoch - 6ms/step\n",
            "Epoch 9/15\n",
            "45/45 - 0s - loss: 0.3662 - accuracy: 0.8729 - val_loss: 0.3708 - val_accuracy: 0.8783 - lr: 1.0000e-03 - 291ms/epoch - 6ms/step\n",
            "Epoch 10/15\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 0.3711 - accuracy: 0.8729 - val_loss: 0.3631 - val_accuracy: 0.8783 - lr: 1.0000e-03 - 286ms/epoch - 6ms/step\n",
            "Epoch 11/15\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "45/45 - 0s - loss: 0.3677 - accuracy: 0.8729 - val_loss: 0.3623 - val_accuracy: 0.8783 - lr: 1.0000e-04 - 309ms/epoch - 7ms/step\n",
            "Epoch 12/15\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
            "45/45 - 0s - loss: 0.3674 - accuracy: 0.8729 - val_loss: 0.3623 - val_accuracy: 0.8783 - lr: 1.0000e-05 - 304ms/epoch - 7ms/step\n",
            "Epoch 13/15\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "45/45 - 0s - loss: 0.3674 - accuracy: 0.8729 - val_loss: 0.3623 - val_accuracy: 0.8783 - lr: 1.0000e-06 - 304ms/epoch - 7ms/step\n",
            "Epoch 14/15\n",
            "45/45 - 0s - loss: 0.3674 - accuracy: 0.8729 - val_loss: 0.3623 - val_accuracy: 0.8783 - lr: 1.0000e-07 - 280ms/epoch - 6ms/step\n",
            "Epoch 15/15\n",
            "45/45 - 0s - loss: 0.3674 - accuracy: 0.8729 - val_loss: 0.3623 - val_accuracy: 0.8783 - lr: 1.0000e-07 - 272ms/epoch - 6ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3623 - accuracy: 0.8783\n",
            "Model: \"model_333\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_334 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_695 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_214 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_696 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "45/45 - 6s - loss: 1.4920 - accuracy: 0.6398 - val_loss: 0.4116 - val_accuracy: 0.7977 - lr: 0.0100 - 6s/epoch - 137ms/step\n",
            "Epoch 2/25\n",
            "45/45 - 0s - loss: 0.4372 - accuracy: 0.8284 - val_loss: 0.3477 - val_accuracy: 0.8947 - lr: 0.0100 - 342ms/epoch - 8ms/step\n",
            "Epoch 3/25\n",
            "45/45 - 0s - loss: 0.3846 - accuracy: 0.8771 - val_loss: 0.3228 - val_accuracy: 0.9079 - lr: 0.0100 - 309ms/epoch - 7ms/step\n",
            "Epoch 4/25\n",
            "45/45 - 0s - loss: 0.3573 - accuracy: 0.8799 - val_loss: 0.2991 - val_accuracy: 0.9243 - lr: 0.0100 - 297ms/epoch - 7ms/step\n",
            "Epoch 5/25\n",
            "45/45 - 0s - loss: 0.3331 - accuracy: 0.8891 - val_loss: 0.2773 - val_accuracy: 0.9227 - lr: 0.0100 - 330ms/epoch - 7ms/step\n",
            "Epoch 6/25\n",
            "45/45 - 0s - loss: 0.3108 - accuracy: 0.8955 - val_loss: 0.2644 - val_accuracy: 0.9227 - lr: 0.0100 - 297ms/epoch - 7ms/step\n",
            "Epoch 7/25\n",
            "45/45 - 0s - loss: 0.3041 - accuracy: 0.9004 - val_loss: 0.2459 - val_accuracy: 0.9276 - lr: 0.0100 - 291ms/epoch - 6ms/step\n",
            "Epoch 8/25\n",
            "45/45 - 0s - loss: 0.2770 - accuracy: 0.9047 - val_loss: 0.2334 - val_accuracy: 0.9326 - lr: 0.0100 - 325ms/epoch - 7ms/step\n",
            "Epoch 9/25\n",
            "45/45 - 0s - loss: 0.2662 - accuracy: 0.9047 - val_loss: 0.2335 - val_accuracy: 0.9309 - lr: 0.0100 - 298ms/epoch - 7ms/step\n",
            "Epoch 10/25\n",
            "45/45 - 0s - loss: 0.2627 - accuracy: 0.9138 - val_loss: 0.2264 - val_accuracy: 0.9243 - lr: 0.0100 - 318ms/epoch - 7ms/step\n",
            "Epoch 11/25\n",
            "45/45 - 0s - loss: 0.2596 - accuracy: 0.9153 - val_loss: 0.2114 - val_accuracy: 0.9260 - lr: 0.0100 - 316ms/epoch - 7ms/step\n",
            "Epoch 12/25\n",
            "45/45 - 0s - loss: 0.2529 - accuracy: 0.9110 - val_loss: 0.2123 - val_accuracy: 0.9276 - lr: 0.0100 - 287ms/epoch - 6ms/step\n",
            "Epoch 13/25\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.2541 - accuracy: 0.9167 - val_loss: 0.2218 - val_accuracy: 0.9309 - lr: 0.0100 - 313ms/epoch - 7ms/step\n",
            "Epoch 14/25\n",
            "45/45 - 0s - loss: 0.2330 - accuracy: 0.9202 - val_loss: 0.1871 - val_accuracy: 0.9309 - lr: 1.0000e-03 - 292ms/epoch - 6ms/step\n",
            "Epoch 15/25\n",
            "45/45 - 0s - loss: 0.2275 - accuracy: 0.9251 - val_loss: 0.1890 - val_accuracy: 0.9211 - lr: 1.0000e-03 - 283ms/epoch - 6ms/step\n",
            "Epoch 16/25\n",
            "45/45 - 0s - loss: 0.2244 - accuracy: 0.9223 - val_loss: 0.2003 - val_accuracy: 0.9359 - lr: 1.0000e-03 - 305ms/epoch - 7ms/step\n",
            "Epoch 17/25\n",
            "\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 0.2243 - accuracy: 0.9258 - val_loss: 0.1862 - val_accuracy: 0.9276 - lr: 1.0000e-03 - 274ms/epoch - 6ms/step\n",
            "Epoch 18/25\n",
            "45/45 - 0s - loss: 0.2218 - accuracy: 0.9258 - val_loss: 0.2036 - val_accuracy: 0.9309 - lr: 1.0000e-04 - 276ms/epoch - 6ms/step\n",
            "Epoch 19/25\n",
            "45/45 - 0s - loss: 0.2210 - accuracy: 0.9266 - val_loss: 0.2028 - val_accuracy: 0.9309 - lr: 1.0000e-04 - 296ms/epoch - 7ms/step\n",
            "Epoch 20/25\n",
            "45/45 - 0s - loss: 0.2206 - accuracy: 0.9287 - val_loss: 0.2020 - val_accuracy: 0.9326 - lr: 1.0000e-04 - 291ms/epoch - 6ms/step\n",
            "Epoch 21/25\n",
            "45/45 - 0s - loss: 0.2203 - accuracy: 0.9280 - val_loss: 0.2013 - val_accuracy: 0.9326 - lr: 1.0000e-04 - 330ms/epoch - 7ms/step\n",
            "Epoch 22/25\n",
            "45/45 - 0s - loss: 0.2201 - accuracy: 0.9287 - val_loss: 0.2010 - val_accuracy: 0.9326 - lr: 1.0000e-04 - 286ms/epoch - 6ms/step\n",
            "Epoch 23/25\n",
            "45/45 - 0s - loss: 0.2199 - accuracy: 0.9287 - val_loss: 0.2007 - val_accuracy: 0.9309 - lr: 1.0000e-04 - 288ms/epoch - 6ms/step\n",
            "Epoch 24/25\n",
            "45/45 - 0s - loss: 0.2198 - accuracy: 0.9280 - val_loss: 0.2004 - val_accuracy: 0.9309 - lr: 1.0000e-04 - 319ms/epoch - 7ms/step\n",
            "Epoch 25/25\n",
            "45/45 - 0s - loss: 0.2196 - accuracy: 0.9287 - val_loss: 0.2002 - val_accuracy: 0.9326 - lr: 1.0000e-04 - 318ms/epoch - 7ms/step\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2002 - accuracy: 0.9326\n",
            "Model: \"model_335\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_336 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_699 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_215 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_700 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "45/45 - 7s - loss: 1.8702 - accuracy: 0.4852 - val_loss: 0.7247 - val_accuracy: 0.4605 - lr: 0.0100 - 7s/epoch - 149ms/step\n",
            "Epoch 2/20\n",
            "45/45 - 0s - loss: 0.7036 - accuracy: 0.4682 - val_loss: 0.6941 - val_accuracy: 0.4605 - lr: 0.0100 - 379ms/epoch - 8ms/step\n",
            "Epoch 3/20\n",
            "45/45 - 0s - loss: 0.6816 - accuracy: 0.4732 - val_loss: 0.6771 - val_accuracy: 0.4671 - lr: 0.0100 - 394ms/epoch - 9ms/step\n",
            "Epoch 4/20\n",
            "45/45 - 0s - loss: 0.6674 - accuracy: 0.5332 - val_loss: 0.6619 - val_accuracy: 0.7697 - lr: 0.0100 - 402ms/epoch - 9ms/step\n",
            "Epoch 5/20\n",
            "45/45 - 0s - loss: 0.6506 - accuracy: 0.8383 - val_loss: 0.6435 - val_accuracy: 0.8454 - lr: 0.0100 - 370ms/epoch - 8ms/step\n",
            "Epoch 6/20\n",
            "45/45 - 0s - loss: 0.6363 - accuracy: 0.8609 - val_loss: 0.6315 - val_accuracy: 0.8470 - lr: 0.0100 - 364ms/epoch - 8ms/step\n",
            "Epoch 7/20\n",
            "45/45 - 0s - loss: 0.6246 - accuracy: 0.8637 - val_loss: 0.6190 - val_accuracy: 0.8520 - lr: 0.0100 - 384ms/epoch - 9ms/step\n",
            "Epoch 8/20\n",
            "45/45 - 0s - loss: 0.6123 - accuracy: 0.8701 - val_loss: 0.6062 - val_accuracy: 0.8503 - lr: 0.0100 - 365ms/epoch - 8ms/step\n",
            "Epoch 9/20\n",
            "45/45 - 0s - loss: 0.5996 - accuracy: 0.8708 - val_loss: 0.5933 - val_accuracy: 0.8536 - lr: 0.0100 - 374ms/epoch - 8ms/step\n",
            "Epoch 10/20\n",
            "45/45 - 0s - loss: 0.5859 - accuracy: 0.8778 - val_loss: 0.5792 - val_accuracy: 0.8668 - lr: 0.0100 - 379ms/epoch - 8ms/step\n",
            "Epoch 11/20\n",
            "45/45 - 0s - loss: 0.5699 - accuracy: 0.8863 - val_loss: 0.5612 - val_accuracy: 0.8684 - lr: 0.0100 - 372ms/epoch - 8ms/step\n",
            "Epoch 12/20\n",
            "45/45 - 0s - loss: 0.5471 - accuracy: 0.8919 - val_loss: 0.5385 - val_accuracy: 0.8766 - lr: 0.0100 - 376ms/epoch - 8ms/step\n",
            "Epoch 13/20\n",
            "45/45 - 0s - loss: 0.5261 - accuracy: 0.8955 - val_loss: 0.5186 - val_accuracy: 0.8783 - lr: 0.0100 - 372ms/epoch - 8ms/step\n",
            "Epoch 14/20\n",
            "45/45 - 0s - loss: 0.5068 - accuracy: 0.8976 - val_loss: 0.4999 - val_accuracy: 0.8816 - lr: 0.0100 - 360ms/epoch - 8ms/step\n",
            "Epoch 15/20\n",
            "45/45 - 0s - loss: 0.4883 - accuracy: 0.8983 - val_loss: 0.4807 - val_accuracy: 0.8832 - lr: 0.0100 - 378ms/epoch - 8ms/step\n",
            "Epoch 16/20\n",
            "45/45 - 0s - loss: 0.4693 - accuracy: 0.8969 - val_loss: 0.4638 - val_accuracy: 0.8898 - lr: 0.0100 - 377ms/epoch - 8ms/step\n",
            "Epoch 17/20\n",
            "45/45 - 0s - loss: 0.4504 - accuracy: 0.9040 - val_loss: 0.4442 - val_accuracy: 0.8865 - lr: 0.0100 - 375ms/epoch - 8ms/step\n",
            "Epoch 18/20\n",
            "45/45 - 0s - loss: 0.4328 - accuracy: 0.9061 - val_loss: 0.4281 - val_accuracy: 0.8849 - lr: 0.0100 - 373ms/epoch - 8ms/step\n",
            "Epoch 19/20\n",
            "45/45 - 0s - loss: 0.4149 - accuracy: 0.9068 - val_loss: 0.4101 - val_accuracy: 0.8964 - lr: 0.0100 - 357ms/epoch - 8ms/step\n",
            "Epoch 20/20\n",
            "45/45 - 0s - loss: 0.3973 - accuracy: 0.9117 - val_loss: 0.3942 - val_accuracy: 0.8964 - lr: 0.0100 - 386ms/epoch - 9ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3942 - accuracy: 0.8964\n",
            "Model: \"model_337\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_338 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_704 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_216 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_705 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "45/45 - 8s - loss: 0.8544 - accuracy: 0.5282 - val_loss: 0.6826 - val_accuracy: 0.5477 - lr: 0.0100 - 8s/epoch - 168ms/step\n",
            "Epoch 2/15\n",
            "45/45 - 0s - loss: 0.6697 - accuracy: 0.5282 - val_loss: 0.6200 - val_accuracy: 0.5477 - lr: 0.0100 - 408ms/epoch - 9ms/step\n",
            "Epoch 3/15\n",
            "45/45 - 0s - loss: 0.5962 - accuracy: 0.5282 - val_loss: 0.5420 - val_accuracy: 0.5477 - lr: 0.0100 - 383ms/epoch - 9ms/step\n",
            "Epoch 4/15\n",
            "45/45 - 0s - loss: 0.5322 - accuracy: 0.5282 - val_loss: 0.4859 - val_accuracy: 0.5477 - lr: 0.0100 - 428ms/epoch - 10ms/step\n",
            "Epoch 5/15\n",
            "45/45 - 0s - loss: 0.4795 - accuracy: 0.6299 - val_loss: 0.4365 - val_accuracy: 0.7582 - lr: 0.0100 - 387ms/epoch - 9ms/step\n",
            "Epoch 6/15\n",
            "45/45 - 0s - loss: 0.4439 - accuracy: 0.7945 - val_loss: 0.3997 - val_accuracy: 0.8372 - lr: 0.0100 - 377ms/epoch - 8ms/step\n",
            "Epoch 7/15\n",
            "45/45 - 0s - loss: 0.4097 - accuracy: 0.8658 - val_loss: 0.3723 - val_accuracy: 0.9128 - lr: 0.0100 - 376ms/epoch - 8ms/step\n",
            "Epoch 8/15\n",
            "45/45 - 0s - loss: 0.3805 - accuracy: 0.9082 - val_loss: 0.3426 - val_accuracy: 0.9309 - lr: 0.0100 - 397ms/epoch - 9ms/step\n",
            "Epoch 9/15\n",
            "45/45 - 0s - loss: 0.3642 - accuracy: 0.9153 - val_loss: 0.3419 - val_accuracy: 0.9211 - lr: 0.0100 - 404ms/epoch - 9ms/step\n",
            "Epoch 10/15\n",
            "45/45 - 0s - loss: 0.3440 - accuracy: 0.9188 - val_loss: 0.3269 - val_accuracy: 0.9112 - lr: 0.0100 - 386ms/epoch - 9ms/step\n",
            "Epoch 11/15\n",
            "45/45 - 0s - loss: 0.3279 - accuracy: 0.9202 - val_loss: 0.2883 - val_accuracy: 0.9243 - lr: 0.0100 - 397ms/epoch - 9ms/step\n",
            "Epoch 12/15\n",
            "45/45 - 0s - loss: 0.3132 - accuracy: 0.9195 - val_loss: 0.2789 - val_accuracy: 0.9211 - lr: 0.0100 - 397ms/epoch - 9ms/step\n",
            "Epoch 13/15\n",
            "45/45 - 0s - loss: 0.3016 - accuracy: 0.9195 - val_loss: 0.2890 - val_accuracy: 0.9194 - lr: 0.0100 - 366ms/epoch - 8ms/step\n",
            "Epoch 14/15\n",
            "45/45 - 0s - loss: 0.2922 - accuracy: 0.9131 - val_loss: 0.2896 - val_accuracy: 0.9243 - lr: 0.0100 - 399ms/epoch - 9ms/step\n",
            "Epoch 15/15\n",
            "45/45 - 0s - loss: 0.2848 - accuracy: 0.9153 - val_loss: 0.2755 - val_accuracy: 0.9227 - lr: 0.0100 - 387ms/epoch - 9ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2755 - accuracy: 0.9227\n",
            "Model: \"model_339\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_340 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_709 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_217 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_710 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "45/45 - 7s - loss: 0.7373 - accuracy: 0.5395 - val_loss: 0.6770 - val_accuracy: 0.5214 - lr: 0.0100 - 7s/epoch - 162ms/step\n",
            "Epoch 2/25\n",
            "45/45 - 0s - loss: 0.6233 - accuracy: 0.5395 - val_loss: 0.5932 - val_accuracy: 0.5214 - lr: 0.0100 - 360ms/epoch - 8ms/step\n",
            "Epoch 3/25\n",
            "45/45 - 0s - loss: 0.5557 - accuracy: 0.5466 - val_loss: 0.5022 - val_accuracy: 0.6431 - lr: 0.0100 - 390ms/epoch - 9ms/step\n",
            "Epoch 4/25\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.5845 - accuracy: 0.8298 - val_loss: 0.6112 - val_accuracy: 0.8766 - lr: 0.0100 - 369ms/epoch - 8ms/step\n",
            "Epoch 5/25\n",
            "\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "45/45 - 0s - loss: 0.6097 - accuracy: 0.8806 - val_loss: 0.6084 - val_accuracy: 0.8766 - lr: 1.0000e-03 - 387ms/epoch - 9ms/step\n",
            "Epoch 6/25\n",
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "45/45 - 0s - loss: 0.6081 - accuracy: 0.8814 - val_loss: 0.6081 - val_accuracy: 0.8750 - lr: 1.0000e-04 - 377ms/epoch - 8ms/step\n",
            "Epoch 7/25\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
            "45/45 - 0s - loss: 0.6080 - accuracy: 0.8814 - val_loss: 0.6081 - val_accuracy: 0.8750 - lr: 1.0000e-05 - 371ms/epoch - 8ms/step\n",
            "Epoch 8/25\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "45/45 - 0s - loss: 0.6080 - accuracy: 0.8814 - val_loss: 0.6081 - val_accuracy: 0.8750 - lr: 1.0000e-06 - 412ms/epoch - 9ms/step\n",
            "Epoch 9/25\n",
            "45/45 - 0s - loss: 0.6080 - accuracy: 0.8814 - val_loss: 0.6081 - val_accuracy: 0.8750 - lr: 1.0000e-07 - 374ms/epoch - 8ms/step\n",
            "Epoch 10/25\n",
            "45/45 - 0s - loss: 0.6080 - accuracy: 0.8814 - val_loss: 0.6081 - val_accuracy: 0.8750 - lr: 1.0000e-07 - 372ms/epoch - 8ms/step\n",
            "Epoch 11/25\n",
            "45/45 - 0s - loss: 0.6080 - accuracy: 0.8814 - val_loss: 0.6081 - val_accuracy: 0.8750 - lr: 1.0000e-07 - 388ms/epoch - 9ms/step\n",
            "Epoch 12/25\n",
            "45/45 - 0s - loss: 0.6080 - accuracy: 0.8814 - val_loss: 0.6081 - val_accuracy: 0.8750 - lr: 1.0000e-07 - 378ms/epoch - 8ms/step\n",
            "Epoch 13/25\n",
            "45/45 - 0s - loss: 0.6080 - accuracy: 0.8814 - val_loss: 0.6081 - val_accuracy: 0.8750 - lr: 1.0000e-07 - 372ms/epoch - 8ms/step\n",
            "Epoch 14/25\n",
            "45/45 - 0s - loss: 0.6080 - accuracy: 0.8814 - val_loss: 0.6081 - val_accuracy: 0.8750 - lr: 1.0000e-07 - 373ms/epoch - 8ms/step\n",
            "Epoch 15/25\n",
            "45/45 - 0s - loss: 0.6080 - accuracy: 0.8814 - val_loss: 0.6081 - val_accuracy: 0.8750 - lr: 1.0000e-07 - 379ms/epoch - 8ms/step\n",
            "Epoch 16/25\n",
            "45/45 - 0s - loss: 0.6080 - accuracy: 0.8814 - val_loss: 0.6081 - val_accuracy: 0.8750 - lr: 1.0000e-07 - 372ms/epoch - 8ms/step\n",
            "Epoch 17/25\n",
            "45/45 - 0s - loss: 0.6080 - accuracy: 0.8814 - val_loss: 0.6081 - val_accuracy: 0.8750 - lr: 1.0000e-07 - 363ms/epoch - 8ms/step\n",
            "Epoch 18/25\n",
            "45/45 - 0s - loss: 0.6080 - accuracy: 0.8814 - val_loss: 0.6081 - val_accuracy: 0.8750 - lr: 1.0000e-07 - 355ms/epoch - 8ms/step\n",
            "Epoch 19/25\n",
            "45/45 - 0s - loss: 0.6080 - accuracy: 0.8814 - val_loss: 0.6081 - val_accuracy: 0.8750 - lr: 1.0000e-07 - 377ms/epoch - 8ms/step\n",
            "Epoch 20/25\n",
            "45/45 - 0s - loss: 0.6080 - accuracy: 0.8814 - val_loss: 0.6081 - val_accuracy: 0.8750 - lr: 1.0000e-07 - 369ms/epoch - 8ms/step\n",
            "Epoch 21/25\n",
            "45/45 - 0s - loss: 0.6080 - accuracy: 0.8814 - val_loss: 0.6081 - val_accuracy: 0.8750 - lr: 1.0000e-07 - 371ms/epoch - 8ms/step\n",
            "Epoch 22/25\n",
            "45/45 - 0s - loss: 0.6080 - accuracy: 0.8814 - val_loss: 0.6081 - val_accuracy: 0.8750 - lr: 1.0000e-07 - 375ms/epoch - 8ms/step\n",
            "Epoch 23/25\n",
            "45/45 - 0s - loss: 0.6080 - accuracy: 0.8814 - val_loss: 0.6081 - val_accuracy: 0.8750 - lr: 1.0000e-07 - 381ms/epoch - 8ms/step\n",
            "Epoch 24/25\n",
            "45/45 - 0s - loss: 0.6080 - accuracy: 0.8814 - val_loss: 0.6081 - val_accuracy: 0.8750 - lr: 1.0000e-07 - 376ms/epoch - 8ms/step\n",
            "Epoch 25/25\n",
            "45/45 - 0s - loss: 0.6080 - accuracy: 0.8814 - val_loss: 0.6081 - val_accuracy: 0.8750 - lr: 1.0000e-07 - 371ms/epoch - 8ms/step\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.8750\n",
            "  Evaluated 30 individuals\n",
            "  Min 0.48355263471603394\n",
            "  Max 0.9342105388641357\n",
            "  Avg 0.8826206147670745\n",
            "  Std 0.08151932978201663\n",
            "-- End of (successful) evolution --\n",
            "avg     \tevals\tgen\tmax     \tmin     \tstd      \n",
            "0.852138\t30   \t1  \t0.944079\t0.53125 \t0.113238 \n",
            "0.863871\t30   \t2  \t0.944079\t0.460526\t0.119448 \n",
            "0.869572\t30   \t3  \t0.934211\t0.534539\t0.10852  \n",
            "0.862719\t30   \t4  \t0.935855\t0.514803\t0.112118 \n",
            "0.882621\t30   \t5  \t0.934211\t0.483553\t0.0815193\n",
            "Best individual is [2, 1, 3, 0, 3, 3, 3], (0.9342105388641357,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "\n",
        "random.seed(69)\n",
        "pop = toolbox.population(n=30)\n",
        "#print(pop)\n",
        "CXPB, MUTPB = 0.9, 0.3\n",
        "\n",
        "print(\"Start of evolution\")\n",
        "\n",
        "# Evaluate the entire population\n",
        "fitnesses = list(map(toolbox.evaluate, pop))\n",
        "\n",
        "print(type(fitnesses))\n",
        "\n",
        "for ind, fit in zip(pop,fitnesses):\n",
        "    ind.fitness.values = fit\n",
        "\n",
        "print(\"  Evaluated %i individuals\" % len(pop))\n",
        "\n",
        "# Extracting all the fitnesses of\n",
        "fits = [ind.fitness.values[0] for ind in pop]      # facciamo una lista con le fitnesses degli individui, ind.fitness.values\n",
        "                                                    # è un vettore (?) composto in questo caso di una sola entrata,\n",
        "                                                    # di cui passiamo il valore\n",
        "\n",
        "# Variable keeping track of the number of generations\n",
        "g = 0\n",
        "\n",
        "# Begin the evolution\n",
        "while max(fits) < 100 and g < 5:\n",
        "    # A new generation\n",
        "    g = g + 1\n",
        "    print(\"-- Generation %i --\" % g)\n",
        "\n",
        "    # Select the next generation individuals\n",
        "    offspring = toolbox.select(pop, len(pop))        # scrivere direttamente 300 va bene lo stesso, sembra. len(pop) è la grandezza della mating pool\n",
        "    # Clone the selected individuals\n",
        "    offspring = list(map(toolbox.clone, offspring))      # inutile?\n",
        "\n",
        "\n",
        "\n",
        "    # Apply crossover and mutation on the offspring\n",
        "    for child1, child2 in zip(offspring[::2], offspring[1::2]):  # offspring[::2] è la lista offspring valutata un elemento\n",
        "                                                                  # sì e uno no a partire dal primo (di posto 0),\n",
        "                                                                  # offspring[1::2] è la stessa cosa ma partendo dal secondo\n",
        "                                                                  # (di posto 1)\n",
        "\n",
        "        # cross two individuals with probability CXPB\n",
        "        if random.random() < CXPB:\n",
        "            toolbox.mate(child1, child2)\n",
        "\n",
        "            # fitness values of the children\n",
        "            # must be recalculated later\n",
        "            del child1.fitness.values\n",
        "            del child2.fitness.values\n",
        "\n",
        "    for mutant in offspring:\n",
        "\n",
        "        # mutate an individual with probability MUTPB\n",
        "        if random.random() < MUTPB:\n",
        "            toolbox.mutate(mutant)\n",
        "            del mutant.fitness.values\n",
        "\n",
        "    # Evaluate the individuals with an invalid fitness                  # \"ind al variare di ind in offspring se il valore di fitness non è valido\"\n",
        "    invalid_ind = [ind for ind in offspring if not ind.fitness.valid]   # creiamo una lista con gli individui alterati\n",
        "    fitnesses = map(toolbox.evaluate, invalid_ind)                      # da crossover e/o mutazioni, cui abbiamo cancellato\n",
        "    for ind, fit in zip(invalid_ind, fitnesses):                        # la fitness precedentemente. Gli riassegniamo\n",
        "        ind.fitness.values = fit                                        # una fitness.\n",
        "\n",
        "    print(\"  Evaluated %i individuals\" % len(invalid_ind))              # Non analizziammo di nuovo tutto ma solo gli individui alterati\n",
        "\n",
        "    # The population is entirely replaced by the offspring\n",
        "    pop[:] = offspring\n",
        "\n",
        "    record=stats.compile(pop)                           # è un altro modo di printare le statistiche\n",
        "                                                        # in realtà il logbook permette anche di conservare (come dizionario) le stats\n",
        "    logbook.record(gen=g,evals=len(pop),**record)       # di ogni generazione\n",
        "    gen,avg=logbook.select(\"gen\",\"avg\")\n",
        "\n",
        "\n",
        "    # Gather all the fitnesses in one list and print the stats\n",
        "    fits = [ind.fitness.values[0] for ind in pop]\n",
        "\n",
        "    length = len(pop)\n",
        "    mean = sum(fits) / length\n",
        "    sum2 = sum(x * x for x in fits)\n",
        "    std = abs(sum2 / length - mean ** 2) ** 0.5\n",
        "\n",
        "    print(\"  Min %s\" % min(fits))\n",
        "    print(\"  Max %s\" % max(fits))\n",
        "    print(\"  Avg %s\" % mean)\n",
        "    print(\"  Std %s\" % std)\n",
        "\n",
        "print(\"-- End of (successful) evolution --\")\n",
        "print(logbook)\n",
        "\n",
        "best_ind = tools.selBest(pop, 1)[0]\n",
        "print(\"Best individual is %s, %s\" % (best_ind, best_ind.fitness.values))\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.grid(True)\n",
        "plt.plot(gen,avg)\n",
        "ax.set_xlabel(\"Generation\")\n",
        "ax.set_xticks(np.arange(1,len(gen),5))\n",
        "ax.set_ylabel(\"Fitness\")\n",
        "#ax.set_yticks(numpy.arange(min(avg), 0.5))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZ5ZJKqYfCtE"
      },
      "outputs": [],
      "source": [
        "#main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation of best individual"
      ],
      "metadata": {
        "id": "zTOVyv7TV1FZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tot_df = pd.read_csv('tot_df_2.csv')\n",
        "# tot_df['Unnamed: 0']\n",
        "tot_df.index = tot_df['Unnamed: 0']\n",
        "tot_df = tot_df.drop(['Unnamed: 0'], axis=1)\n",
        "#shuffle sul dataframe\n",
        "index_list = list(np.array(list(range(int(tot_df.shape[0]/max_n_slot))))) # creo la lista degli indici\n",
        "np.random.shuffle(index_list) # shuffle non ritorna niente, agisce su index_list\n",
        "\n",
        "#tot_df = tot_df.loc[index_list]\n",
        "\n",
        "x_col = list(tot_df.columns)\n",
        "\n",
        "# rimuovo la colonna della variabile target\n",
        "x_col.remove('target')\n",
        "x_col.remove('electrons_isTightElectron')\n",
        "x_col.remove('muons_isTightMuon')\n",
        "x_col.remove('top_label')\n",
        "X = tot_df[x_col].values\n",
        "\n",
        "# definisco la colonna della variabile target\n",
        "y = tot_df['target'].values\n",
        "\n",
        "# preprocessing per LSTM\n",
        "X= shape_sequence(X, 4)\n",
        "y= shape_sequence(y, 4)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=False)\n",
        "\n",
        "model1=create_model(X_train,y_train)\n",
        "\n",
        "shape=X_train.shape[1]\n",
        "feat_length=X_train.shape[2]\n",
        "\n",
        "individual=best_ind\n",
        "\n",
        "#l'individuo sarà una lista di 6 componenti fatta di numeri random da 0 a 4\n",
        "#per esempio l'individuo: [0,0,0,0,0,0] corrisponde a scegliere\n",
        "#[1,sigmoid,sigmoid,LSTM(feat_length),0,5]\n",
        "\n",
        "#la struttura generale dell'individuo è quindi:\n",
        "#[n_layers,activation,rec_activation,layers,semifinal_layer,number_epochs]\n",
        "lista_of_activation=['sigmoid','tanh','softmax','relu']  #individual[0]\n",
        "lista_first_condition=[0,0,1,1] #individual[1]\n",
        "lista_second_condition=[0,1,2,3] #individual[2]\n",
        "lista_condizione_finale=[0,0,1,1] #individual[3]\n",
        "lista_interi_m=[1,2,3,4] #individual[4]\n",
        "lista_interi_n=[1,2,3,4] #individual[5]\n",
        "list_number_of_epochs=[10,15,20,25] #individual[6]\n",
        "\n",
        "input = Input(shape=(shape, feat_length))\n",
        "if lista_first_condition[individual[1]] == 1:\n",
        "  if lista_second_condition[individual[2]]==0:\n",
        "    state_h_0 = LSTM(shape*lista_interi_m[individual[4]], return_sequences=True) (input)\n",
        "    state_h = LSTM(shape*lista_interi_n[individual[5]], return_sequences=True) (state_h_0)\n",
        "  elif lista_second_condition[individual[2]]==1:\n",
        "    state_h_0 = Dense(shape*lista_interi_m[individual[4]], activation=lista_of_activation[individual[0]]) (input)\n",
        "    state_h = Dense(shape*lista_interi_n[individual[5]], activation=lista_of_activation[individual[0]]) (state_h_0)\n",
        "  elif lista_second_condition[individual[2]]==2:\n",
        "    state_h_0 = LSTM(shape*lista_interi_m[individual[4]], return_sequences=True) (input)\n",
        "    state_h = Dense(shape*lista_interi_n[individual[5]], activation=lista_of_activation[individual[0]]) (state_h_0)\n",
        "  elif lista_second_condition[individual[2]]==3:\n",
        "    state_h_0 = Dense(shape*lista_interi_m[individual[4]], activation=lista_of_activation[individual[0]]) (input)\n",
        "    state_h = LSTM(shape*lista_interi_m[individual[4]], return_sequences=True) (state_h_0)\n",
        "else:\n",
        "  if lista_condizione_finale[individual[3]]==0:\n",
        "    state_h = LSTM(shape*lista_interi_n[individual[5]], return_sequences=True) (input)\n",
        "  else:\n",
        "    state_h = Dense(shape*lista_interi_n[individual[5]], activation=lista_of_activation[individual[0]]) (input)\n",
        "\n",
        "state_h_2 = LSTM(1) (state_h)\n",
        "model = Model(inputs=input, outputs=state_h_2)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=1, min_lr=1e-7, verbose=2)\n",
        "opt=SGD(lr=0.01)\n",
        "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "history_def=model.fit(X_train, y_train, epochs=list_number_of_epochs[individual[5]], validation_data=(X_test, y_test), callbacks=[reduce_lr], verbose=2)\n",
        "score = model.evaluate(X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LznsrU3xV7os",
        "outputId": "a59fa1f2-de70-4b69-9f58-c7aa837e24eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_345\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_346 (InputLayer)      [(None, 4, 14)]           0         \n",
            "                                                                 \n",
            " lstm_722 (LSTM)             (None, 4, 12)             1296      \n",
            "                                                                 \n",
            " dense_220 (Dense)           (None, 4, 4)              52        \n",
            "                                                                 \n",
            " lstm_723 (LSTM)             (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45/45 - 5s - loss: 0.7379 - accuracy: 0.6130 - val_loss: 0.4779 - val_accuracy: 0.8734 - lr: 0.0100 - 5s/epoch - 102ms/step\n",
            "Epoch 2/25\n",
            "45/45 - 0s - loss: 0.4585 - accuracy: 0.8658 - val_loss: 0.4001 - val_accuracy: 0.8931 - lr: 0.0100 - 273ms/epoch - 6ms/step\n",
            "Epoch 3/25\n",
            "45/45 - 0s - loss: 0.4082 - accuracy: 0.8722 - val_loss: 0.3576 - val_accuracy: 0.8898 - lr: 0.0100 - 301ms/epoch - 7ms/step\n",
            "Epoch 4/25\n",
            "45/45 - 0s - loss: 0.3633 - accuracy: 0.8715 - val_loss: 0.3413 - val_accuracy: 0.8914 - lr: 0.0100 - 307ms/epoch - 7ms/step\n",
            "Epoch 5/25\n",
            "45/45 - 0s - loss: 0.3316 - accuracy: 0.8736 - val_loss: 0.3140 - val_accuracy: 0.9013 - lr: 0.0100 - 303ms/epoch - 7ms/step\n",
            "Epoch 6/25\n",
            "45/45 - 0s - loss: 0.3072 - accuracy: 0.8898 - val_loss: 0.3158 - val_accuracy: 0.8882 - lr: 0.0100 - 308ms/epoch - 7ms/step\n",
            "Epoch 7/25\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "45/45 - 0s - loss: 0.3200 - accuracy: 0.8686 - val_loss: 0.2974 - val_accuracy: 0.8882 - lr: 0.0100 - 283ms/epoch - 6ms/step\n",
            "Epoch 8/25\n",
            "45/45 - 0s - loss: 0.3029 - accuracy: 0.8686 - val_loss: 0.2950 - val_accuracy: 0.8882 - lr: 1.0000e-03 - 311ms/epoch - 7ms/step\n",
            "Epoch 9/25\n",
            "45/45 - 0s - loss: 0.3004 - accuracy: 0.8672 - val_loss: 0.2926 - val_accuracy: 0.8882 - lr: 1.0000e-03 - 279ms/epoch - 6ms/step\n",
            "Epoch 10/25\n",
            "45/45 - 0s - loss: 0.2979 - accuracy: 0.8672 - val_loss: 0.2901 - val_accuracy: 0.8882 - lr: 1.0000e-03 - 294ms/epoch - 7ms/step\n",
            "Epoch 11/25\n",
            "45/45 - 0s - loss: 0.2953 - accuracy: 0.8679 - val_loss: 0.2876 - val_accuracy: 0.8914 - lr: 1.0000e-03 - 309ms/epoch - 7ms/step\n",
            "Epoch 12/25\n",
            "45/45 - 0s - loss: 0.2926 - accuracy: 0.8686 - val_loss: 0.2850 - val_accuracy: 0.8914 - lr: 1.0000e-03 - 282ms/epoch - 6ms/step\n",
            "Epoch 13/25\n",
            "45/45 - 0s - loss: 0.2897 - accuracy: 0.8701 - val_loss: 0.2821 - val_accuracy: 0.8914 - lr: 1.0000e-03 - 264ms/epoch - 6ms/step\n",
            "Epoch 14/25\n",
            "45/45 - 0s - loss: 0.2866 - accuracy: 0.8708 - val_loss: 0.2789 - val_accuracy: 0.8898 - lr: 1.0000e-03 - 275ms/epoch - 6ms/step\n",
            "Epoch 15/25\n",
            "45/45 - 0s - loss: 0.2835 - accuracy: 0.8729 - val_loss: 0.2760 - val_accuracy: 0.8914 - lr: 1.0000e-03 - 301ms/epoch - 7ms/step\n",
            "Epoch 16/25\n",
            "45/45 - 0s - loss: 0.2798 - accuracy: 0.8750 - val_loss: 0.2727 - val_accuracy: 0.8980 - lr: 1.0000e-03 - 271ms/epoch - 6ms/step\n",
            "Epoch 17/25\n",
            "45/45 - 0s - loss: 0.2778 - accuracy: 0.8792 - val_loss: 0.2727 - val_accuracy: 0.8947 - lr: 1.0000e-03 - 288ms/epoch - 6ms/step\n",
            "Epoch 18/25\n",
            "45/45 - 0s - loss: 0.2746 - accuracy: 0.8814 - val_loss: 0.2689 - val_accuracy: 0.9030 - lr: 1.0000e-03 - 278ms/epoch - 6ms/step\n",
            "Epoch 19/25\n",
            "45/45 - 0s - loss: 0.2702 - accuracy: 0.8856 - val_loss: 0.2658 - val_accuracy: 0.9095 - lr: 1.0000e-03 - 292ms/epoch - 6ms/step\n",
            "Epoch 20/25\n",
            "45/45 - 0s - loss: 0.2658 - accuracy: 0.8905 - val_loss: 0.2627 - val_accuracy: 0.9128 - lr: 1.0000e-03 - 298ms/epoch - 7ms/step\n",
            "Epoch 21/25\n",
            "45/45 - 0s - loss: 0.2621 - accuracy: 0.8997 - val_loss: 0.2598 - val_accuracy: 0.9161 - lr: 1.0000e-03 - 275ms/epoch - 6ms/step\n",
            "Epoch 22/25\n",
            "45/45 - 0s - loss: 0.2591 - accuracy: 0.9004 - val_loss: 0.2581 - val_accuracy: 0.9145 - lr: 1.0000e-03 - 311ms/epoch - 7ms/step\n",
            "Epoch 23/25\n",
            "45/45 - 0s - loss: 0.2579 - accuracy: 0.8976 - val_loss: 0.2553 - val_accuracy: 0.9194 - lr: 1.0000e-03 - 263ms/epoch - 6ms/step\n",
            "Epoch 24/25\n",
            "45/45 - 0s - loss: 0.2536 - accuracy: 0.9032 - val_loss: 0.2534 - val_accuracy: 0.9178 - lr: 1.0000e-03 - 277ms/epoch - 6ms/step\n",
            "Epoch 25/25\n",
            "45/45 - 0s - loss: 0.2520 - accuracy: 0.9054 - val_loss: 0.2503 - val_accuracy: 0.9194 - lr: 1.0000e-03 - 298ms/epoch - 7ms/step\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.9194\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lstm_test_evaluation_graphs(history):\n",
        "    # summarize history for accuracy\n",
        "    fig_acc = plt.figure(figsize=(10, 10))\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()\n",
        "    # fig_acc.savefig(\"model_accuracy.png\")\n",
        "\n",
        "    # summarize history for Loss\n",
        "    fig_acc = plt.figure(figsize=(10, 10))\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()\n",
        "    # fig_acc.savefig(\"model_regression_loss.png\")"
      ],
      "metadata": {
        "id": "BxeBeHp7WK-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_test_evaluation_graphs(history_def)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XvgBiu3jWLp3",
        "outputId": "da100acc-ba11-4440-f172-b255faa37bd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmkAAAJcCAYAAACixjPMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXzc1X3v//dHu7VYtiVZxpaNLWPABpslBmwgzUIcliQsoSUkJVubkL00TXNDe7NQ2rT53dvStM1WkkuapWyBhJCGJNgplCQ2CWazLRvwErBlm5EsWcuMrRnN6Pz+OCNpZGuZkb4zo+X1fDzmMTPfZeaMSuDdc87nHHPOCQAAAJNLQb4bAAAAgJMR0gAAACYhQhoAAMAkREgDAACYhAhpAAAAkxAhDQAAYBIipAGY8szsP8zs79K89mUze1O22wQAE0VIAwAAmIQIaQAwSZhZUb7bAGDyIKQByInkMOOnzWybmUXM7P+ZWb2Z/czMus1sk5nNTbn+ajNrMrMOM3vczFamnDvPzJ5J3nefpLITvuutZvZc8t7NZrYmzTa+xcyeNbMuMztgZredcP7S5Od1JM+/L3l8lpn9k5m9YmadZvbr5LHXm1nzMH+HNyVf32ZmD5jZ982sS9L7zOxCM9uS/I7DZvYVMytJuf8sM9toZu1mFjKzvzazBWZ2zMxqUq4738xazaw4nd8OYPIhpAHIpeslbZB0uqS3SfqZpL+WVCf/76M/kyQzO13SPZL+PHnuEUk/MbOSZGB5SNL3JM2T9IPk5yp573mS7pL0IUk1kv5d0sNmVppG+yKS3iNpjqS3SPqImV2b/NxTk+39t2SbzpX0XPK+f5T0GkkXJ9v0vyT1pfk3uUbSA8nv/E9JCUmflFQrab2kyyR9NNmGKkmbJP1c0kJJp0n6pXPuVUmPS7oh5XPfLele51xvmu0AMMkQ0gDk0r8550LOuYOSfiXpt865Z51zPZJ+JOm85HXvkPRT59zGZMj4R0mz5EPQOknFkr7snOt1zj0g6amU77hZ0r87537rnEs4574jKZq8b1TOucedc9udc33OuW3yQfF1ydPvkrTJOXdP8nvbnHPPmVmBpD+RdItz7mDyOzc756Jp/k22OOceSn7ncefc0865J51zcefcy/Ihs78Nb5X0qnPun5xzPc65bufcb5PnviPpJkkys0JJ75QPsgCmKEIagFwKpbw+Psz7yuTrhZJe6T/hnOuTdEDSouS5g845l3LvKymvT5X0qeRwYYeZdUhanLxvVGZ2kZk9lhwm7JT0YfkeLSU/Y+8wt9XKD7cOdy4dB05ow+lm9l9m9mpyCPTv02iDJP1Y0iozWybfW9npnPvdONsEYBIgpAGYjA7Jhy1JkpmZfEA5KOmwpEXJY/2WpLw+IOmLzrk5KY9y59w9aXzv3ZIelrTYOVct6RuS+r/ngKTlw9xzRFLPCOcikspTfkeh/FBpKnfC+69LekHSCufcbPnh4NQ2NA7X8GRv5P3yvWnvFr1owJRHSAMwGd0v6S1mdlly4vun5IcsN0vaIiku6c/MrNjM3i7pwpR7vynpw8leMTOzimRBQFUa31slqd0512NmF8oPcfb7T0lvMrMbzKzIzGrM7NxkL99dku4ws4VmVmhm65Nz4F6SVJb8/mJJn5U01ty4KkldksJmdqakj6Sc+y9Jp5jZn5tZqZlVmdlFKee/K+l9kq4WIQ2Y8ghpACYd59yL8j1C/ybfU/U2SW9zzsWcczFJb5cPI+3y89d+mHLvVkkflPQVSUcl7Ulem46PSrrdzLolfV4+LPZ/7n5JV8kHxnb5ooFzkqf/UtJ2+blx7ZL+P0kFzrnO5Gd+S74XMCJpSLXnMP5SPhx2ywfO+1La0C0/lPk2Sa9K2i3pDSnnfyNfsPCMcy51CBjAFGRDp3UAAKYyM/tvSXc7576V77YAmBhCGgBME2Z2gaSN8nPquvPdHgATw3AnAEwDZvYd+TXU/pyABkwP9KQBAABMQvSkAQAATELTZjPf2tpat3Tp0nw3AwAAYExPP/30EefciesmDjFtQtrSpUu1devWfDcDAABgTGY25jI5DHcCAABMQoQ0AACASYiQBgAAMAlNmzlpw+nt7VVzc7N6enry3ZSsKysrU0NDg4qLi/PdFAAAEIBpHdKam5tVVVWlpUuXyszy3Zyscc6pra1Nzc3NWrZsWb6bAwAAAjCthzt7enpUU1MzrQOaJJmZampqZkSPIQAAM8W0DmmSpn1A6zdTficAADPFtA9pAAAAUxEhLcs6Ojr0ta99LeP7rrrqKnV0dGShRQAAYCogpGXZSCEtHo+Pet8jjzyiOXPmZKtZAABgkpvW1Z2Twa233qq9e/fq3HPPVXFxscrKyjR37ly98MILeumll3TttdfqwIED6unp0S233KKbb75Z0uA2V+FwWFdeeaUuvfRSbd68WYsWLdKPf/xjzZo1K8+/DAAAZNOMCWl/85Mm7TzUFehnrlo4W19421mjXvOlL31JO3bs0HPPPafHH39cb3nLW7Rjx46BpTLuuusuzZs3T8ePH9cFF1yg66+/XjU1NUM+Y/fu3brnnnv0zW9+UzfccIMefPBB3XTTTYH+FgAAMLnMmJA2WVx44YVD1jL713/9V/3oRz+SJB04cEC7d+8+KaQtW7ZM5557riTpNa95jV5++eWctRcAAOTHjAlpY/V45UpFRcXA68cff1ybNm3Sli1bVF5erte//vXDrnVWWlo68LqwsFDHjx/PSVsBAED+UDiQZVVVVeru7h72XGdnp+bOnavy8nK98MILevLJJ3PcOgAAMFnNmJ60fKmpqdEll1yis88+W7NmzVJ9ff3AuSuuuELf+MY3tHLlSp1xxhlat25dHlsKAAAmE3PO5bsNgVi7dq3bunXrkGO7du3SypUr89Si3JtpvxcAgKnKzJ52zq0d7RqGOwEAACYhQhoAAMAkREgDAACYhAhpAAAAkxAhDQAAYBJiCQ4AADCzOCf1dEgdB6TOZqnzQPLR7I+Vz5P++Af5biUhLds6Ojp0991366Mf/WjG9375y1/WzTffrPLy8iy0DACAaSoRl7oPDw1gA4EseSwWHnpPYalU3eAftafnp90nIKRlWUdHh772ta+NO6TddNNNhDQAAIZzZI/08hMn9Ig1S12HJJcYeu2sedKcxVLNcqnxdVL1Yh/I5iz2r8trpYLJNQuMkJZlt956q/bu3atzzz1XGzZs0Pz583X//fcrGo3quuuu09/8zd8oEonohhtuUHNzsxKJhD73uc8pFArp0KFDesMb3qDa2lo99thj+f4pAABMHs1PS9+92veIFRRJsxf6sHXqJSnhq2EwjJVUjP2Zk8zMCWk/u1V6dXuwn7lgtXTll0a95Etf+pJ27Nih5557To8++qgeeOAB/e53v5NzTldffbWeeOIJtba2auHChfrpT38qye/pWV1drTvuuEOPPfaYamtrg203AABTWcsu6T+vl8prpA8+5nvHCgrz3arATa5+vWnu0Ucf1aOPPqrzzjtP559/vl544QXt3r1bq1ev1saNG/WZz3xGv/rVr1RdXZ3vpgIAMDm1/1767rV+Dtl7fizVnT4tA5o0k3rSxujxygXnnP7qr/5KH/rQh04698wzz+iRRx7RZz/7WV122WX6/Oc/n4cWAgAwiXUdlr57jZSISu//mTRvWb5blFX0pGVZVVWVuru7JUmXX3657rrrLoXDvqLk4MGDamlp0aFDh1ReXq6bbrpJn/70p/XMM8+cdC8AADPasXbpe9dJx9qkP35Qmr8y3y3KupnTk5YnNTU1uuSSS3T22Wfryiuv1Lve9S6tX79eklRZWanvf//72rNnjz796U+roKBAxcXF+vrXvy5Juvnmm3XFFVdo4cKFFA4AAGauaLf0/eul9n3STQ9IDa/Jd4tywpxz+W5DINauXeu2bt065NiuXbu0cuX0T9r9ZtrvBQDMAL090n/+ofTKZukd35fOvCrfLQqEmT3tnFs72jX0pAEAgMkp0Ss98H7p5V9Lb79z2gS0dBHSAADA5NPXJ/34Y9KLj0hX/aO05oZ8tyjnpn3hwHQZzh3LTPmdAIAZwDnpZ/9L2naf9MbPSRd+MN8tyotpHdLKysrU1tY27QOMc05tbW0qKyvLd1MAAJi4x74oPfVN6eJPSK/9VL5bkzfTerizoaFBzc3Nam1tzXdTsq6srEwNDQ35bgYAABOz+d+kJ/6vdP57pA1/K5nlu0V5M61DWnFxsZYtm94L3QEAMG08/R3p0c9KZ10nvfXLMzqgSdN8uBMAAEwRTT+SfnKLdNqbpOvunLZbPWWCkAYAAPJr9ybpwQ9KS9ZJN3xPKirJd4smBUIaAADIn1e2SPfd5Ld5etd9Ukl5vls0aRDSAABAfhx+Xrr7Bqm6Qbrph1JZdb5bJEmKxfvy3QRJ07xwAAAApCkalpp/53u2Dj0rzVksLVnvH3MWB/99R3ZL33u7D2bveUiqrAv+OzJ0LBbX7T/ZqcOdPfr2+y5QQUF+CxcIaQAAzEThVmn/lsHH4W2SS0hWINWdKe1/Utp6l7+2OhnYTl0vLblYqjtjYpWXHQek717rP+PdD/metDzb3typW+59Vr9vi+jDr1uuPudUIEIaAADIJuekoy8PBrJXtkhtu/25ojJp0VrptX/hg9jiC6XSKqkvIYV2+Gv3b5b2PS5tv9/fM2uen+S/ZL106sXSKedIhcXptSXcKn3vWinaLb3/p1Ltadn4xWnr63O681f79E+PvqiailL95wcu0sXLa/Papn6ENAAAppu+PqllZzKQbfbP3Yf9ubJqH67Ou2kwYBWVnvwZBYX+3CnnSOs+7INe+77BkLd/s99XU5KKy6WGtb6Xbck6qeECqbTy5M883iF9/zqp65D07h9JC1Zn72+QhsOdx/UX9z2vLfvadOXZC/QPb1+tOeWTp7KUkAYAwFQXj/p5ZP2BbP9vpWinPzd7kXTqJT48nXqxVLdSKhhH3aCZVLPcP867yR/rDqX0zm2Wnvg/kuuTLBnwTr14cF5b8Szp7ndILS9I77rXtyePfrb9sG794Xb1Jvr0f65foz9a2yCbZIvnWjb3tTSzKyT9i6RCSd9yzn3phPOnSrpLUp2kdkk3Oeeak+feK+mzyUv/zjn3ndG+a+3atW7r1q0B/wIAACaJ3uNSZ7PUecA/dySf2/f5gJaI+utqTx8chlyyXpqzJHcr9/d0SQd+NxjcmrcOtmvWXKmnU/rDb0tnXZub9gwjEvXFAfdtPaA1DdX6lxvP07Laipy3w8yeds6tHfWabIU0MyuU9JKkDZKaJT0l6Z3OuZ0p1/xA0n85575jZm+U9H7n3LvNbJ6krZLWSnKSnpb0Gufc0ZG+j5AGAJiynJOOtfkA1h++Og8MDWTHjgy9xwqkqlP8pP6Gtckeq3VSxeSYTyVpaA/foWf9dk9nvz1vzdnW3KFb7n1OL7dF9JHXLdcnN5yu4sL8rEaWTkjL5nDnhZL2OOf2JRtzr6RrJO1MuWaVpL9Ivn5M0kPJ15dL2uica0/eu1HSFZLuyWJ7AUxl8ZjUdVCax369M07XIT/ENgkqBEeV6PW9TB2vDIawgUDWLMWPD72+uNwHsOoGP3RY3ZB8nzw2e2H6k/Xzpag0WWCQ36HNRJ/TnU/44oC6qlLd/YF1Wr+8Jq9tSkc2Q9oiSQdS3jdLuuiEa56X9Hb5IdHrJFWZWc0I9y468QvM7GZJN0vSkiVLAms4gCmm9SXpwT+VXt0mXfZ56dK/mPEbM09bzvn1tfZvTk5e3+JDj0xadY2vUDzlnHy3cqje49Kz35c2/6vUsX/weMV8v/5Y/Srp9MsHw9ecZBCbNZd/jgNwuPO4Pnnfc3pyX7uuWr1Af3/d5CoOGE2+Cwf+UtJXzOx9kp6QdFBSIt2bnXN3SrpT8sOd2WgggEnMOenpb0s//2s/Kfm0DdIvb/cTk6/+N6m4LN8txEQl4tKrzw8Gsv1PDg77ldf6dbsu+rAUaZGe+n/Szof8Bt2v/ZSfk5VPPV1+nbEtX/Xta7hA2nC7tGCNn8w/w/757DgWU1lxocqKc7dx+pDigD9coz96zeQrDhhNNkPaQUmpSxQ3JI8NcM4dku9Jk5lVSrreOddhZgclvf6Eex/PYlsBTDWRNunhT0gv/lRqfIN03TekynrpiX+UHvs7P5n6xrulqvp8txSZiB2Tmp8anHh+4CmpN+LPzV0qrXhzckHV9VLNaUN7mi79pPTUt6QtX5O+faW0eJ0Pays25LZHKnJE+u03pN/d6SfKN75Beu1d0tJLZ1TPmHNOu1vC2rgzpI07Q3ruQIdKigp0/pI5Wt9Yq4tPq9E5DXNUUhT8nLDU4oBzGqr15TwVB0xUNgsHiuQLBy6TD2dPSXqXc64p5ZpaSe3OuT4z+6KkhHPu88nCgaclnZ+89Bn5woH2kb6PwgFgBtn739KPPiwdPyq96Tbpoo8MXVJg54/9+VlzpXfeM/mGvzDoWPvQBVYPPyf1xSWZVH92ctmI5Cr3s09J7zNjx/zw4m/+RepqlupXS6/9pLTqWr/2V7Z0NkubvyI9/R9+ftnKt/mh90Xnj3nrdNGb6NNTL7dr084WbdoV0v72Y5Kkcxqq9cYz69Xd06vNe9u069UuOSfNKi7U2qVztX55jdY31mj1omoVTXAi/2QqDhhNXqs7kw24StKX5ZfguMs590Uzu13SVufcw2b2h5L+Qb6C8wlJH3PORZP3/omkv05+1Bedc98e7bsIacAMEI/64cwtX/Hb1lz/rZEXwzz8vHTPO32Qu+4bfr7SdNa+z68CP2tOvlsyuo4DQxdYbX3BHy8skRaePxjIFl848d8Sj0nbfyD9+p/96vrzGqVL/lw658bhF28dryN7pN98WXr+Xl/AsOYd0qV/7rdOmgG6e3r1Py+1atPOkB57sVWdx3tVUlSgS5bXaMOqBbps5XzVzx46tNtxLKYn97Vry94j2rKvTS+FwpKkytIiXbhsntY31mj98hqtPGW2CtPcPzPR5/TvT+zVHY++pLqqUv3zO87VusbJWxyQ95CWS4Q0YJprecEXB4R2SBd8UHrz3/p5aKPpDkn3vks6uFV6w/+W/uDT02u4qeOADyHbf+BXl+/vfTo1uRRDJr1P2dDXJx15cTCQvbLF92xJUulsH8T61/NaeH725mj1JaQX/kv61R2+p65qoXTxx6XXvE8qmcAQ2OFt0q/vkJoe8qHv/PdIF3/Cr0s2zR3sOK5f7vLDmE/ua1NvwmluebHeeGa9Nqyq12tX1KqiNP0ZVUfCUT25r02b97bpyb1t2nfED3FXzyrWRcvm+Z625TU6fX7VsJuepxYHvGX1Kfr761arunxyV74S0gBMfc75eUaPflYqqZSu+ap0xhXp39/b4+eubb9fOvt6f/9Y4W4yO9buh3O33e8rHCVp8UV+/amezuHncfVv1XPqxSfP4wpSPOZ7MPsrLw886XsyJT9fcGCB1XU+TGZz6HE4zvmh8l/dIb3ya9/zeNGHpQs/KJXPS/9zXtnsP2PPRh82L/hTad1Hpcr52Wt7njnn1HSoSxt3hrRpV0hNh7okSctqK7RhlQ9m5y+Zm3av11he7exJhjbf03ag3S9PUlNRonWNNVq3vEYXL69RY22Ffr7j1YHigNuuPmvKFAcQ0gBMbeFW6eGPSy/93FfsXfO18RUCOOeHvH55u7TwPF9QkM8epkz1Hvd/g20/kHY/KvX1+lXl19wgrf4jH8RSJXr9ciQDFZFb/EKpklRRN7gx9pL1vtKwcJw1ZNGw1Py7we9p3jq41te85YMT/Jes90ONk+k/nPt/63vBXvq5D/9r/0Ra/zGpasHw1zsn7dkk/eqf/G8tr5XWfUS64AOTf4h5nKLxhJ7c165NyWB2uLNHZtJrlszVhlX1etOqei2vG2Z/zixoPnpMW/a2+ce+Nh3u7JEkzasoUXskpnOSOwcsnULFAYQ0AFPX7k3SQx/xvUMbbpcu+tDE/yP/wk+lBz8olc32QW0yT+juS0i/f8IPZe76iRTtkioXSKv/0AezU85J/+9x0tpimwfX6yqp9EtD9PdwLVorlZQP/znh1qH7NL66XXIJv/L9gtWDgWzJ+qlTVfvqDh/gm34oFRRL5/2xdPGfDS6K3JfwPZe/vsP/3tkN0iV/Jp337pH/TlNUV0+vdjR3atvBTj27/6h+s6dN4Whcs4oL9doVtdqwql5vPHO+aioDnM83Ds45vdJ2TFv2tem3+9p02vxKfeh1yydlccBoCGkApp7eHmnTF/wSBvNX+eKA+rOC+/xXt/uCgsgR6dqv5XWLmpM454cLt/9A2v6AFH5VKqmSVl3te82Wvja4IcLOg0OrKlt2SnI+qCw8d3CLoZ7OwTllbXv8vUVlPsz1V142XOiD71TWttcvNvvc3T6YnX29nzP35Nel9r1SzQq/xMfqP5KKpsZCqKOJRONqOtSlbc0d2n6wU9ubOwfmgUlSw9xZA8Hs4uW1OV3bbKYgpAGYWkI7fXFAy04/V+hNt2Vn/li4RbrvJunAb6XX3Sq97jNDl/DItaMv+2C27X7pyEs+KK14s7Tmj6TTr8jNHLrjR/2WRf2B7OAzflhVksqq/Zpj/ZWXC88NtjpyMuk67KuHt37bz+s75Ry/1tqZb839HLqA9PQmtOtwl7Y1d2pbc6e2H+zQnpaw+pL/+T+lukyrF1VrTUO1VjfM0epF1ZpXMfWD6GRHSAMwNTjnF/589HM+EFz7Nb8AaTbFo9JPbpGev8evn3Xt13M7fBVp80Ns23/gw6LkA9CaG/xyIZlMZM+G3uPSoed8D1ndyvyG2Hw41u6HhDMZVp4EYvE+vRTq1vPNHdqeDGUvhboVTyay2soSrUkGsTUN1Vq9qFrzZ8+snQ8mi3xvsA4AYwu3+LlnezZJKy731ZeVddn/3qJSH8zmr5Q2fsH3Zr3zHr9pdTYkev2SDfs3+7lme//bL9o6f5V02Rf8XLPJtHRD8SzfczZTlc/Lf1AeQ8exmPa2RrS3JaxtB30o23W4W7FEnyRpTnmxVi+q1ofObNTqRXO0pqFap1SXTYnKR3iENAD589IvpIc+KsXC0lX/6CvlcvkfEDPpklt8peSDH5DufIP0zrulRa+Z+GfHIn57o/6J+s1bpV6/+rrmLvNLNqx5h7Tg7Il/F6at3kSf9rcf077WiPa1hrW3NexfH4moPRIbuK6qtEhnL6rW+y9ZqtUN1VqzaI4Wz5tFIJviGO4EkFt9fVI45JcyeOqbfr2s67/le7TyKdQk3XOj79m75qu+ZysTkbbBifj7t/gCgP7tjRac7Ycy+5ekGGmZB8xIzjm1R2Lad8QHsX2tEe1NhrL97ccGhiolP1zZWFep5XUVaqytVGNdhZbXVWrJvPJhF3nF5MVwJ4Dc6z3u9zDsPOCfOw6kvD/gqwr7J6Sv+5j0pi9Mjkno9WdJH3xMuu/dvnih9QXp9X89/Fws5/x8pYHtjZ70K+tLUmGp74m75Jbk9kYX+Hl2mLGcczrem1A4GlfHsd5kT1g4pXcsos7jvQPXlxQWaGltuc5YUKUrVy8YCGONdZWqnjW5V9FHsAhpANLnnF8UtWN/MnilhK/+MHbsyNB7rECqOkWqXuyXbTjrOqm6wW8DNNnWKauold7zY+mnn5Se+L9S64t+38+iWVLrrsFAtn+L1HXQ31NaLS25yO8HuWS9/02TIXRiQvr6nDqP9yocjSscjSsy8JxIeR1XOOafI9HEwLETr43E4uobZtBqflWpGusq9JY1p2h5XbJXrLZSi+bOCmzlfkxthLR8e+Z7fsI0MGk5qadrMJT1ryjfr7jcB7DqBr80Q3WDVL3EP89Z7ANa4RT6//6LSqSrv+IrGjd+TvrqOr+QbE+HP191ytDtjeavmrJLM8xEzvnwFeqKKtTVo1BXj1q6/etXO3sU6o6qpatHrd3RIcOMIykpKlBlaZEqSgtVUVKkytIizSkvUcPccn+stCh53j9mlxVpWW2FltVWqKpsCv3vAnlBSMu3x//BTzCunCKrc2NmKqmQ6ldJp18+GMjmLPavZ82dUksUpMXMb8Bde7r0my/7LY1OvdiHs7lLp9/vnSYi0bhe7Q9eAyEsqlB3j1q6epLnoorF+066t3pWsRbMLtP82aVaMb9W9bNLVVNRqsqywZBVmQxd/WGsorRIJUUzbGkS5BQhLZ+Otfshkw23+/krACaX09/sH0jbsVh8aC9V/+vuqEKdPQp19+hYLBH49x6P+eHGE5WXFA6Er/OXzE2+LlP97FLVzy5TfZU/x4r6mIwIafnUstM/B7nlDQBkQTSeUEtXVC3dPSkhbDCM9Qey7mGCUllxwUA4OqdhjipKg/9PT1lxgQ9d/eEr+ajMwncBucI/vfkUavLP9ayTBCB7YvG+wcnssf6J7UMnwKceS722LRxTqKtHR4/1nvS5xYWm+VVlWlBdpjMWVOm1K+pOCEqlmj+7TFWlRazXBYwDIS2fQjuk8hrmowEYoq/PJcPUMBWDsZPDVLhn+OP9VYf9K9CPpbjQBuZcVZX5OVeL55Vr7dK5qq/yPVPzU3qq5pYXE76ALCKk5VOoyVeG8S85YEpzzika7xt9qYb+Y7GhvVfdPfGTAlm6c7bMpMqS/srBwoHJ7PMqygcrDkuLBq4ZrDIsTJkMP3istIh5WcBkQkjLl76E1LJLOv+9+W4JMCPFE30+GMVO7HkaYygwJWSFe/p7txJKpLFcgySVDizZ4ANSZWmR6ipLtbRm6FINlanLNwwJWYMBq7ykkJ4sYBojpOXL0Zf9Pn4UDQATdiQc1fbmTu1pCav7pAVFU3qpYoO9V9FhlmEYTmGBqaKk8IQAVaT6qrKhyzKUDrNUQ+qxEh+wigpZsgFAeghp+TJQNEBIAzLRcSym7Qc7ta25U9ubO7WtuUOHOnuGXFNeUjik56mipEgL55QNDU4lIw/7pR4rLSqgtwpAXhDS8iXU5LfLqTsz3y0BJq3unl7tONil7Qc79HwylO1vPzZwfmlNudYunac1DdVavahaZy6YraqyIjaaBjAtENLyJbRDmrdcKinPd0uASeFYLK6dh7q0Ldk7to2GpQUAACAASURBVO1gp/a1RgbOL5ozS2saqvXOC5doTUO1zl5YrepyttUBMH0R0vIl1CSdck6+WwHkxbFYXC+FwtrePNhDtrule2AT6vrZpVq9aI6uO3eRVid7yWoq2bQcwMxCSMuHaFg6+nvp3D/Od0uArOnrczrUeVz7WiPa1xrWviORgdepc8jmVZRoTUO1Lj+rXmsa5mh1Q7XqZ5flseUAMDkQ0vKhZZd/rl+V33YAAQhH4z6EJQPY3mQY+/2RsHp6BysoK0uL1FhXoQuXzVNjXaVWzK/UmsVztLC6jIn5ADAMQlo+hHb4Zyo7MUUk+pwOHj2uvUcGw9i+1oj2HQkr1BUduK7ApIa55Wqsq9DFy2vUWFehxtpKLa+rUF1VKWEMADJASMuHUJNUUiVVL8l3S4AR7W0Na9POkDbtCun55k7FUtYVm11WpMa6Sl16Wp0a6yq0vK5CjXWVOrWmnFXrASAghLR8aNnphzoLWNQSk0eiz+mZ/Ue1cWdIm3aGtO+Ir6w8a+FsvXf9qVpeV6nGuko11lWopqKEXjEAyDJCWq4554c7z74+3y0BFInG9avdR7RxZ0iPvdii9khMxYWmdY01ev8lS3XZynotnDMr380EgBmJkJZrXQelnk7moyFvQl09+uWuFm3aFdKv9xxRLN6n2WVFeuOZ87Vh1QL9wem1qipj/TEAyDdCWq4NbAd1dn7bgRnDOacXQ93atDOkjTv9/DJJWjxvlm666FRtWFWvtUvnqpg9JQFgUiGk5Vp/Zef8lfltB6a13kSfnvp9uzbu8hP/D7QflySdu3iOPn35Gdqwql4r5lcyrwwAJjFCWq6FmnxVZ1l1vluCaaTjWEx7WyPa2xLWb/Ye0WMvtKirJ67SogJdelqtPvr603TZmfM1n0ViAWDKIKTlWqiJ+WgYl95En/a3H9Pelv7V+/vXKouoPRIbuK6mokSXn7VAG1bV69IVtSov4X/mADAV8W/vXIpHpSO7pTPfmu+WYJJyzqk94nvFBrdS8mFsf/sxxfs3t5RUW1mqxroKXX5WvV8wdr5fOHbxvHIVFjCMCQBTHSEtl1pflFxiSvakdff06tXOHtVVlap6VjFzmcbBOadovE+RaFyRaELd0V4daD+WDGR+9f59rRF1Hu8duKekqEDLaip0xoIqXbl6QTKMVWpZbYWqZ1GBCQDTGSEtl6ZQZeexWFxbXz6qLfvatHlvm3Yc7FQi2YtTUlSg+tmlqq8qU/3sMs2fXar62WVakPK6fnaZKktz+49Xb8IHoGOxhNzYl2ekr8/peG9C4Wg8GbLiCkcTyeeTj0ViqccH70vtCUtVP7tUjbWVeuuaUwYWjD2trlIL58yiVwwAZihCWi6FdkhFZdK8xny35CQ9vQk9s/+ontzrQ9nzzR3qTTgVFZjOWTxHH3ndcq2or9SRcEyhrp6Bx67DXXrsxR4diyVO+syKksIhIa5+dpnmVw2+XjC7TNXlxToeOzH89IecxNBjJwSe/uv6j6VuW5RrhQWmytIiVZYWqaK0UBXJ1/VVZcnX/ljFwDX+2MI5s7SstoJ1yQAAJyGk5VKoSao7UyrM/589Fu/T880d2rK3TZv3HtEz+zsUi/epwKTVi6r1J5cu08XLa7X21LmqSKNHLByNDwS3lq6oQl09ejXl9TP7jyrUFR1XkDKTKkqGhp+KkiI1zC1XZWmhKsuSoafEP5eXFKogC8Oxs0oKBwJWRWlhStgqUmlRAUPAAIBA5T8tzCShJmnFhrx8dTzRp+0HO7VlX5u27G3T1peP6nhvQmbSygWz9e51p+ri5TW6YNk8zR5Hr05laZEq6yq1vK5yxGucc+o83qtQMriFunrUcaxXs0oKVVVWlAxig71R/SFoVnGhChjyAwDMMIS0XAm3SJGWnBUNJPqcdh3u0pa9bdqyr02/+327wtG4JOn0+krdsLZB65fXal3jPM0pL8lJm8xMc8pLNKe8RGcsqMrJdwIAMFUR0nJloGgg2JDW1+d0uKtH+1rDKetnRbStuUNdPT6UNdZW6OpzF2p9Y43WNdaorqo00DYAAIDgEdJypWWnfx5nZWc4GtfvWyPa2xr2gSwZxn5/JKye3sF5XlWlRWqsq9CVZ5+idcvnaX1jrRZUs8o8AABTDSEtV0JNUmW9VFE74iWJPqdDHce1p38l+YEV5cMKdUUHriswafG8cjXWVuji5TVqrPOLmC6vq1BdVSkT2AEAmAYIabkS2jHsUOfPd7yqHz930PeKtUWGVD/OLivS8vmVuvS0OjXWVWh5XYUa6yp1ak25SosKc9l6AACQY4S0XEjEpZYXpItuPunUlze9pEMdx3Xhsnl63Rl1aqytGFjMtKaihF4xAABmKEJaLrTvlRLRYeejdffE9aaV9brjHefmoWEAAGCyKsh3A2aE0A7/PH/VSacisXhai8UCAICZhZCWC6EmyQqlujNOOhWJEtIAAMDJCGm5EGqSak+XioauTxaNJ9SbcKospQgAAAAMRUjLhdDOYSs7I1G/KTk9aQAA4ESEtGzr6ZQ6948Q0vyOAIQ0AABwIkJatoVG3mmgfy/NSkIaAAA4ASEt2/orO+lJAwAAGSCkZVuoSSqbI81eeNKpwZ40CgcAAMBQhLRsCzX5XrRhdg6gcAAAAIyEkJZNfX1Sy/CVnVLKcGcJIQ0AAAxFSMumjlekWHjEkEbhAAAAGAkhLZtaRq7slCgcAAAAIyOkZVOoSZJJdWcOezoci6uksEAlRfyfAQAADEU6yKbQDmneMqm0ctjTft9OKjsBAMDJCGnZ1F/ZOYJINMFQJwAAGBYhLVtix6S2vSPOR5N84QBFAwAAYDiEtGxp3SXJSfNXjXhJhJAGAABGQEjLllCTfx51uDPOcCcAABgWIS1bQjul4nJp7rIRL+mmJw0AAIwgqyHNzK4wsxfNbI+Z3TrM+SVm9piZPWtm28zsquTxpWZ23MyeSz6+kc12ZkVohx/qLBj5T0x1JwAAGEnWunHMrFDSVyVtkNQs6Skze9g5tzPlss9Kut8593UzWyXpEUlLk+f2OufOzVb7sso5P9y58m2jXkZ1JwAAGEk2e9IulLTHObfPOReTdK+ka064xkmanXxdLelQFtuTO92vSsfbR63sdM4pEmO4EwAADC+bIW2RpAMp75uTx1LdJukmM2uW70X7RMq5Zclh0P8xs9cO9wVmdrOZbTWzra2trQE2fYLSKBo4FkvIObaEAgAAw8t34cA7Jf2Hc65B0lWSvmdmBZIOS1rinDtP0l9IutvMZp94s3PuTufcWufc2rq6upw2fFShHf65fvTlNyRCGgAAGF42Q9pBSYtT3jckj6X6U0n3S5JzboukMkm1zrmoc64tefxpSXslnZ7FtgYr1CTNXiTNmjviJeFkSKukcAAAAAwjmyHtKUkrzGyZmZVIulHSwydcs1/SZZJkZivlQ1qrmdUlCw9kZo2SVkjal8W2BmuM7aAkXzQgSRUl9KQBAICTZS2kOefikj4u6ReSdslXcTaZ2e1mdnXysk9J+qCZPS/pHknvc845SX8gaZuZPSfpAUkfds61Z6utgYrHpCMvjRnSBnvSCGkAAOBkWU0IzrlH5AsCUo99PuX1TkmXDHPfg5IezGbbsqZtt9TXO2plp8ScNAAAMLp8Fw5MP2lUdkpSJEZIAwAAIyOkBS20QyoskWpOG/UyhjsBAMBoCGlBCzVJdWdIhcWjXjY43El1JwAAOBkhLWihpjHno0lSmOpOAAAwCkJakCJtUvdhv7H6WJdG4yovKVRBgeWgYQAAYKohpAWpJb2iAcmHNIoGAADASAhpQQrt9M9pDXeyuToAABgZIS1IoR1Sea1UOX/MS31PGkUDAABgeIS0IPVvB2VjzzOLRBMUDQAAgBER0oLSl5BadqU11Ckx3AkAAEZHSAtK+++l+PG0igYkv+MAhQMAAGAkhLSghHb453RDWjSuyjJCGgAAGB4hLSihJskK/G4DaWC4EwAAjIaQFpRQk9+vs3jWmJfGE33q6e2jcAAAAIyIkBaUlqYM5qMlt4RiCQ4AADACQloQot3S0Zczmo8mieFOAAAwIkJaEFp2+ecMlt+QRHUnAAAYESEtCBlWdobpSQMAAGMgpAUh1CSVzpaqF6d1eYSeNAAAMAZCWhAy2A5KSg1pFA4AAIDhEdImyjkptFOavyrtW8JRX93JcCcAABgJIW2iOpulaGfa89EkhjsBAMDYCGkTFWryz2lWdkoUDgAAgLER0iaqv7Jz/sq0b4lE4yosMJUW8ecHAADDIyVMVKhJmnOqVDY77Vsi0bgqSgplaRYaAACAmYeQNlGhpoyGOiVfOMBQJwAAGA0hbSJ6e6S23RkVDUjJnjRCGgAAGAUhbSJaX5BcX+YhLUZIAwAAoyOkTcRAZWdmIS0cjTPcCQAARkVIm4iWnVJRmTSvMaPb/HAnuw0AAICREdImIrTDL71RkFngikQTDHcCAIBREdImon/Pzgwx3AkAAMZCSBuvcIsUac14+Q3nHNWdAABgTIS08erfaSDDnrRovE/xPkdPGgAAGBUhbbz6KzvnZ75GmiRVlFA4AAAARkZIG69Qk1S5QKqoyei2SDQhSaosK85GqwAAwDRBSBuv0I5xFw1IUiVLcAAAgFEQ0sYjEZdaXxxXSIvEksOdzEkDAACjIKSNR9seKRHLuLJTGuxJI6QBAIDRENLGY5yVndJg4QDVnQAAYDSEtPEINUkFRVLt6RnfGqEnDQAApIGQNh6hJqn2DKmoJONbu3uSPWklhDQAADAyQtp4jHM7KGlwCQ42WAcAAKMhpGXq+FGpq1mqXzWu2yOxuEqLClRUyJ8eAACMjKSQqdBO/zyOyk6JzdUBAEB6CGmZaukPaeMd7mRzdQAAMDZCWqZCO6RZc6WqU8Z1OyENAACkg5CWqVCTH+o0G9ftfriTogEAADA6Qlom+vr8nLRxDnVKvrqTnjQAADAWQlomOl6WeiMTDGkMdwIAgLER0jIRavLPEwhp4WichWwBAMCYCGmZCDVJMqlu5bg/gp40AACQDkJaJkJN0rxGqaR8XLf39TlFYgkKBwAAwJgIaZmYwHZQknSst39LKHrSAADA6Ahp6epL+LXRFl847o+IRP3m6oQ0AAAwFtJCugoKpff/dEIfEU6GNLaFAgAAY6EnLYfoSQMAAOkipOVQeCCkUTgAAABGR0jLoUjUFw4w3AkAAMZCSMshhjsBAEC6CGk51D/cWUVIAwAAYyCk5RA9aQAAIF2EtByKROMyk8pLKBwAAACjI6TlUDiaUEVJkcws300BAACTHCEth/zm6vSiAQCAsRHScigcizMfDQAApIWQlkORaJw10gAAQFoIaTkU7omrooSQBgAAxpbVkGZmV5jZi2a2x8xuHeb8EjN7zMyeNbNtZnZVyrm/St73opldns125ko4ynAnAABIT9YSg5kVSvqqpA2SmiU9ZWYPO+d2plz2WUn3O+e+bmarJD0iaWny9Y2SzpK0UNImMzvdOZfIVntzIRKLq5LCAQAAkIZs9qRdKGmPc26fcy4m6V5J15xwjZM0O/m6WtKh5OtrJN3rnIs6534vaU/y86a0SDRBTxoAAEhLNkPaIkkHUt43J4+luk3STWbWLN+L9okM7pWZ3WxmW81sa2tra1DtzpowhQMAACBN+S4ceKek/3DONUi6StL3zCztNjnn7nTOrXXOra2rq8taI4PQm+hTLN5HTxoAAEhLNhPDQUmLU943JI+l+lNJV0iSc26LmZVJqk3z3imFfTsBAEAmstmT9pSkFWa2zMxK5AsBHj7hmv2SLpMkM1spqUxSa/K6G82s1MyWSVoh6XdZbGvWhZMhjcIBAACQjqx16zjn4mb2cUm/kFQo6S7nXJOZ3S5pq3PuYUmfkvRNM/ukfBHB+5xzTlKTmd0vaaekuKSPTfnKzqhvPj1pAAAgHVlNDM65R+QLAlKPfT7l9U5Jl4xw7xclfTGb7culMMOdAAAgA/kuHJgxIgPDnYQ0AAAwNkJajgwUDrAtFAAASAMhLUfC9KQBAIAMENJyZHAJDqo7AQDA2AhpORKJUd0JAADSR0jLkXA0rqICU2kRf3IAADA2EkOORKJxVZQWyczy3RQAADAFENJyhM3VAQBAJghpORIhpAEAgAwQ0nIkEk1Q2QkAANJGSMuRcHJOGgAAQDoIaTnCcCcAAMgEIS1HIvSkAQCADBDScoTqTgAAkAlCWg445xSJUTgAAADSR0jLgZ7ePiX6HMOdAAAgbYS0HAgnN1dnuBMAAKSLkJYDkWRIqyghpAEAgPQQ0nKgvyeN4U4AAJAuQloORBjuBAAAGSKk5UAk1t+TRnUnAABIDyEtB8LRhCR60gAAQPoIaTkQYU4aAADIECEtBwhpAAAgU4S0HBio7ixhThoAAEgPIS0HItG4yooLVFTInxsAAKSH1JAD4WiCogEAAJARQloORKJx5qMBAICMENJyIBKNsyUUAADICCEtB8LROMOdAAAgI4S0HIjE4uw2AAAAMkJIy4FINKHKsuJ8NwMAAEwhhLQc8MOd9KQBAID0EdJygMIBAACQKUJalvX1OR2LJViCAwAAZISQlmWRmN8SiupOAACQCUJalkWiCUlsrg4AADJDSMuygc3VKRwAAAAZIKRlWSTKcCcAAMgcIS3LIgM9aYQ0AACQPkJalnXTkwYAAMaBkJZl9KQBAIDxSCukmdkPzewtZkaoy1CEwgEAADAO6Yaur0l6l6TdZvYlMzsji22aVsLJJTgY7gQAAJlIK6Q55zY55/5Y0vmSXpa0ycw2m9n7zYydw0cRicZVYNKsYnrSAABA+tIevjSzGknvk/QBSc9K+hf50LYxKy2bJsLJfTvNLN9NAQAAU0haY3Bm9iNJZ0j6nqS3OecOJ0/dZ2Zbs9W46SASjVM0AAAAMpZuevhX59xjw51wzq0NsD3TTiQWp2gAAABkLN3hzlVmNqf/jZnNNbOPZqlN00o4mqBoAAAAZCzdkPZB51xH/xvn3FFJH8xOk6YXhjsBAMB4pBvSCi1l5ruZFUoqyU6TphdCGgAAGI9008PP5YsE/j35/kPJYxhDOBpnuBMAAGQs3fTwGflg9pHk+42SvpWVFk0zvieNwgEAAJCZtEKac65P0teTD2QgEk0w3AkAADKW7jppKyT9g6RVksr6jzvnGrPUrmkhFu9TLNGnyhJCGgAAyEy6hQPflu9Fi0t6g6TvSvp+tho1XfRvrl5ZRkgDAACZSTekzXLO/VKSOedecc7dJukt2WvW9BBOhjSGOwEAQKbSTQ9RMyuQtNvMPi7poKTK7DVreojEkj1phDQAAJChdHvSbpFULunPJL1G0k2S3putRk0XEXrSAADAOI2ZHpIL177DOfeXksKS3p/1Vk0T4WhCklTJEhwAACBDY/akOecSki7NQVumHXrSAADAeKWbHp41s4cl/UBSpP+gc+6HWWnVNDFQOMASHAAAIEPppocySW2S3phyzEkipI1iYAkOetIAAECG0t1xgHlo48BwJwAAGK90dxz4tnzP2RDOuT8JvEXTSDiaUElhgUqK0i2iBQAA8NLt4vmvlNdlkq6TdCj45kwvbK4OAADGK93hzgdT35vZPZJ+nZUWTSPhaJyhTgAAMC7jHYdbIWn+WBeZ2RVm9qKZ7TGzW4c5/89m9lzy8ZKZdaScS6Sce3ic7cyrcDRO0QAAABiXdOekdWvonLRXJX1mjHsKJX1V0gZJzZKeMrOHnXM7+69xzn0y5fpPSDov5SOOO+fOTad9k1WEnjQAADBO6Q53Vo3jsy+UtMc5t0+SzOxeSddI2jnC9e+U9IVxfM+kFYnGVV1eku9mAACAKSit4U4zu87MqlPezzGza8e4bZGkAynvm5PHhvv8UyUtk/TfKYfLzGyrmT050neZ2c3Ja7a2tram81Nyyg93UjgAAAAyl+6ctC845zr73zjnOhRsr9eNkh5IbkHV71Tn3FpJ75L0ZTNbfuJNzrk7nXNrnXNr6+rqAmxOMCLRBLsNAACAcUk3pA133Vjp46CkxSnvG5LHhnOjpHtSDzjnDiaf90l6XEPnq00JzEkDAADjlW5I22pmd5jZ8uTjDklPj3HPU5JWmNkyMyuRD2InVWma2ZmS5kraknJsrpmVJl/XSrpEI89lm5Scc4rEqO4EAADjk25I+4SkmKT7JN0rqUfSx0a7wTkXl/RxSb+QtEvS/c65JjO73cyuTrn0Rkn3OudSq0dXygfD5yU9JulLqVWhU8Hx3oT6HFtCAQCA8Um3ujMi6aR1ztK47xFJj5xw7PMnvL9tmPs2S1qd6fdNJuGBzdUpHAAAAJlLt7pzo5nNSXk/18x+kb1mTX2RqK+BoCcNAACMR7rDnbXJik5JknPuqNLYcWAmiyR70ghpAABgPNINaX1mtqT/jZkt1dAdCHCCweFOQhoAAMhcugnif0v6tZn9jyST9FpJN2etVdNAhJAGAAAmIN3CgZ+b2Vr5YPaspIckHc9mw6a6MMOdAABgAtLdYP0Dkm6RX5D2OUnr5Nc1e2P2mja19RcO0JMGAADGI905abdIukDSK865N8iv/t8x+i0z22DhAEtwAACAzKUb0nqccz2SZGalzrkXJJ2RvWZNfQPDnezdCQAAxiHdBNGcXCftIUkbzeyopFey16ypLxKNq7ykUAUFlu+mAACAKSjdwoHrki9vM7PHJFVL+nnWWjUNRGJsrg4AAMYv4xThnPufbDRkuglHExQNAACAcUt3ThoyFInGKRoAAADjRkjLknA0TtEAAAAYN0JalkSicYY7AQDAuBHSssQPdxLSAADA+BDSsiRMSAMAABNASMuScDSuSgoHAADAOBHSsiCe6FNPbx89aQAAYNwIaVkQibG5OgAAmBhCWhYMbq5OSAMAAONDSMsCQhoAAJgoQloWhJMhjcIBAAAwXoS0LIhE/Zw0dhwAAADjRUjLgjDDnQAAYIIIaVkQGRjuJKQBAIDxIaRlQSRGTxoAAJgYQloWhOlJAwAAE0RIy4JINK7CAlNZMX9eAAAwPqSILIhEE6ooKZSZ5bspAABgiiKkZYHfXJ2hTgAAMH6EtCyIROMUDQAAgAkhpGVBmJAGAAAmiJCWBRGGOwEAwAQR0rIgEk2ogn07AQDABBDSsoDhTgAAMFGEtCyIxBjuBAAAE0NIywKqOwEAwEQR0gIWjSfUm3D0pAEAgAkhpAUsEk1IkipKKBwAAADjR0gLWCS5uTrDnQAAYCIIaQELJ0Maw50AAGAiCGkBC9OTBgAAAkBICxghDQAABIGQFrAIw50AACAAhLSADRYOUN0JAADGj5AWsHByCQ560gAAwEQQ0gLGEhwAACAIhLSARaJxlRQVqLiQPy0AABg/kkTAwlE2VwcAABNHSAuY31ydogEAADAxhLSAhaMJVZTQkwYAACaGkBawSDSuqjJCGgAAmBhCWsAisTiVnQAAYMIIaQELRwlpAABg4ghpAYtE46pkThoAAJggQlrAItEEPWkAAGDCCGkBcs4pEourkiU4AADABBHSAnQslpBzbAkFAAAmjpAWIPbtBAAAQSGkBSicDGlsCwUAACaKkBagSDQhiZ40AAAwcYS0AIUHhjspHAAAABNDSAtQhOFOAAAQEEJagCIxCgcAAEAwCGkBonAAAAAEhZAWIJbgAAAAQSGkBSjc40NaeTGFAwAAYGKyGtLM7Aoze9HM9pjZrcOc/2czey75eMnMOlLOvdfMdicf781mO4MSjiZUUVKoggLLd1MAAMAUl7VxOTMrlPRVSRskNUt6ysweds7t7L/GOffJlOs/Iem85Ot5kr4gaa0kJ+np5L1Hs9XeIESicYY6AQBAILLZk3ahpD3OuX3OuZikeyVdM8r175R0T/L15ZI2Oufak8Fso6QrstjWQIRjcYoGAABAILIZ0hZJOpDyvjl57CRmdqqkZZL+O5N7zexmM9tqZltbW1sDafRE0JMGAACCMlkKB26U9IBzLpHJTc65O51za51za+vq6rLUtPT5kEbRAAAAmLhshrSDkhanvG9IHhvOjRoc6sz03kkjHE0w3AkAAAKRzZD2lKQVZrbMzErkg9jDJ15kZmdKmitpS8rhX0h6s5nNNbO5kt6cPDapMdwJAACCkrVE4ZyLm9nH5cNVoaS7nHNNZna7pK3Ouf7AdqOke51zLuXedjP7W/mgJ0m3O+fas9XWoBDSAABAULKaKJxzj0h65IRjnz/h/W0j3HuXpLuy1rgsCEfjqiKkAQCAAEyWwoEpL57oUzTeR08aAAAIBCEtIJGoL0wlpAEAgCAQ0gISjvl9OytZggMAAASAkBaQSNSHNHrSAABAEAhpAQkT0gAAQIAIaQHp70ljMVsAABAEQlpABoY7SwhpAABg4ghpAQknqzvpSQMAAEEgpAVksHCA6k4AADBxhLSAUDgAAACCREgLSCQaV1GBqbSIPykAAJg4EkVA+jdXN7N8NwUAAEwDhLSAhKMJigYAAEBgCGkB8T1pFA0AAIBgENICEonFKRoAAACBIaQFpLsnznAnAAAIDCEtIJFonN0GAABAYAhpAemv7gQAAAgCIS0g4WhclRQOAACAgBDSAuCcUySWoCcNAAAEhpAWgGi8T4k+R0gDAACBIaQFoH/fTqo7AQBAUAhpAYiwuToAAAgYIS0A9KQBAICgEdICEIkmJBHSAABAcAhpARgc7mQJDgAAEAxCWgAY7gQAAEEjpAWAwgEAABA0QloAwoQ0AAAQMEJaAPoLBypKmJMGAACCQUgLQCQWV1lxgYoK+XMCAIBgkCoC4DdXZ6gTAAAEh5AWgEg0znw0AAAQKEJaACLRuCpKCGkAACA4hLQAMNwJAACCRkgLQCSaYLcBAAAQKEJaAJiTBgAAgkZICwDDnQAAIGiEtADQkwYAAIJGSJugvj6nSCxBSAMAAIEipE3QsV6/JVQlhQMAACBANUhw3gAADjtJREFUhLQJCvewuToAAAgeIW2CwlEf0igcAAAAQSKkTVAkGdLYcQAAAASJkDZBAyGNnjQAABAgQtoEMdwJAACygZA2QZFYf08a1Z0AACA4hLQJCkeTS3CU0ZMGAACCQ0iboAjDnQAAIAsIaRMUicZVYNKsYoY7AQBAcAhpExSOxlVRUiQzy3dTAAD/f3v3H2Npdddx/P1hlwW6GIEATbMgpXVJqlZBN/whaEgMiP4hmFQEtUH/KP5REpsmTcFo22BMGuOvf4iWRhIaQaxa6MaQUKyV2hrsLoRKWYTilobdIKyAyr2BOzuzX/+4z8J1ZNe5d+bc++zu+5VM5t4zz71zZk6e2c+e83yfIx1HDGnr5ObqkiSpBUPaOg1HK1Z2SpKkDWdIW6fBaNmiAUmStOEMaevkcqckSWrBkLZOA0OaJElqwJC2TsMllzslSdLGM6Stk4UDkiSpBUPaOrncKUmSWjCkrcPBlUMsLR/i9C2GNEmStLEMaetweN9OZ9IkSdJGM6Stw8DN1SVJUiOGtHUYjlYAZ9IkSdLGM6Stw+DN5U6rOyVJ0sYypK3D0OVOSZLUiCFtHSwckCRJrRjS1uE1Z9IkSVIjhrR1cCZNkiS10jSkJbk6ydNJnk1yyxGOuS7JniRPJrlnon0lyePdx86W/ZzV0MIBSZLUSLMpoCSbgNuBK4F9wK4kO6tqz8Qx24Fbgcuq6tUk5068xetVdXGr/m2EwWiFkzeFUzYb0iRJ0sZqOZN2KfBsVe2tqiXgXuCaVcd8CLi9ql4FqKqXGvZnww3dt1OSJDXSMqRtA56feL6va5t0EXBRkq8neSTJ1RNfOzXJ7q792rf7Bklu6o7ZfeDAgY3t/RoMR8sWDUiSpCYWnTA2A9uBK4DzgK8meX9V/SdwQVXtT/Ie4O+TPFFV/zb54qq6A7gDYMeOHTXfro9vZmtIkyRJLbScSdsPnD/x/LyubdI+YGdVHayq7wDPMA5tVNX+7vNe4B+ASxr2dSbDJZc7JUlSGy1D2i5ge5ILk2wBrgdWV2nez3gWjSRnM17+3JvkzCSnTLRfBuyhZwajFUOaJElqollIq6pl4GbgQeAp4PNV9WSS25L8XHfYg8DLSfYAXwE+VlUvA+8Ddif5Ztf+6cmq0L4YX5NmZackSdp4TaeBquoB4IFVbZ+YeFzAR7uPyWP+CXh/y75thOFoma1bnEmTJEkbzx0H1mHgLTgkSVIjhrQZVZW34JAkSc0Y0mb0xsFDHCr37ZQkSW0Y0mY06PbttHBAkiS1YEib0VubqzuTJkmSNp4hbUYDQ5okSWrIkDaj4ZvLnYY0SZK08QxpMxouOZMmSZLaMaTNaDBaASwckCRJbRjSZmThgCRJasmQNiNDmiRJasmQNqM3qzvdu1OSJDVgSJvRcLTMaSdvYtNJWXRXJEnScciQNqPBaMWlTkmS1IwhbUbjzdWt7JQkSW0Y0mY0GC07kyZJkpoxpM3IkCZJkloypM1ovNxpSJMkSW0Y0mZkSJMkSS0Z0mZkdackSWrJkDYjqzslSVJLhrQZrBwqXj/oTJokSWrHkDaD4dJ4SyivSZMkSa0Y0mbg5uqSJKk1Q9oMDGmSJKk1Q9oMBqMVAAsHJElSM4a0Gbw5k7bFmTRJktSGIW0GA5c7JUlSY4a0GRyeSbO6U5IktWJIm4GFA5IkqTVD2gzeKhwwpEmSpDYMaTMYjpY5KXDqyf76JElSG6aMGQxGy2w9ZTNJFt0VSZJ0nDKkzWC8ubpLnZIkqR1D2gyGS8sWDUiSpKYMaTMYjFYMaZIkqSlD2gzGy51uCSVJktoxpM1gOFp2SyhJktSUIW0GAwsHJElSY4a0GQxHFg5IkqS2DGkzGBjSJElSY4a0KY2WVzi4UhYOSJKkpgxpUxq6b6ckSZoDQ9qUhqNlAJc7JUlSU4a0KQ26kOZMmiRJasmQNiVn0iRJ0jwY0qY0MKRJkqQ5MKRNycIBSZI0D4a0Kb213OktOCRJUjuGtClZOCBJkubBkDYlCwckSdI8GNKmNFhaZsvmkzh5k786SZLUjkljSsPRskudkiSpOUPalIajFYsGJElSc4a0KQ1Gy2zd4kyaJElqy5A2JZc7JUnSPBjSpjQcLVvZKUmSmjOkTWngTJokSZoDQ9qULByQJEnzYEibksudkiRpHgxpU6gqhksud0qSpPYMaVN4/eAKh8otoSRJUnuGtCkM3LdTkiTNiSFtCsPRCgCnWzggSZIaM6RNYXh4Js0dByRJUmOGtCm89sY4pFk4IEmSWjOkTeHwTNrppxrSJElSW01DWpKrkzyd5NkktxzhmOuS7EnyZJJ7JtpvTPLt7uPGlv1cq+GShQOSJGk+mqWNJJuA24ErgX3AriQ7q2rPxDHbgVuBy6rq1STndu1nAZ8EdgAFPNq99tVW/V2Lw9WdLndKkqTWWs6kXQo8W1V7q2oJuBe4ZtUxHwJuPxy+quqlrv2ngYeq6pXuaw8BVzfs65oMvQWHJEmak5YhbRvw/MTzfV3bpIuAi5J8PckjSa6e4rUkuSnJ7iS7Dxw4sIFdf3uD7hYc7zjZW3BIkqS2Fl04sBnYDlwB3AB8NskZa31xVd1RVTuqasc555zTqItvGY6W2bplEyedlObfS5IkndhahrT9wPkTz8/r2ibtA3ZW1cGq+g7wDOPQtpbXzp2bq0uSpHlpGdJ2AduTXJhkC3A9sHPVMfcznkUjydmMlz/3Ag8CVyU5M8mZwFVd20INRm6uLkmS5qNZ4qiq5SQ3Mw5Xm4A7q+rJJLcBu6tqJ2+FsT3ACvCxqnoZIMnvMA56ALdV1Sut+rpWzqRJkqR5aZo4quoB4IFVbZ+YeFzAR7uP1a+9E7izZf+mNRytsNV9OyVJ0hwsunDgmOJypyRJmhdD2hSGSy53SpKk+TCkTcFr0iRJ0rwY0qaw7YzT2HbGaYvuhiRJOgE4LTSFL958+aK7IEmSThDOpEmSJPWQIU2SJKmHDGmSJEk9ZEiTJEnqIUOaJElSDxnSJEmSesiQJkmS1EOGNEmSpB4ypEmSJPWQIU2SJKmHDGmSJEk9ZEiTJEnqIUOaJElSDxnSJEmSesiQJkmS1EOGNEmSpB4ypEmSJPWQIU2SJKmHDGmSJEk9ZEiTJEnqIUOaJElSDxnSJEmSesiQJkmS1EOpqkX3YUMkOQB8dw7f6mzgP+bwfTQ7x+jY4DgdGxynY4Pj1H+rx+iCqjrnaC84bkLavCTZXVU7Ft0PHZljdGxwnI4NjtOxwXHqv1nGyOVOSZKkHjKkSZIk9ZAhbXp3LLoD+n85RscGx+nY4DgdGxyn/pt6jLwmTZIkqYecSZMkSeohQ5okSVIPGdLWKMnVSZ5O8mySWxbdH729JM8leSLJ40l2L7o/GktyZ5KXknxrou2sJA8l+Xb3+cxF9lFHHKdPJdnfnVOPJ/nZRfbxRJfk/CRfSbInyZNJfqNr93zqkaOM01Tnk9ekrUGSTcAzwJXAPmAXcENV7Vlox/R/JHkO2FFV3tSxR5L8JDAAPldVP9S1/R7wSlV9uvuPz5lV9fFF9vNEd4Rx+hQwqKrfX2TfNJbkXcC7quqxJN8DPApcC/wqnk+9cZRxuo4pzidn0tbmUuDZqtpbVUvAvcA1C+6TdMyoqq8Cr6xqvga4q3t8F+M/YFqgI4yTeqSqXqiqx7rHrwFPAdvwfOqVo4zTVAxpa7MNeH7i+T5m+GVrLgr4UpJHk9y06M7oqN5ZVS90j/8deOciO6OjujnJv3TLoS6j9USSdwOXAP+M51NvrRonmOJ8MqTpeHN5Vf0o8DPAh7vlG/Vcja+78NqLfvoT4L3AxcALwB8stjsCSHI68DfAR6rqvye/5vnUH28zTlOdT4a0tdkPnD/x/LyuTT1TVfu7zy8B9zFeqlY/vdhdt3H4+o2XFtwfvY2qerGqVqrqEPBZPKcWLsnJjP/hv7uqvtA1ez71zNuN07TnkyFtbXYB25NcmGQLcD2wc8F90ipJtnYXaJJkK3AV8K2jv0oLtBO4sXt8I/DFBfZFR3D4H/7Oz+M5tVBJAvwZ8FRV/eHElzyfeuRI4zTt+WR15xp1ZbJ/DGwC7qyq311wl7RKkvcwnj0D2Azc4zj1Q5K/AK4AzgZeBD4J3A98Hvg+4LvAdVXlResLdIRxuoLx0kwBzwG/PnHtk+YsyeXAPwJPAIe65t9kfL2T51NPHGWcbmCK88mQJkmS1EMud0qSJPWQIU2SJKmHDGmSJEk9ZEiTJEnqIUOaJElSDxnSJGmdklyR5G8X3Q9JxxdDmiRJUg8Z0iSdMJL8SpJvJHk8yWeSbEoySPJHSZ5M8uUk53THXpzkkW4j5PsOb4Sc5PuT/F2SbyZ5LMl7u7c/PclfJ/nXJHd3dxyXpJkZ0iSdEJK8D/hF4LKquhhYAX4Z2ArsrqofBB5mfJd9gM8BH6+qH2Z81/DD7XcDt1fVjwA/zniTZIBLgI8APwC8B7is+Q8l6bi2edEdkKQ5+Sngx4Bd3STXaYw3oT4E/GV3zJ8DX0jyvcAZVfVw134X8Ffd3rDbquo+gKp6A6B7v29U1b7u+ePAu4Gvtf+xJB2vDGmSThQB7qqqW/9XY/Lbq46bda+80cTjFfz7KmmdXO6UdKL4MvCBJOcCJDkryQWM/w5+oDvml4CvVdV/Aa8m+Ymu/YPAw1X1GrAvybXde5yS5B1z/SkknTD8n56kE0JV7UnyW8CXkpwEHAQ+DAyBS7uvvcT4ujWAG4E/7ULYXuDXuvYPAp9Jclv3Hr8wxx9D0gkkVbPO7EvSsS/JoKpOX3Q/JGk1lzslSZJ6yJk0SZKkHnImTZIkqYcMaZIkST1kSJMkSeohQ5okSVIPGdIkSZJ66H8A7BUS2X0BYhQAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=model.predict(X_test)"
      ],
      "metadata": {
        "id": "HeZg-PE-WNdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = reduce_Y(y_test)\n",
        "y_train = reduce_Y(y_train)\n",
        "d0 = model.predict(X_train[np.where(y_train>0.5)])\n",
        "d1 = model.predict(X_train[np.where(y_train<0.5)])\n",
        "\n",
        "d2 = model.predict(X_test[np.where(y_test>0.5)])\n",
        "d3 = model.predict(X_test[np.where(y_test<0.5)])\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.hist(d0, color='r', alpha=0.5, range=(0,1), bins=30, histtype='stepfilled', label='Signal (t\\\n",
        "rain)')\n",
        "ax.hist(d1, color='b', alpha=0.5, range=(0,1), bins=30, histtype='stepfilled', label='Backgroun\\\n",
        "d (train)')\n",
        "hist, bins = np.histogram(d2, bins=30, range=(0,1))\n",
        "scale = len(d2) / sum(hist)\n",
        "err = np.sqrt(hist * scale) / scale\n",
        "center = (bins[:-1] + bins[1:]) / 2\n",
        "ax.errorbar(center, hist, yerr=err, fmt='o', c='r', label='Signal (test)')\n",
        "hist, bins = np.histogram(d3, bins=30, range=(0,1))\n",
        "scale = len(d3) / sum(hist)\n",
        "err = np.sqrt(hist * scale) / scale\n",
        "ax.errorbar(center, hist, yerr=err, fmt='o', c='b', label='Background (test)')\n",
        "ax.set_xlabel(\"Output\")\n",
        "ax.set_ylabel(\"Arbitrary units\")\n",
        "# ax.set_title()\n",
        "ax.legend(loc='best')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "SWaYPcItWQje",
        "outputId": "e367ee49-8646-49e7-dfb3-bcff58c4b91d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fc63c431450>"
            ]
          },
          "metadata": {},
          "execution_count": 92
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Curva ROC"
      ],
      "metadata": {
        "id": "LHVfx7QCWVNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Roc\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "roc_auc = auc(fpr,tpr)\n",
        "\n",
        "# Roc plot\n",
        "fig_roc, ax_roc = plt.subplots(figsize=(7, 5))\n",
        "ax_roc.plot(fpr, tpr, lw=2, color='purple',label='full training (auc = %.3f)' % (roc_auc))\n",
        "ax_roc.plot([0, 1], [0, 1], linestyle='--', lw=2, color='k', label='random chance')\n",
        "ax_roc.set_xlim([0, 1.0])\n",
        "ax_roc.set_ylim([0, 1.0])\n",
        "ax_roc.set_xlabel('false positive rate')\n",
        "ax_roc.set_ylabel('true positive rate')\n",
        "ax_roc.set_title('Receiver Operating Curve')\n",
        "ax_roc.grid(True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "JmVIKcYxWUQ8",
        "outputId": "803428e6-15c5-4725-ce28-6ea3e47fcdf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}